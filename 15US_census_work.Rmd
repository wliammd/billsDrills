# US_Census_Data_Kyle_Walker_Presentation_YouTube {#census}

These are notes from a course taught by Kyle Walker, PhD and posted to YouTube by John DeWitt at the following YouTube <https://www.youtube.com/watch?v=PnFJfuJ83NI>

```{r}
library(tidyverse)
library(tidycensus)
library(plotly)
  
# install a new API key if necessary by obtaining a new key and installing it with the following
# census_api_key("aec016261a3b069f2318c77075e5224445517668", install = TRUE)
```

Let's see if this will connect me with the census data with a few simple queries. `get_decennial()` defaults to the latest 10-year, simple survey performed by the Census Bureau. The 10-year survey renders numbers. 

`get_acs()` contains much more information, and is based on the latest American Community Survey. ACS variables are rendered as estimates with a margin of error (MOE). 

```{r}
pop10 <- get_decennial(geography = "state", variables = "P001001")

pop10

income_15to19 <- get_acs(geography = "state",
                         variables = "B19013_001")

income_19 <- get_acs(geography = "state",
                    variables = "B19013_001",
                    survey = "acs1")

```

That looks great, but would be very labor intensive to assemble piecemeal. 

Luckily, common tables of variables are available.

```{r}
age_table<- get_acs(geography = "state",
                    table = "B01001")

age_table
```

That's great, but the variables are still encoded in the long form of the table. We'll need to solve that at some point.

```{r}
wi_income <- get_acs(geography = "county",
                     variables = "B19013_001",
                     state = "WI",
                     year =  2019)
wi_income
```

Querying by census tract is also possible. Census tracts are loosely analogous to neighborhoods and contain about 4000 people.

```{r}
dane_income <- get_acs(geography = "tract",
                     variables = "B19013_001",
                     state = "WI",
                     county =  "Dane")
dane_income
```

## Variables

```{r}
vars <- load_variables(2019, "acs5")
vars
```

This can be searched using RStudio's `View()` function, but it's still a mess. De Witt uses Census Reporter a lot--search online for this. Try <https://censusreporter.org/>, especially the **Explore** search field, which is a good way to identify good variables. One useful trick is to find the table identifier in Census Reporter and then use that to explore variables loaded using `load_variables()`. 

Another invaluable resource is <https://rconsortium.github.io/censusguide/>.   

The census.gov tools are also extensive. See for instance <https://www.census.gov/data/academy/data-gems/2021/how-to-visualize-your-data-using-thematic-maps-on-data-census-gov.html>.

```{r}
  hhinc <- get_acs(
    geography = "state",
    table = "B19001",
    survey = "acs1"
  )
  hhinc
  glimpse(hhinc)
  str(hhinc)

```

This is pretty tough to read. A wide form is easier and can be had without using `pivot_wider()`. 

```{r}
  hhinc_wide <- get_acs(
    geography = "state",
    table = "B19001",
    survey = "acs1",
    output = "wide"
  )
hhinc_wide

glimpse(hhinc_wide)

str(hhinc_wide)
```

We still aren't transparent with respect to vectors. I will never remember them. Named vectors can be used:

```{r}
ga_wide <- get_acs(
  geography = "county",
  state = "GA",
  variables = c(median_inc = "B19013_001",
                median_age = "B01002_001"),
  output = "wide"
)

ga_wide
```

Let's try something closer to home:

```{r}
med_age_Hennepin_wide <- get_acs(
  geography = "tract",
  state = "MN",
  variables = c(median_age = "B01002_001"),
  output = "wide"
)

med_age_Hennepin_wide

vs15 <- load_variables(2015, "acs5", cache = TRUE)

mn_wide <- get_acs(
  geography = "county",
  state = "MN",
  variables = c(total_pop = "B01003_001", 
                median_inc = "B19013_001",
                median_age = "B01002_001",
                white = "B02001_002",
                black = "B02001_003",
                native_am = "B02001_004",
                asian = "B02001_005",
                doctor = "B15003_025"),
  output = "wide"
)

mn_wide
```

## Part 2: Wrangling Census Data with **tidyverse** Tools

```{r}
median_age <- get_acs(
  geography = "county",
  variables = "B01002_001"
)

arrange(median_age, estimate)

arrange(median_age, desc(estimate))

above50 <- filter(median_age, estimate >=50)
```

Note how DeWitt assembles the following race/ethnicity groups, and then applies a summary variable:

```{r}
race_vars <- c(
  white = "B03002_003",
  black = "B03002_004",
  native = "B03002_005",
  asian = "B03002_006",
  HIPI = "B03002_007",
  hispanic = "B03002_012"
)

az_race <- get_acs(
  geography = "county",
  state = "AZ",
  variables = race_vars,
  summary_var = "B03002_001"
)

az_race

```

### Normalizing the data with `mutate()`.

```{r}
az_race_percent <-  az_race %>% 
  mutate(percent = 100*(estimate/summary_est)) %>% 
  select(NAME, variable, percent)

az_race_percent
```

### `group_by()` and `summarize()` in census analysis

```{r}
largest_group <- az_race_percent %>% 
  group_by(NAME) %>% 
  filter(percent == max(percent))

largest_group

az_race_percent %>% 
  group_by(variable) %>% 
  summarize(median_pct = median(percent))
```

### Margin of error considerations

```{r}
vars1 <- paste0("B01001_0", c(20:25, 44:49))
salt_lake <- get_acs(
  geography = "tract",
  variables = vars1,
  state = "Utah",
  county = "Salt Lake",
  year = 2019
)

example_tract <- salt_lake %>% 
  filter(GEOID == "49035100100")

example_tract %>% select(-NAME)
```

**tidycensus** has multiple functions already built to make margin of error calculations more straigtforward when you are assembling calculated values from multiple variables each with their own margin of error. 

One of these functions is `mod_prop()`. Check out the help documentation to understand the following example:

```{r}
moe_prop(25,100, 5, 3)
```

At 1 hour 52 minutes in the YouTube, a nice example to reduce margin of error by grouping small bins of data into larger bins is introduced. I do not take it up here.

Exercises for 2nd break:

```{r}
mn_bachelors_and_up <- get_acs(
  geography = "county",
  state = "MN",
  variables = "DP02_0068P")

mn_bachelors_and_up$estimate %>% median()

median(mn_bachelors_and_up$estimate)

# mn_bachelors_and_up %>% median()

```

New goal: find the percentage of commuters taking public transit to work in the 20 most populous metropolitan areas.

```{r}
  metros <- get_acs(
    geography = "cbsa",
    variables = "DP03_0021P",
    summary_var = "B01003_001",
    survey = "acs1"
  ) %>% filter(min_rank(desc(summary_est)) <21)

glimpse(metros)


  ggplot(data = metros, aes(x = NAME, y = estimate)) +
  geom_col()
  
  p <- metros %>% 
    mutate(NAME = str_remove(NAME, "-.*$")) %>% 
    mutate(NAME = str_remove(NAME, ",.*$")) %>%
    ggplot(aes(y = reorder(NAME, estimate), x = estimate)) +
    geom_col()
  
  p + theme_minimal() +
      labs(title = "Nifty title",
           y = "",
           x = "acs estimate (percent)",
           caption = "Nifty caption")
```

### Visualizing margins of error

```{r}
maine_income <- get_acs(
  state = "Maine",
  geography = "county",
  variables = c(hhincome = "B19013_001")) %>% 
  mutate(NAME = str_remove(NAME, " County, Maine"))

maine_income %>% arrange(desc(moe))

maine_income %>% ggplot(
  aes(x = estimate, y = reorder(NAME, estimate))) +
    geom_errorbarh(aes(xmin = estimate-moe, xmax = estimate+moe)) +
    geom_point(size = 3, color = "darkgreen") +
    labs(title = "Spiffy title",
        subtitle = "Counites of Maine",
        x = "2015-2019 ACS Estimate",
        y = "") + 
    scale_x_continuous(labels = scales::dollar)

```

### `get_estimates()` and how to use them

```{r}
utah <- get_estimates(
  geography = "state",
  state = "UT",
  product = "characteristics",
  breakdown = c("SEX", "AGEGROUP"),
  breakdown_labels = TRUE,
  year = 2019
)

utah

utah_filtered <- filter(utah, str_detect(AGEGROUP, "^Age"),
                        SEX != "Both sexes") %>% 
  mutate(value = ifelse(SEX == "Male", -value, value))

utah_filtered

utah_filtered %>% ggplot(aes(x = value, y = AGEGROUP, fill = SEX)) +
  geom_col()

utah_pyramid <- utah_filtered %>% ggplot(aes(x = value, y = AGEGROUP, fill = SEX)) +
  geom_col(width = 0.95, alpha = 0.75)+
  theme_minimal(base_family = "Verdana") +
  scale_x_continuous(labels = function(y)paste0(abs(y/1000), "k")) +
  scale_y_discrete(labels = function(x)gsub("Age|years", "", x)) +
  scale_fill_manual(values = c("darkred", "navy")) +
  labs(x = "",
       y = "2019 Census Bureau population estimate",
       title = "Population Structure in Utah",
       fill = "",
       caption = "Data source: US Census Bureau population estimates and tidycensus R package")

utah_pyramid

ggplotly(utah_pyramid)
```

### `ggbeeswarm()` automates some jitter considerations

```{r}
mn_race_income <- get_acs(
  geography = "tract",
  state = "MN",
  county = c("Hennepin", "Ramsey", "Washington", "Carver", "Dakota", "Anoka", "Wright", "Scott"),
  variables = c(White = "B03002_003",
                Black = "B03002_004",
                Asian = "B03002_006",
                Hispanic = "B03002_012"),
  summary_var = "B19013_001"
) %>% group_by(GEOID) %>% 
  filter(estimate == max(estimate, na.rm = TRUE)) %>% 
  ungroup() %>% 
  filter(estimate != 0)

library(ggbeeswarm)

mn_race_income %>% ggplot(aes(x = variable, 
                              y = summary_est, 
                              color = summary_est)) +
  geom_quasirandom(alpha = 0.5) +
  coord_flip() +
  theme_minimal() +
  scale_color_viridis_c(guide = FALSE) +
  scale_y_continuous(labels = scales::dollar) +
  labs(x = "Largest Group in Census Tract",
       y = "Median Household Income",
       title = "Household Income By Largest Race/Ethnic Group",
       subtitle = "Census Tracts, Twin Cities Metro Area",
       caption = "Data source: 2015-2019 ACS")
```

