[["us-census-data-kyle-walker-presentation-youtube-censusss.html", "Chapter 15 US_Census_Data_Kyle_Walker_Presentation_YouTube {#census}ss 15.1 Variables 15.2 Part 2: Wrangling Census Data with tidyverse Tools", " Chapter 15 US_Census_Data_Kyle_Walker_Presentation_YouTube {#census}ss These are notes from a course taught by Kyle Walker, PhD and posted to YouTube by John DeWitt at the following YouTube https://www.youtube.com/watch?v=PnFJfuJ83NI library(tidyverse) library(tidycensus) library(plotly) ## ## Attaching package: &#39;plotly&#39; ## The following object is masked from &#39;package:ggplot2&#39;: ## ## last_plot ## The following object is masked from &#39;package:stats&#39;: ## ## filter ## The following object is masked from &#39;package:graphics&#39;: ## ## layout # install a new API key if necessary by obtaining a new key and installing it with the following # census_api_key(&quot;aec016261a3b069f2318c77075e5224445517668&quot;, install = TRUE) Let’s see if this will connect me with the census data with a few simple queries. get_decennial() defaults to the latest 10-year, simple survey performed by the Census Bureau. The 10-year survey renders numbers. get_acs() contains much more information, and is based on the latest American Community Survey. ACS variables are rendered as estimates with a margin of error (MOE). pop10 &lt;- get_decennial(geography = &quot;state&quot;, variables = &quot;P001001&quot;) ## Getting data from the 2010 decennial Census ## Using Census Summary File 1 pop10 ## # A tibble: 52 x 4 ## GEOID NAME variable value ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 01 Alabama P001001 4779736 ## 2 02 Alaska P001001 710231 ## 3 04 Arizona P001001 6392017 ## 4 05 Arkansas P001001 2915918 ## 5 06 California P001001 37253956 ## 6 22 Louisiana P001001 4533372 ## 7 21 Kentucky P001001 4339367 ## 8 08 Colorado P001001 5029196 ## 9 09 Connecticut P001001 3574097 ## 10 10 Delaware P001001 897934 ## # … with 42 more rows income_15to19 &lt;- get_acs(geography = &quot;state&quot;, variables = &quot;B19013_001&quot;) ## Getting data from the 2015-2019 5-year ACS income_19 &lt;- get_acs(geography = &quot;state&quot;, variables = &quot;B19013_001&quot;, survey = &quot;acs1&quot;) ## The 1-year ACS provides data for geographies with populations of 65,000 and greater. ## Getting data from the 2019 1-year ACS That looks great, but would be very labor intensive to assemble piecemeal. Luckily, common tables of variables are available. age_table&lt;- get_acs(geography = &quot;state&quot;, table = &quot;B01001&quot;) ## Getting data from the 2015-2019 5-year ACS ## Loading ACS5 variables for 2019 from table B01001. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset. age_table ## # A tibble: 2,548 x 5 ## GEOID NAME variable estimate moe ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 01 Alabama B01001_001 4876250 NA ## 2 01 Alabama B01001_002 2359355 1270 ## 3 01 Alabama B01001_003 149090 704 ## 4 01 Alabama B01001_004 153494 2290 ## 5 01 Alabama B01001_005 158617 2274 ## 6 01 Alabama B01001_006 98257 468 ## 7 01 Alabama B01001_007 64980 834 ## 8 01 Alabama B01001_008 35870 1436 ## 9 01 Alabama B01001_009 35040 1472 ## 10 01 Alabama B01001_010 95065 1916 ## # … with 2,538 more rows That’s great, but the variables are still encoded in the long form of the table. We’ll need to solve that at some point. wi_income &lt;- get_acs(geography = &quot;county&quot;, variables = &quot;B19013_001&quot;, state = &quot;WI&quot;, year = 2019) ## Getting data from the 2015-2019 5-year ACS wi_income ## # A tibble: 72 x 5 ## GEOID NAME variable estimate moe ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 55001 Adams County, Wisconsin B19013_001 46369 1834 ## 2 55003 Ashland County, Wisconsin B19013_001 42510 2858 ## 3 55005 Barron County, Wisconsin B19013_001 52703 2104 ## 4 55007 Bayfield County, Wisconsin B19013_001 56096 1877 ## 5 55009 Brown County, Wisconsin B19013_001 62340 1112 ## 6 55011 Buffalo County, Wisconsin B19013_001 57829 1873 ## 7 55013 Burnett County, Wisconsin B19013_001 52672 1388 ## 8 55015 Calumet County, Wisconsin B19013_001 75814 2425 ## 9 55017 Chippewa County, Wisconsin B19013_001 59742 1759 ## 10 55019 Clark County, Wisconsin B19013_001 54012 1223 ## # … with 62 more rows Querying by census tract is also possible. Census tracts are loosely analogous to neighborhoods and contain about 4000 people. dane_income &lt;- get_acs(geography = &quot;tract&quot;, variables = &quot;B19013_001&quot;, state = &quot;WI&quot;, county = &quot;Dane&quot;) ## Getting data from the 2015-2019 5-year ACS dane_income ## # A tibble: 107 x 5 ## GEOID NAME variable estimate moe ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 55025000100 Census Tract 1, Dane County, Wisconsin B19013_0… 72471 12984 ## 2 55025000201 Census Tract 2.01, Dane County, Wiscons… B19013_0… 94821 11860 ## 3 55025000202 Census Tract 2.02, Dane County, Wiscons… B19013_0… 84145 7021 ## 4 55025000204 Census Tract 2.04, Dane County, Wiscons… B19013_0… 79617 11823 ## 5 55025000205 Census Tract 2.05, Dane County, Wiscons… B19013_0… 91326 13453 ## 6 55025000300 Census Tract 3, Dane County, Wisconsin B19013_0… 53778 7593 ## 7 55025000401 Census Tract 4.01, Dane County, Wiscons… B19013_0… 98178 7330 ## 8 55025000402 Census Tract 4.02, Dane County, Wiscons… B19013_0… 107440 6585 ## 9 55025000405 Census Tract 4.05, Dane County, Wiscons… B19013_0… 68911 4141 ## 10 55025000406 Census Tract 4.06, Dane County, Wiscons… B19013_0… 74489 10451 ## # … with 97 more rows 15.1 Variables vars &lt;- load_variables(2019, &quot;acs5&quot;) vars ## # A tibble: 27,040 x 3 ## name label concept ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 B01001_001 Estimate!!Total: SEX BY AGE ## 2 B01001_002 Estimate!!Total:!!Male: SEX BY AGE ## 3 B01001_003 Estimate!!Total:!!Male:!!Under 5 years SEX BY AGE ## 4 B01001_004 Estimate!!Total:!!Male:!!5 to 9 years SEX BY AGE ## 5 B01001_005 Estimate!!Total:!!Male:!!10 to 14 years SEX BY AGE ## 6 B01001_006 Estimate!!Total:!!Male:!!15 to 17 years SEX BY AGE ## 7 B01001_007 Estimate!!Total:!!Male:!!18 and 19 years SEX BY AGE ## 8 B01001_008 Estimate!!Total:!!Male:!!20 years SEX BY AGE ## 9 B01001_009 Estimate!!Total:!!Male:!!21 years SEX BY AGE ## 10 B01001_010 Estimate!!Total:!!Male:!!22 to 24 years SEX BY AGE ## # … with 27,030 more rows This can be searched using RStudio’s View() function, but it’s still a mess. De Witt uses Census Reporter a lot–search online for this. Try https://censusreporter.org/, especially the Explore search field, which is a good way to identify good variables. One useful trick is to find the table identifier in Census Reporter and then use that to explore variables loaded using load_variables(). Another invaluable resource is https://rconsortium.github.io/censusguide/. The census.gov tools are also extensive. See for instance https://www.census.gov/data/academy/data-gems/2021/how-to-visualize-your-data-using-thematic-maps-on-data-census-gov.html. hhinc &lt;- get_acs( geography = &quot;state&quot;, table = &quot;B19001&quot;, survey = &quot;acs1&quot; ) ## The 1-year ACS provides data for geographies with populations of 65,000 and greater. ## Getting data from the 2019 1-year ACS ## Loading ACS1 variables for 2019 from table B19001. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset. hhinc ## # A tibble: 884 x 5 ## GEOID NAME variable estimate moe ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 01 Alabama B19001_001 1897576 10370 ## 2 01 Alabama B19001_002 154558 5883 ## 3 01 Alabama B19001_003 103653 6001 ## 4 01 Alabama B19001_004 108500 5926 ## 5 01 Alabama B19001_005 98706 6491 ## 6 01 Alabama B19001_006 90916 5859 ## 7 01 Alabama B19001_007 105146 4149 ## 8 01 Alabama B19001_008 85014 5417 ## 9 01 Alabama B19001_009 87118 5163 ## 10 01 Alabama B19001_010 82323 4231 ## # … with 874 more rows glimpse(hhinc) ## Rows: 884 ## Columns: 5 ## $ GEOID &lt;chr&gt; &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;… ## $ NAME &lt;chr&gt; &quot;Alabama&quot;, &quot;Alabama&quot;, &quot;Alabama&quot;, &quot;Alabama&quot;, &quot;Alabama&quot;, &quot;Alaba… ## $ variable &lt;chr&gt; &quot;B19001_001&quot;, &quot;B19001_002&quot;, &quot;B19001_003&quot;, &quot;B19001_004&quot;, &quot;B190… ## $ estimate &lt;dbl&gt; 1897576, 154558, 103653, 108500, 98706, 90916, 105146, 85014,… ## $ moe &lt;dbl&gt; 10370, 5883, 6001, 5926, 6491, 5859, 4149, 5417, 5163, 4231, … str(hhinc) ## tibble [884 × 5] (S3: tbl_df/tbl/data.frame) ## $ GEOID : chr [1:884] &quot;01&quot; &quot;01&quot; &quot;01&quot; &quot;01&quot; ... ## $ NAME : chr [1:884] &quot;Alabama&quot; &quot;Alabama&quot; &quot;Alabama&quot; &quot;Alabama&quot; ... ## $ variable: chr [1:884] &quot;B19001_001&quot; &quot;B19001_002&quot; &quot;B19001_003&quot; &quot;B19001_004&quot; ... ## $ estimate: num [1:884] 1897576 154558 103653 108500 98706 ... ## $ moe : num [1:884] 10370 5883 6001 5926 6491 ... This is pretty tough to read. A wide form is easier and can be had without using pivot_wider(). hhinc_wide &lt;- get_acs( geography = &quot;state&quot;, table = &quot;B19001&quot;, survey = &quot;acs1&quot;, output = &quot;wide&quot; ) ## The 1-year ACS provides data for geographies with populations of 65,000 and greater. ## Getting data from the 2019 1-year ACS ## Loading ACS1 variables for 2019 from table B19001. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset. hhinc_wide ## # A tibble: 52 x 36 ## GEOID NAME B19001_001E B19001_001M B19001_002E B19001_002M B19001_003E ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 17 Illinois 4866006 12627 289515 9500 178230 ## 2 13 Georgia 3852714 14425 237054 8319 163741 ## 3 16 Idaho 655859 5316 27773 3127 24498 ## 4 15 Hawaii 465299 5012 23344 2470 12238 ## 5 18 Indiana 2597765 12716 153355 7188 104333 ## 6 19 Iowa 1287221 6606 65503 3958 52788 ## 7 20 Kansas 1138329 6595 57967 4269 49134 ## 8 21 Kentucky 1748732 8789 137394 7450 96775 ## 9 22 Louisiana 1741076 11011 175845 7581 98971 ## 10 23 Maine 573618 4999 29156 2776 26772 ## # … with 42 more rows, and 29 more variables: B19001_003M &lt;dbl&gt;, ## # B19001_004E &lt;dbl&gt;, B19001_004M &lt;dbl&gt;, B19001_005E &lt;dbl&gt;, B19001_005M &lt;dbl&gt;, ## # B19001_006E &lt;dbl&gt;, B19001_006M &lt;dbl&gt;, B19001_007E &lt;dbl&gt;, B19001_007M &lt;dbl&gt;, ## # B19001_008E &lt;dbl&gt;, B19001_008M &lt;dbl&gt;, B19001_009E &lt;dbl&gt;, B19001_009M &lt;dbl&gt;, ## # B19001_010E &lt;dbl&gt;, B19001_010M &lt;dbl&gt;, B19001_011E &lt;dbl&gt;, B19001_011M &lt;dbl&gt;, ## # B19001_012E &lt;dbl&gt;, B19001_012M &lt;dbl&gt;, B19001_013E &lt;dbl&gt;, B19001_013M &lt;dbl&gt;, ## # B19001_014E &lt;dbl&gt;, B19001_014M &lt;dbl&gt;, B19001_015E &lt;dbl&gt;, B19001_015M &lt;dbl&gt;, ## # B19001_016E &lt;dbl&gt;, B19001_016M &lt;dbl&gt;, B19001_017E &lt;dbl&gt;, B19001_017M &lt;dbl&gt; glimpse(hhinc_wide) ## Rows: 52 ## Columns: 36 ## $ GEOID &lt;chr&gt; &quot;17&quot;, &quot;13&quot;, &quot;16&quot;, &quot;15&quot;, &quot;18&quot;, &quot;19&quot;, &quot;20&quot;, &quot;21&quot;, &quot;22&quot;, &quot;23&quot;… ## $ NAME &lt;chr&gt; &quot;Illinois&quot;, &quot;Georgia&quot;, &quot;Idaho&quot;, &quot;Hawaii&quot;, &quot;Indiana&quot;, &quot;Iowa… ## $ B19001_001E &lt;dbl&gt; 4866006, 3852714, 655859, 465299, 2597765, 1287221, 113832… ## $ B19001_001M &lt;dbl&gt; 12627, 14425, 5316, 5012, 12716, 6606, 6595, 8789, 11011, … ## $ B19001_002E &lt;dbl&gt; 289515, 237054, 27773, 23344, 153355, 65503, 57967, 137394… ## $ B19001_002M &lt;dbl&gt; 9500, 8319, 3127, 2470, 7188, 3958, 4269, 7450, 7581, 2776… ## $ B19001_003E &lt;dbl&gt; 178230, 163741, 24498, 12238, 104333, 52788, 49134, 96775,… ## $ B19001_003M &lt;dbl&gt; 7552, 6674, 2683, 1722, 5489, 3671, 3808, 5086, 5899, 2777… ## $ B19001_004E &lt;dbl&gt; 183540, 166221, 30937, 12277, 114209, 51996, 47555, 91258,… ## $ B19001_004M &lt;dbl&gt; 7592, 7842, 3245, 2332, 5524, 2979, 3760, 4652, 5590, 2377… ## $ B19001_005E &lt;dbl&gt; 206595, 173428, 28519, 15179, 130573, 55813, 46910, 97164,… ## $ B19001_005M &lt;dbl&gt; 6895, 7666, 2743, 2454, 6385, 3597, 3061, 5289, 5982, 2447… ## $ B19001_006E &lt;dbl&gt; 189948, 169736, 29674, 12991, 119781, 53262, 45121, 87632,… ## $ B19001_006M &lt;dbl&gt; 7371, 9173, 3382, 2087, 6143, 3656, 3036, 5571, 4877, 2930… ## $ B19001_007E &lt;dbl&gt; 197382, 174416, 33553, 16607, 134479, 64428, 56401, 87383,… ## $ B19001_007M &lt;dbl&gt; 6397, 8422, 3043, 2164, 5695, 4104, 3843, 4678, 5559, 2342… ## $ B19001_008E &lt;dbl&gt; 186475, 160146, 29333, 12211, 119809, 55396, 52296, 79311,… ## $ B19001_008M &lt;dbl&gt; 6024, 8450, 2652, 1880, 6480, 3239, 3277, 4462, 4746, 2811… ## $ B19001_009E &lt;dbl&gt; 197027, 168658, 28390, 14811, 126321, 64728, 54980, 82031,… ## $ B19001_009M &lt;dbl&gt; 8242, 9366, 2763, 1770, 5521, 3751, 3076, 4207, 4875, 2634… ## $ B19001_010E &lt;dbl&gt; 170536, 148721, 28771, 13260, 112198, 53469, 44142, 72412,… ## $ B19001_010M &lt;dbl&gt; 7120, 7865, 2955, 1601, 5822, 3312, 3229, 4349, 4467, 2747… ## $ B19001_011E &lt;dbl&gt; 338947, 286625, 59944, 31700, 225269, 106115, 91195, 13847… ## $ B19001_011M &lt;dbl&gt; 9644, 10319, 4165, 2968, 7454, 4657, 4413, 5578, 6506, 354… ## $ B19001_012E &lt;dbl&gt; 465073, 417847, 75990, 46591, 278719, 145070, 128644, 1840… ## $ B19001_012M &lt;dbl&gt; 10099, 13725, 4653, 3741, 8045, 5722, 4856, 6505, 7022, 36… ## $ B19001_013E &lt;dbl&gt; 622878, 490823, 93083, 62750, 335223, 181075, 154883, 2175… ## $ B19001_013M &lt;dbl&gt; 11460, 11586, 5688, 3941, 8714, 6372, 5325, 7666, 8214, 39… ## $ B19001_014E &lt;dbl&gt; 485409, 345431, 62355, 54269, 239586, 129838, 109663, 1447… ## $ B19001_014M &lt;dbl&gt; 11851, 8991, 3869, 3256, 7242, 4739, 5628, 5547, 6002, 309… ## $ B19001_015E &lt;dbl&gt; 335706, 224841, 36160, 38537, 142304, 73169, 65709, 79088,… ## $ B19001_015M &lt;dbl&gt; 8103, 8362, 3380, 3111, 6171, 4237, 3518, 4307, 4712, 2141… ## $ B19001_016E &lt;dbl&gt; 379693, 243294, 34280, 47879, 139536, 70712, 66556, 81644,… ## $ B19001_016M &lt;dbl&gt; 8588, 7657, 3485, 3352, 5495, 3654, 3704, 4722, 4979, 2540… ## $ B19001_017E &lt;dbl&gt; 439052, 281732, 32599, 50655, 122070, 63859, 67173, 71788,… ## $ B19001_017M &lt;dbl&gt; 8929, 8944, 2923, 3266, 5142, 3712, 3598, 3720, 5284, 2666… str(hhinc_wide) ## tibble [52 × 36] (S3: tbl_df/tbl/data.frame) ## $ GEOID : chr [1:52] &quot;17&quot; &quot;13&quot; &quot;16&quot; &quot;15&quot; ... ## $ NAME : chr [1:52] &quot;Illinois&quot; &quot;Georgia&quot; &quot;Idaho&quot; &quot;Hawaii&quot; ... ## $ B19001_001E: num [1:52] 4866006 3852714 655859 465299 2597765 ... ## $ B19001_001M: num [1:52] 12627 14425 5316 5012 12716 ... ## $ B19001_002E: num [1:52] 289515 237054 27773 23344 153355 ... ## $ B19001_002M: num [1:52] 9500 8319 3127 2470 7188 ... ## $ B19001_003E: num [1:52] 178230 163741 24498 12238 104333 ... ## $ B19001_003M: num [1:52] 7552 6674 2683 1722 5489 ... ## $ B19001_004E: num [1:52] 183540 166221 30937 12277 114209 ... ## $ B19001_004M: num [1:52] 7592 7842 3245 2332 5524 ... ## $ B19001_005E: num [1:52] 206595 173428 28519 15179 130573 ... ## $ B19001_005M: num [1:52] 6895 7666 2743 2454 6385 ... ## $ B19001_006E: num [1:52] 189948 169736 29674 12991 119781 ... ## $ B19001_006M: num [1:52] 7371 9173 3382 2087 6143 ... ## $ B19001_007E: num [1:52] 197382 174416 33553 16607 134479 ... ## $ B19001_007M: num [1:52] 6397 8422 3043 2164 5695 ... ## $ B19001_008E: num [1:52] 186475 160146 29333 12211 119809 ... ## $ B19001_008M: num [1:52] 6024 8450 2652 1880 6480 ... ## $ B19001_009E: num [1:52] 197027 168658 28390 14811 126321 ... ## $ B19001_009M: num [1:52] 8242 9366 2763 1770 5521 ... ## $ B19001_010E: num [1:52] 170536 148721 28771 13260 112198 ... ## $ B19001_010M: num [1:52] 7120 7865 2955 1601 5822 ... ## $ B19001_011E: num [1:52] 338947 286625 59944 31700 225269 ... ## $ B19001_011M: num [1:52] 9644 10319 4165 2968 7454 ... ## $ B19001_012E: num [1:52] 465073 417847 75990 46591 278719 ... ## $ B19001_012M: num [1:52] 10099 13725 4653 3741 8045 ... ## $ B19001_013E: num [1:52] 622878 490823 93083 62750 335223 ... ## $ B19001_013M: num [1:52] 11460 11586 5688 3941 8714 ... ## $ B19001_014E: num [1:52] 485409 345431 62355 54269 239586 ... ## $ B19001_014M: num [1:52] 11851 8991 3869 3256 7242 ... ## $ B19001_015E: num [1:52] 335706 224841 36160 38537 142304 ... ## $ B19001_015M: num [1:52] 8103 8362 3380 3111 6171 ... ## $ B19001_016E: num [1:52] 379693 243294 34280 47879 139536 ... ## $ B19001_016M: num [1:52] 8588 7657 3485 3352 5495 ... ## $ B19001_017E: num [1:52] 439052 281732 32599 50655 122070 ... ## $ B19001_017M: num [1:52] 8929 8944 2923 3266 5142 ... We still aren’t transparent with respect to vectors. I will never remember them. Named vectors can be used: ga_wide &lt;- get_acs( geography = &quot;county&quot;, state = &quot;GA&quot;, variables = c(median_inc = &quot;B19013_001&quot;, median_age = &quot;B01002_001&quot;), output = &quot;wide&quot; ) ## Getting data from the 2015-2019 5-year ACS ga_wide ## # A tibble: 159 x 6 ## GEOID NAME median_incE median_incM median_ageE median_ageM ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 13005 Bacon County, Georgia 37519 5492 36.7 0.7 ## 2 13025 Brantley County, Georg… 38857 3480 41.1 0.8 ## 3 13017 Ben Hill County, Georg… 32229 3845 39.9 1.1 ## 4 13033 Burke County, Georgia 44151 2438 37.4 0.6 ## 5 13047 Catoosa County, Georgia 56235 2290 40.4 0.4 ## 6 13053 Chattahoochee County, … 47096 5158 24.5 0.5 ## 7 13055 Chattooga County, Geor… 36807 2268 39.4 0.7 ## 8 13073 Columbia County, Georg… 82339 3532 36.9 0.4 ## 9 13087 Decatur County, Georgia 41481 3584 37.8 0.6 ## 10 13115 Floyd County, Georgia 48336 2266 38.3 0.3 ## # … with 149 more rows Let’s try something closer to home: med_age_Hennepin_wide &lt;- get_acs( geography = &quot;tract&quot;, state = &quot;MN&quot;, variables = c(median_age = &quot;B01002_001&quot;), output = &quot;wide&quot; ) ## Getting data from the 2015-2019 5-year ACS med_age_Hennepin_wide ## # A tibble: 1,338 x 4 ## GEOID NAME median_ageE median_ageM ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 27053025401 Census Tract 254.01, Hennepin County, Mi… 37.4 3.8 ## 2 27053025805 Census Tract 258.05, Hennepin County, Mi… 52.2 6 ## 3 27053026018 Census Tract 260.18, Hennepin County, Mi… 41.9 1.8 ## 4 27053026402 Census Tract 264.02, Hennepin County, Mi… 36.1 2.9 ## 5 27053026404 Census Tract 264.04, Hennepin County, Mi… 50.5 3.7 ## 6 27053026809 Census Tract 268.09, Hennepin County, Mi… 29.1 2.2 ## 7 27053027602 Census Tract 276.02, Hennepin County, Mi… 45.9 3.6 ## 8 27053102000 Census Tract 1020, Hennepin County, Minn… 33.9 3.6 ## 9 27053103600 Census Tract 1036, Hennepin County, Minn… 47.9 5.1 ## 10 27053022902 Census Tract 229.02, Hennepin County, Mi… 40.2 3.1 ## # … with 1,328 more rows vs15 &lt;- load_variables(2015, &quot;acs5&quot;, cache = TRUE) mn_wide &lt;- get_acs( geography = &quot;county&quot;, state = &quot;MN&quot;, variables = c(total_pop = &quot;B01003_001&quot;, median_inc = &quot;B19013_001&quot;, median_age = &quot;B01002_001&quot;, white = &quot;B02001_002&quot;, black = &quot;B02001_003&quot;, native_am = &quot;B02001_004&quot;, asian = &quot;B02001_005&quot;, doctor = &quot;B15003_025&quot;), output = &quot;wide&quot; ) ## Getting data from the 2015-2019 5-year ACS mn_wide ## # A tibble: 87 x 18 ## GEOID NAME total_popE total_popM median_incE median_incM median_ageE ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 27093 Meeker Count… 23105 NA 63452 1601 42.2 ## 2 27131 Rice County,… 66185 NA 68584 2227 36.5 ## 3 27125 Red Lake Cou… 4015 NA 58576 4262 42.7 ## 4 27027 Clay County,… 63446 NA 65269 2909 32.6 ## 5 27045 Fillmore Cou… 20949 NA 61207 1604 42.3 ## 6 27119 Polk County,… 31521 NA 59343 2282 38.7 ## 7 27143 Sibley Count… 14892 NA 63439 1646 41.7 ## 8 27165 Watonwan Cou… 10972 NA 54065 2930 39.9 ## 9 27011 Big Stone Co… 4996 NA 53900 5054 49 ## 10 27021 Cass County,… 29268 NA 52204 1447 48.9 ## # … with 77 more rows, and 11 more variables: median_ageM &lt;dbl&gt;, whiteE &lt;dbl&gt;, ## # whiteM &lt;dbl&gt;, blackE &lt;dbl&gt;, blackM &lt;dbl&gt;, native_amE &lt;dbl&gt;, ## # native_amM &lt;dbl&gt;, asianE &lt;dbl&gt;, asianM &lt;dbl&gt;, doctorE &lt;dbl&gt;, doctorM &lt;dbl&gt; 15.2 Part 2: Wrangling Census Data with tidyverse Tools median_age &lt;- get_acs( geography = &quot;county&quot;, variables = &quot;B01002_001&quot; ) ## Getting data from the 2015-2019 5-year ACS arrange(median_age, estimate) ## # A tibble: 3,220 x 5 ## GEOID NAME variable estimate moe ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 51678 Lexington city, Virginia B01002_001 22.3 0.7 ## 2 51750 Radford city, Virginia B01002_001 23.4 0.5 ## 3 16065 Madison County, Idaho B01002_001 23.5 0.2 ## 4 46121 Todd County, South Dakota B01002_001 23.8 0.4 ## 5 02158 Kusilvak Census Area, Alaska B01002_001 24.1 0.2 ## 6 13053 Chattahoochee County, Georgia B01002_001 24.5 0.5 ## 7 53075 Whitman County, Washington B01002_001 24.7 0.3 ## 8 49049 Utah County, Utah B01002_001 24.8 0.1 ## 9 46027 Clay County, South Dakota B01002_001 24.9 0.4 ## 10 51830 Williamsburg city, Virginia B01002_001 24.9 0.7 ## # … with 3,210 more rows arrange(median_age, desc(estimate)) ## # A tibble: 3,220 x 5 ## GEOID NAME variable estimate moe ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 12119 Sumter County, Florida B01002_001 67.4 0.2 ## 2 51091 Highland County, Virginia B01002_001 60.9 3.5 ## 3 08027 Custer County, Colorado B01002_001 59.7 2.6 ## 4 12015 Charlotte County, Florida B01002_001 59.1 0.2 ## 5 41069 Wheeler County, Oregon B01002_001 59 3.3 ## 6 51133 Northumberland County, Virginia B01002_001 58.9 0.7 ## 7 26131 Ontonagon County, Michigan B01002_001 58.6 0.4 ## 8 35021 Harding County, New Mexico B01002_001 58.5 5.5 ## 9 53031 Jefferson County, Washington B01002_001 58.3 0.7 ## 10 26001 Alcona County, Michigan B01002_001 58.2 0.3 ## # … with 3,210 more rows above50 &lt;- filter(median_age, estimate &gt;=50) Note how DeWitt assembles the following race/ethnicity groups, and then applies a summary variable: race_vars &lt;- c( white = &quot;B03002_003&quot;, black = &quot;B03002_004&quot;, native = &quot;B03002_005&quot;, asian = &quot;B03002_006&quot;, HIPI = &quot;B03002_007&quot;, hispanic = &quot;B03002_012&quot; ) az_race &lt;- get_acs( geography = &quot;county&quot;, state = &quot;AZ&quot;, variables = race_vars, summary_var = &quot;B03002_001&quot; ) ## Getting data from the 2015-2019 5-year ACS az_race ## # A tibble: 90 x 7 ## GEOID NAME variable estimate moe summary_est summary_moe ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 04001 Apache County, Arizona white 13022 4 71511 NA ## 2 04001 Apache County, Arizona black 373 138 71511 NA ## 3 04001 Apache County, Arizona native 52285 234 71511 NA ## 4 04001 Apache County, Arizona asian 246 78 71511 NA ## 5 04001 Apache County, Arizona HIPI 16 16 71511 NA ## 6 04001 Apache County, Arizona hispanic 4531 NA 71511 NA ## 7 04003 Cochise County, Arizona white 69216 235 125867 NA ## 8 04003 Cochise County, Arizona black 4620 247 125867 NA ## 9 04003 Cochise County, Arizona native 1142 191 125867 NA ## 10 04003 Cochise County, Arizona asian 2431 162 125867 NA ## # … with 80 more rows 15.2.1 Normalizing the data with mutate(). az_race_percent &lt;- az_race %&gt;% mutate(percent = 100*(estimate/summary_est)) %&gt;% select(NAME, variable, percent) az_race_percent ## # A tibble: 90 x 3 ## NAME variable percent ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Apache County, Arizona white 18.2 ## 2 Apache County, Arizona black 0.522 ## 3 Apache County, Arizona native 73.1 ## 4 Apache County, Arizona asian 0.344 ## 5 Apache County, Arizona HIPI 0.0224 ## 6 Apache County, Arizona hispanic 6.34 ## 7 Cochise County, Arizona white 55.0 ## 8 Cochise County, Arizona black 3.67 ## 9 Cochise County, Arizona native 0.907 ## 10 Cochise County, Arizona asian 1.93 ## # … with 80 more rows 15.2.2 group_by() and summarize() in census analysis largest_group &lt;- az_race_percent %&gt;% group_by(NAME) %&gt;% filter(percent == max(percent)) largest_group ## # A tibble: 15 x 3 ## # Groups: NAME [15] ## NAME variable percent ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Apache County, Arizona native 73.1 ## 2 Cochise County, Arizona white 55.0 ## 3 Coconino County, Arizona white 54.1 ## 4 Gila County, Arizona white 62.3 ## 5 Graham County, Arizona white 50.9 ## 6 Greenlee County, Arizona hispanic 46.8 ## 7 La Paz County, Arizona white 57.4 ## 8 Maricopa County, Arizona white 55.2 ## 9 Mohave County, Arizona white 77.3 ## 10 Navajo County, Arizona native 43.5 ## 11 Pima County, Arizona white 51.7 ## 12 Pinal County, Arizona white 56.8 ## 13 Santa Cruz County, Arizona hispanic 83.5 ## 14 Yavapai County, Arizona white 80.5 ## 15 Yuma County, Arizona hispanic 63.8 az_race_percent %&gt;% group_by(variable) %&gt;% summarize(median_pct = median(percent)) ## # A tibble: 6 x 2 ## variable median_pct ## &lt;chr&gt; &lt;dbl&gt; ## 1 asian 0.924 ## 2 black 1.12 ## 3 HIPI 0.121 ## 4 hispanic 30.2 ## 5 native 3.58 ## 6 white 54.1 15.2.3 Margin of error considerations vars1 &lt;- paste0(&quot;B01001_0&quot;, c(20:25, 44:49)) salt_lake &lt;- get_acs( geography = &quot;tract&quot;, variables = vars1, state = &quot;Utah&quot;, county = &quot;Salt Lake&quot;, year = 2019 ) ## Getting data from the 2015-2019 5-year ACS example_tract &lt;- salt_lake %&gt;% filter(GEOID == &quot;49035100100&quot;) example_tract %&gt;% select(-NAME) ## # A tibble: 12 x 4 ## GEOID variable estimate moe ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 49035100100 B01001_020 12 13 ## 2 49035100100 B01001_021 36 23 ## 3 49035100100 B01001_022 8 11 ## 4 49035100100 B01001_023 5 8 ## 5 49035100100 B01001_024 0 11 ## 6 49035100100 B01001_025 22 23 ## 7 49035100100 B01001_044 0 11 ## 8 49035100100 B01001_045 11 13 ## 9 49035100100 B01001_046 27 20 ## 10 49035100100 B01001_047 10 12 ## 11 49035100100 B01001_048 7 11 ## 12 49035100100 B01001_049 0 11 tidycensus has multiple functions already built to make margin of error calculations more straigtforward when you are assembling calculated values from multiple variables each with their own margin of error. One of these functions is mod_prop(). Check out the help documentation to understand the following example: moe_prop(25,100, 5, 3) ## [1] 0.0494343 At 1 hour 52 minutes in the YouTube, a nice example to reduce margin of error by grouping small bins of data into larger bins is introduced. I do not take it up here. Exercises for 2nd break: mn_bachelors_and_up &lt;- get_acs( geography = &quot;county&quot;, state = &quot;MN&quot;, variables = &quot;DP02_0068P&quot;) ## Getting data from the 2015-2019 5-year ACS ## Using the ACS Data Profile mn_bachelors_and_up$estimate %&gt;% median() ## [1] 22.2 median(mn_bachelors_and_up$estimate) ## [1] 22.2 # mn_bachelors_and_up %&gt;% median() New goal: find the percentage of commuters taking public transit to work in the 20 most populous metropolitan areas. metros &lt;- get_acs( geography = &quot;cbsa&quot;, variables = &quot;DP03_0021P&quot;, summary_var = &quot;B01003_001&quot;, survey = &quot;acs1&quot; ) %&gt;% filter(min_rank(desc(summary_est)) &lt;21) ## The 1-year ACS provides data for geographies with populations of 65,000 and greater. ## Getting data from the 2019 1-year ACS ## Using the ACS Data Profile glimpse(metros) ## Rows: 20 ## Columns: 7 ## $ GEOID &lt;chr&gt; &quot;12060&quot;, &quot;14460&quot;, &quot;16980&quot;, &quot;19100&quot;, &quot;19740&quot;, &quot;19820&quot;, &quot;264… ## $ NAME &lt;chr&gt; &quot;Atlanta-Sandy Springs-Alpharetta, GA Metro Area&quot;, &quot;Boston… ## $ variable &lt;chr&gt; &quot;DP03_0021P&quot;, &quot;DP03_0021P&quot;, &quot;DP03_0021P&quot;, &quot;DP03_0021P&quot;, &quot;D… ## $ estimate &lt;dbl&gt; 2.8, 13.4, 12.4, 1.3, 4.5, 1.4, 2.0, 4.8, 2.9, 4.5, 31.6, … ## $ moe &lt;dbl&gt; 0.2, 0.4, 0.3, 0.1, 0.3, 0.2, 0.2, 0.1, 0.2, 0.2, 0.2, 0.3… ## $ summary_est &lt;dbl&gt; 6018744, 4873019, 9457867, 7573136, 2967239, 4319629, 7066… ## $ summary_moe &lt;dbl&gt; 3340, NA, 1469, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ggplot(data = metros, aes(x = NAME, y = estimate)) + geom_col() p &lt;- metros %&gt;% mutate(NAME = str_remove(NAME, &quot;-.*$&quot;)) %&gt;% mutate(NAME = str_remove(NAME, &quot;,.*$&quot;)) %&gt;% ggplot(aes(y = reorder(NAME, estimate), x = estimate)) + geom_col() p + theme_minimal() + labs(title = &quot;Nifty title&quot;, y = &quot;&quot;, x = &quot;acs estimate (percent)&quot;, caption = &quot;Nifty caption&quot;) 15.2.4 Visualizing margins of error maine_income &lt;- get_acs( state = &quot;Maine&quot;, geography = &quot;county&quot;, variables = c(hhincome = &quot;B19013_001&quot;)) %&gt;% mutate(NAME = str_remove(NAME, &quot; County, Maine&quot;)) ## Getting data from the 2015-2019 5-year ACS maine_income %&gt;% arrange(desc(moe)) ## # A tibble: 16 x 5 ## GEOID NAME variable estimate moe ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 23015 Lincoln hhincome 57720 3240 ## 2 23007 Franklin hhincome 51422 2966 ## 3 23013 Knox hhincome 57751 2820 ## 4 23021 Piscataquis hhincome 40890 2613 ## 5 23025 Somerset hhincome 44256 2591 ## 6 23023 Sagadahoc hhincome 63694 2309 ## 7 23027 Waldo hhincome 51931 2170 ## 8 23009 Hancock hhincome 57178 2057 ## 9 23011 Kennebec hhincome 55365 1948 ## 10 23017 Oxford hhincome 49204 1879 ## 11 23001 Androscoggin hhincome 53509 1770 ## 12 23029 Washington hhincome 41347 1565 ## 13 23031 York hhincome 67830 1450 ## 14 23005 Cumberland hhincome 73072 1427 ## 15 23003 Aroostook hhincome 41123 1381 ## 16 23019 Penobscot hhincome 50808 1326 maine_income %&gt;% ggplot( aes(x = estimate, y = reorder(NAME, estimate))) + geom_errorbarh(aes(xmin = estimate-moe, xmax = estimate+moe)) + geom_point(size = 3, color = &quot;darkgreen&quot;) + labs(title = &quot;Spiffy title&quot;, subtitle = &quot;Counites of Maine&quot;, x = &quot;2015-2019 ACS Estimate&quot;, y = &quot;&quot;) + scale_x_continuous(labels = scales::dollar) 15.2.5 get_estimates() and how to use them utah &lt;- get_estimates( geography = &quot;state&quot;, state = &quot;UT&quot;, product = &quot;characteristics&quot;, breakdown = c(&quot;SEX&quot;, &quot;AGEGROUP&quot;), breakdown_labels = TRUE, year = 2019 ) utah ## # A tibble: 96 x 5 ## GEOID NAME value SEX AGEGROUP ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;fct&gt; ## 1 49 Utah 3205958 Both sexes All ages ## 2 49 Utah 247803 Both sexes Age 0 to 4 years ## 3 49 Utah 258976 Both sexes Age 5 to 9 years ## 4 49 Utah 1614917 Male All ages ## 5 49 Utah 132868 Male Age 5 to 9 years ## 6 49 Utah 1591041 Female All ages ## 7 49 Utah 126108 Female Age 5 to 9 years ## 8 49 Utah 23039 Female Age 80 to 84 years ## 9 49 Utah 267985 Both sexes Age 10 to 14 years ## 10 49 Utah 137940 Male Age 10 to 14 years ## # … with 86 more rows utah_filtered &lt;- filter(utah, str_detect(AGEGROUP, &quot;^Age&quot;), SEX != &quot;Both sexes&quot;) %&gt;% mutate(value = ifelse(SEX == &quot;Male&quot;, -value, value)) utah_filtered ## # A tibble: 36 x 5 ## GEOID NAME value SEX AGEGROUP ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;fct&gt; ## 1 49 Utah -132868 Male Age 5 to 9 years ## 2 49 Utah 126108 Female Age 5 to 9 years ## 3 49 Utah 23039 Female Age 80 to 84 years ## 4 49 Utah -137940 Male Age 10 to 14 years ## 5 49 Utah -129312 Male Age 15 to 19 years ## 6 49 Utah 130045 Female Age 10 to 14 years ## 7 49 Utah 124535 Female Age 15 to 19 years ## 8 49 Utah -135806 Male Age 20 to 24 years ## 9 49 Utah 128846 Female Age 20 to 24 years ## 10 49 Utah -111776 Male Age 30 to 34 years ## # … with 26 more rows utah_filtered %&gt;% ggplot(aes(x = value, y = AGEGROUP, fill = SEX)) + geom_col() utah_pyramid &lt;- utah_filtered %&gt;% ggplot(aes(x = value, y = AGEGROUP, fill = SEX)) + geom_col(width = 0.95, alpha = 0.75)+ theme_minimal(base_family = &quot;Verdana&quot;) + scale_x_continuous(labels = function(y)paste0(abs(y/1000), &quot;k&quot;)) + scale_y_discrete(labels = function(x)gsub(&quot;Age|years&quot;, &quot;&quot;, x)) + scale_fill_manual(values = c(&quot;darkred&quot;, &quot;navy&quot;)) + labs(x = &quot;&quot;, y = &quot;2019 Census Bureau population estimate&quot;, title = &quot;Population Structure in Utah&quot;, fill = &quot;&quot;, caption = &quot;Data source: US Census Bureau population estimates and tidycensus R package&quot;) utah_pyramid ggplotly(utah_pyramid) 15.2.6 ggbeeswarm() automates some jitter considerations mn_race_income &lt;- get_acs( geography = &quot;tract&quot;, state = &quot;MN&quot;, county = c(&quot;Hennepin&quot;, &quot;Ramsey&quot;, &quot;Washington&quot;, &quot;Carver&quot;, &quot;Dakota&quot;, &quot;Anoka&quot;, &quot;Wright&quot;, &quot;Scott&quot;), variables = c(White = &quot;B03002_003&quot;, Black = &quot;B03002_004&quot;, Asian = &quot;B03002_006&quot;, Hispanic = &quot;B03002_012&quot;), summary_var = &quot;B19013_001&quot; ) %&gt;% group_by(GEOID) %&gt;% filter(estimate == max(estimate, na.rm = TRUE)) %&gt;% ungroup() %&gt;% filter(estimate != 0) ## Getting data from the 2015-2019 5-year ACS library(ggbeeswarm) mn_race_income %&gt;% ggplot(aes(x = variable, y = summary_est, color = summary_est)) + geom_quasirandom(alpha = 0.5) + coord_flip() + theme_minimal() + scale_color_viridis_c(guide = FALSE) + scale_y_continuous(labels = scales::dollar) + labs(x = &quot;Largest Group in Census Tract&quot;, y = &quot;Median Household Income&quot;, title = &quot;Household Income By Largest Race/Ethnic Group&quot;, subtitle = &quot;Census Tracts, Twin Cities Metro Area&quot;, caption = &quot;Data source: 2015-2019 ACS&quot;) ## Warning: Removed 3 rows containing missing values (position_quasirandom). "]]
