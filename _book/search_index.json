[["knncv.html", "Chapter 16 K Nearest Neighbors Revisited: Cross Validation Added Tips for This Document", " Chapter 16 K Nearest Neighbors Revisited: Cross Validation Added Tips for This Document library(caret) ## Loading required package: lattice ## ## Attaching package: &#39;caret&#39; ## The following object is masked from &#39;package:purrr&#39;: ## ## lift library(pROC) ## Type &#39;citation(&quot;pROC&quot;)&#39; for a citation. ## ## Attaching package: &#39;pROC&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## cov, smooth, var library(mlbench) library(tidyverse) library(MLmetrics) ## ## Attaching package: &#39;MLmetrics&#39; ## The following objects are masked from &#39;package:caret&#39;: ## ## MAE, RMSE ## The following object is masked from &#39;package:base&#39;: ## ## Recall theme_set(theme_minimal()) Good resource: https://www.r-bloggers.com/2021/04/knn-algorithm-machine-learning/?utm_source=feedburner&amp;utm_medium=email&amp;utm_campaign=Feed%3A+RBloggers+%28R+bloggers%29 An excellent source for the caret is https://topepo.github.io/caret/index.html The following code is from https://stats.stackexchange.com/questions/318968/knn-and-k-folding-in-r trControl &lt;- trainControl(method = &quot;cv&quot;, number = 5) fit &lt;- train(Species ~ ., method = &quot;knn&quot;, tuneGrid = expand.grid(k = 1:10), trControl = trControl, metric = &quot;Accuracy&quot;, data = iris) fit ## k-Nearest Neighbors ## ## 150 samples ## 4 predictor ## 3 classes: &#39;setosa&#39;, &#39;versicolor&#39;, &#39;virginica&#39; ## ## No pre-processing ## Resampling: Cross-Validated (5 fold) ## Summary of sample sizes: 120, 120, 120, 120, 120 ## Resampling results across tuning parameters: ## ## k Accuracy Kappa ## 1 0.9600000 0.94 ## 2 0.9466667 0.92 ## 3 0.9533333 0.93 ## 4 0.9533333 0.93 ## 5 0.9533333 0.93 ## 6 0.9466667 0.92 ## 7 0.9600000 0.94 ## 8 0.9666667 0.95 ## 9 0.9600000 0.94 ## 10 0.9600000 0.94 ## ## Accuracy was used to select the optimal model using the largest value. ## The final value used for the model was k = 8. plot(fit) I’d like to see whether this will help build a model to improve the classification of pituitary neuroendocrine tumors (pituitary adenomas). A copy of the patmandx data from PitAdTMA9.0 is already in the test book data directory. pit &lt;- read_csv(&quot;data/patmanDx.csv&quot;) ## ## ── Column specification ──────────────────────────────────────────────────────── ## cols( ## .default = col_double(), ## Dx = col_character(), ## SurgPathNo = col_character(), ## CAM5.2Pattern = col_character(), ## newDx = col_character(), ## finDx = col_character(), ## villaDx = col_character(), ## villaCode = col_character(), ## Note = col_character(), ## manDx = col_character(), ## OrigDx = col_character(), ## Sex = col_character(), ## ClinNotes = col_character() ## ) ## ℹ Use `spec()` for the full column specifications. df &lt;- pit %&gt;% select(SF1Median, Pit1Median, TPITMedian, PRLMedian, GHMedian, TSHMedian, LHMedian, FSHMedian, ACTHMedian, ASUMedian, GATA3Median, manDx) %&gt;% na.omit() table(df$manDx) ## ## ACTH GH GON NULL PIT1 PLUR PRL UNK ## 23 16 77 10 4 1 15 1 # Now, the trouble with null cell adenoma is that the diagnosis abbreviation &quot;NULL&quot; is mistaken for the NULL value. I&#39;ll need to change this. The following is an ugly way to do this. df &lt;- df %&gt;% mutate(manDx = case_when( manDx == &quot;NULL&quot; ~ &quot;Null&quot;, TRUE ~ manDx )) table(df$manDx) ## ## ACTH GH GON Null PIT1 PLUR PRL UNK ## 23 16 77 10 4 1 15 1 Now I’ll ape the code from above and see whether it works. trControl &lt;- trainControl(method = &quot;cv&quot;, number = 5) fit &lt;- train(manDx ~ ., method = &quot;knn&quot;, tuneGrid = expand.grid(k = 1:10), trControl = trControl, metric = &quot;Accuracy&quot;, data = df) ## Warning: predictions failed for Fold2: k= 1 Error in dimnames(x) &lt;- dn : ## length of &#39;dimnames&#39; [2] not equal to array extent ## Warning: predictions failed for Fold2: k= 2 Error in dimnames(x) &lt;- dn : ## length of &#39;dimnames&#39; [2] not equal to array extent ## Warning: predictions failed for Fold2: k= 3 Error in dimnames(x) &lt;- dn : ## length of &#39;dimnames&#39; [2] not equal to array extent ## Warning: predictions failed for Fold2: k= 4 Error in dimnames(x) &lt;- dn : ## length of &#39;dimnames&#39; [2] not equal to array extent ## Warning: predictions failed for Fold2: k= 5 Error in dimnames(x) &lt;- dn : ## length of &#39;dimnames&#39; [2] not equal to array extent ## Warning: predictions failed for Fold2: k= 6 Error in dimnames(x) &lt;- dn : ## length of &#39;dimnames&#39; [2] not equal to array extent ## Warning: predictions failed for Fold2: k= 7 Error in dimnames(x) &lt;- dn : ## length of &#39;dimnames&#39; [2] not equal to array extent ## Warning: predictions failed for Fold2: k= 8 Error in dimnames(x) &lt;- dn : ## length of &#39;dimnames&#39; [2] not equal to array extent ## Warning: predictions failed for Fold2: k= 9 Error in dimnames(x) &lt;- dn : ## length of &#39;dimnames&#39; [2] not equal to array extent ## Warning: predictions failed for Fold2: k=10 Error in dimnames(x) &lt;- dn : ## length of &#39;dimnames&#39; [2] not equal to array extent ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. fit ## k-Nearest Neighbors ## ## 147 samples ## 11 predictor ## 8 classes: &#39;ACTH&#39;, &#39;GH&#39;, &#39;GON&#39;, &#39;Null&#39;, &#39;PIT1&#39;, &#39;PLUR&#39;, &#39;PRL&#39;, &#39;UNK&#39; ## ## No pre-processing ## Resampling: Cross-Validated (5 fold) ## Summary of sample sizes: 118, 117, 118, 119, 116 ## Resampling results across tuning parameters: ## ## k Accuracy Kappa ## 1 0.9387315 0.9068413 ## 2 0.9048049 0.8518203 ## 3 0.9223542 0.8793651 ## 4 0.9301108 0.8917910 ## 5 0.9387315 0.9057871 ## 6 0.9217384 0.8805768 ## 7 0.9217384 0.8811790 ## 8 0.9306670 0.8930613 ## 9 0.9050532 0.8561589 ## 10 0.8964325 0.8424796 ## ## Accuracy was used to select the optimal model using the largest value. ## The final value used for the model was k = 5. plot(fit) Note that if I run this multiple times, I get multiple different optimal values of k. set.seed(1234)* would render a single, reproducible (if not “correct”) value. So ostensibly, this works, but I have a couple important items to address: A fundimental lack of understanding “what’s going on under the hood.” A bunch of warnings that I’m simply ignoring for now. I’ve inadvertently included more packages than necessary. These need to be weeded out. "]]
