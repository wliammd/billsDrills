[["modeling.html", "Chapter 17 Modeling 17.1 Modeling notes 17.2 Out of sample error example 17.3 A regression example from the course, this time using caret 17.4 Classification 17.5 From the DataCamp course 17.6 Random forest with caret 17.7 Random forest model and tuneGrid()", " Chapter 17 Modeling library(tidyverse) library(rpart) 17.1 Modeling notes Notes on/inspired by the Machine Learning with caret in R DataCamp course. I’d like to better understand machine learning, especially as it pertains to classification problems. Most discussions begin with regression examples, so these will also be addressed in order to build a better foundation. This is the general approach of James, Witten, Hastie and Tibshirani in An Introduction to Statistical Learning with Applications in R, too. But let’s back up and consider the whole rationale behind modeling: according to Haley Wickham in R4DS, The goal of a model is to provide a simple low-dimensional summary of a dataset. Modeling is a mode of supervised learning, which can be divided into classification and regression. Root mean squared error, RMSE, is an important concept in regression problems. For a review of what is meant by RMSE, see this Wikipedia page: https://en.wikipedia.org/wiki/Root-mean-square_deviation. The units RMSE are the same as the original data, so it is very interpretable. It’s worth taking a more careful look at RMSE, and practicing with it, to illustrate the underlying methods of regression before we get into caret. glimpse(diamonds) ## Rows: 53,940 ## Columns: 10 ## $ carat &lt;dbl&gt; 0.23, 0.21, 0.23, 0.29, 0.31, 0.24, 0.24, 0.26, 0.22, 0.23, 0.… ## $ cut &lt;ord&gt; Ideal, Premium, Good, Premium, Good, Very Good, Very Good, Ver… ## $ color &lt;ord&gt; E, E, E, I, J, J, I, H, E, H, J, J, F, J, E, E, I, J, J, J, I,… ## $ clarity &lt;ord&gt; SI2, SI1, VS1, VS2, SI2, VVS2, VVS1, SI1, VS2, VS1, SI1, VS1, … ## $ depth &lt;dbl&gt; 61.5, 59.8, 56.9, 62.4, 63.3, 62.8, 62.3, 61.9, 65.1, 59.4, 64… ## $ table &lt;dbl&gt; 55, 61, 65, 58, 58, 57, 57, 55, 61, 61, 55, 56, 61, 54, 62, 58… ## $ price &lt;int&gt; 326, 326, 327, 334, 335, 336, 336, 337, 337, 338, 339, 340, 34… ## $ x &lt;dbl&gt; 3.95, 3.89, 4.05, 4.20, 4.34, 3.94, 3.95, 4.07, 3.87, 4.00, 4.… ## $ y &lt;dbl&gt; 3.98, 3.84, 4.07, 4.23, 4.35, 3.96, 3.98, 4.11, 3.78, 4.05, 4.… ## $ z &lt;dbl&gt; 2.43, 2.31, 2.31, 2.63, 2.75, 2.48, 2.47, 2.53, 2.49, 2.39, 2.… # Fit lm model: model model&lt;-lm(price~., diamonds) # Predict on full data: p p&lt;-predict(model, diamonds) # Compute errors: error error&lt;-p-diamonds$price # Calculate RMSE sqrt(mean(error^2)) ## [1] 1129.843 Note that the RMSE in this case is $1129.84, which is in keeping with what we know about the price of diamonds, which range from $326 to $18823 and average $3932.8. Within-sample RMSE always overestimates model accuracy–the model only “knows” what it has encountered, not what the rest of the universe holds in store. Hence, out-of-sample data is checked with the model by some means. A separate “validation set” of sample points is provided (as we did when we moved from exploration to validation in our first pituitary adenoma paper). Zach Mayer states this another way: In-sample validation almost guarantees overfitting. So in the wide world and blue, this is perhaps the nicest intellectual defense of study abroad, of learning the perspectives, habits, and languages of others in order to avoid overfitting of our mental models to local norms. Sample size cannot always grow, however: samples are expensive. caret simulates the process of having a validation set and permits the progressive refinement of a model. 17.2 Out of sample error example This example from the DataCamp course divides diamonds into test and training sets. Note the assumptions that get built into the process: the use of 80% train/20% test, for instance. How does one arrive at this figure? # Set seed set.seed(42) # Shuffle row indices in case the data set is inhomogeneous: rows rows&lt;-sample(nrow(diamonds)) # Randomly order data shuffled_diamonds&lt;-diamonds[rows,] # Determine row to split on: split split&lt;-round(nrow(diamonds)*0.80) # Create train train&lt;-diamonds[1:split,] # Create test test&lt;-diamonds[(split+1):nrow(diamonds),] # Fit lm model on train: model model&lt;-lm(price~., train) # Predict on test: p p&lt;-predict(model, test) # Compute errors: error error &lt;- p - test$price # Calculate RMSE sqrt(mean(error^2)) ## [1] 796.8922 So the RMSE for the model of diamond price, as measured by dividing the set this way, is $796.89. 17.3 A regression example from the course, this time using caret Note that the train() function has the method characteristic that can choose the type of model and that the trainControl() function has a method that determines cross validation. The number characteristic refers to the number of folds of cross validation. 10-fold cross validation is common, but takes more time than the use of smaller numbers. 5-fold will be used here to improve the speed of the processing. library(caret) ## Loading required package: lattice ## ## Attaching package: &#39;caret&#39; ## The following object is masked from &#39;package:purrr&#39;: ## ## lift model &lt;- train( price~., diamonds, method = &quot;lm&quot;, trControl = trainControl( method = &quot;cv&quot;, number = 5, verboseIter = TRUE ) ) ## + Fold1: intercept=TRUE ## - Fold1: intercept=TRUE ## + Fold2: intercept=TRUE ## - Fold2: intercept=TRUE ## + Fold3: intercept=TRUE ## - Fold3: intercept=TRUE ## + Fold4: intercept=TRUE ## - Fold4: intercept=TRUE ## + Fold5: intercept=TRUE ## - Fold5: intercept=TRUE ## Aggregating results ## Fitting final model on full training set # Print model to console model ## Linear Regression ## ## 53940 samples ## 9 predictor ## ## No pre-processing ## Resampling: Cross-Validated (5 fold) ## Summary of sample sizes: 43152, 43152, 43152, 43152, 43152 ## Resampling results: ## ## RMSE Rsquared MAE ## 1137.965 0.9186084 741.3386 ## ## Tuning parameter &#39;intercept&#39; was held constant at a value of TRUE Note that caret handles the work of splitting test sets and calculating RMSE. Another example from the DataCamp course. library(MASS) ## ## Attaching package: &#39;MASS&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## select # Fit lm model using 5-fold CV: model model &lt;- train( medv~., Boston, method = &quot;lm&quot;, trControl = trainControl( method = &quot;cv&quot;, number = 5, verboseIter = TRUE ) ) ## + Fold1: intercept=TRUE ## - Fold1: intercept=TRUE ## + Fold2: intercept=TRUE ## - Fold2: intercept=TRUE ## + Fold3: intercept=TRUE ## - Fold3: intercept=TRUE ## + Fold4: intercept=TRUE ## - Fold4: intercept=TRUE ## + Fold5: intercept=TRUE ## - Fold5: intercept=TRUE ## Aggregating results ## Fitting final model on full training set # Print model to console model ## Linear Regression ## ## 506 samples ## 13 predictor ## ## No pre-processing ## Resampling: Cross-Validated (5 fold) ## Summary of sample sizes: 405, 405, 405, 403, 406 ## Resampling results: ## ## RMSE Rsquared MAE ## 4.811293 0.7238097 3.375276 ## ## Tuning parameter &#39;intercept&#39; was held constant at a value of TRUE Cross validation can itself be repeated. The following is a 5-fold cross validation repeated 5 times. # Fit lm model using 5 x 5-fold CV: model model &lt;- train( medv ~ ., Boston, method = &quot;lm&quot;, trControl = trainControl( method = &quot;repeatedcv&quot;, number = 5, repeats = 5, verboseIter = TRUE ) ) ## + Fold1.Rep1: intercept=TRUE ## - Fold1.Rep1: intercept=TRUE ## + Fold2.Rep1: intercept=TRUE ## - Fold2.Rep1: intercept=TRUE ## + Fold3.Rep1: intercept=TRUE ## - Fold3.Rep1: intercept=TRUE ## + Fold4.Rep1: intercept=TRUE ## - Fold4.Rep1: intercept=TRUE ## + Fold5.Rep1: intercept=TRUE ## - Fold5.Rep1: intercept=TRUE ## + Fold1.Rep2: intercept=TRUE ## - Fold1.Rep2: intercept=TRUE ## + Fold2.Rep2: intercept=TRUE ## - Fold2.Rep2: intercept=TRUE ## + Fold3.Rep2: intercept=TRUE ## - Fold3.Rep2: intercept=TRUE ## + Fold4.Rep2: intercept=TRUE ## - Fold4.Rep2: intercept=TRUE ## + Fold5.Rep2: intercept=TRUE ## - Fold5.Rep2: intercept=TRUE ## + Fold1.Rep3: intercept=TRUE ## - Fold1.Rep3: intercept=TRUE ## + Fold2.Rep3: intercept=TRUE ## - Fold2.Rep3: intercept=TRUE ## + Fold3.Rep3: intercept=TRUE ## - Fold3.Rep3: intercept=TRUE ## + Fold4.Rep3: intercept=TRUE ## - Fold4.Rep3: intercept=TRUE ## + Fold5.Rep3: intercept=TRUE ## - Fold5.Rep3: intercept=TRUE ## + Fold1.Rep4: intercept=TRUE ## - Fold1.Rep4: intercept=TRUE ## + Fold2.Rep4: intercept=TRUE ## - Fold2.Rep4: intercept=TRUE ## + Fold3.Rep4: intercept=TRUE ## - Fold3.Rep4: intercept=TRUE ## + Fold4.Rep4: intercept=TRUE ## - Fold4.Rep4: intercept=TRUE ## + Fold5.Rep4: intercept=TRUE ## - Fold5.Rep4: intercept=TRUE ## + Fold1.Rep5: intercept=TRUE ## - Fold1.Rep5: intercept=TRUE ## + Fold2.Rep5: intercept=TRUE ## - Fold2.Rep5: intercept=TRUE ## + Fold3.Rep5: intercept=TRUE ## - Fold3.Rep5: intercept=TRUE ## + Fold4.Rep5: intercept=TRUE ## - Fold4.Rep5: intercept=TRUE ## + Fold5.Rep5: intercept=TRUE ## - Fold5.Rep5: intercept=TRUE ## Aggregating results ## Fitting final model on full training set # Print model to console model ## Linear Regression ## ## 506 samples ## 13 predictor ## ## No pre-processing ## Resampling: Cross-Validated (5 fold, repeated 5 times) ## Summary of sample sizes: 405, 404, 404, 406, 405, 405, ... ## Resampling results: ## ## RMSE Rsquared MAE ## 4.8764 0.722424 3.421333 ## ## Tuning parameter &#39;intercept&#39; was held constant at a value of TRUE p &lt;- predict(model, Boston) error &lt;- p - Boston$medv sqrt(mean(error^2)) ## [1] 4.679191 17.4 Classification 17.4.1 An rpart classification example. model &lt;- rpart( Species ~ ., data = iris, method = &quot;class&quot; ) predicted &lt;- predict(model, iris, type = &quot;class&quot;) predicted ## 1 2 3 4 5 6 7 ## setosa setosa setosa setosa setosa setosa setosa ## 8 9 10 11 12 13 14 ## setosa setosa setosa setosa setosa setosa setosa ## 15 16 17 18 19 20 21 ## setosa setosa setosa setosa setosa setosa setosa ## 22 23 24 25 26 27 28 ## setosa setosa setosa setosa setosa setosa setosa ## 29 30 31 32 33 34 35 ## setosa setosa setosa setosa setosa setosa setosa ## 36 37 38 39 40 41 42 ## setosa setosa setosa setosa setosa setosa setosa ## 43 44 45 46 47 48 49 ## setosa setosa setosa setosa setosa setosa setosa ## 50 51 52 53 54 55 56 ## setosa versicolor versicolor versicolor versicolor versicolor versicolor ## 57 58 59 60 61 62 63 ## versicolor versicolor versicolor versicolor versicolor versicolor versicolor ## 64 65 66 67 68 69 70 ## versicolor versicolor versicolor versicolor versicolor versicolor versicolor ## 71 72 73 74 75 76 77 ## virginica versicolor versicolor versicolor versicolor versicolor versicolor ## 78 79 80 81 82 83 84 ## versicolor versicolor versicolor versicolor versicolor versicolor versicolor ## 85 86 87 88 89 90 91 ## versicolor versicolor versicolor versicolor versicolor versicolor versicolor ## 92 93 94 95 96 97 98 ## versicolor versicolor versicolor versicolor versicolor versicolor versicolor ## 99 100 101 102 103 104 105 ## versicolor versicolor virginica virginica virginica virginica virginica ## 106 107 108 109 110 111 112 ## virginica versicolor virginica virginica virginica virginica virginica ## 113 114 115 116 117 118 119 ## virginica virginica virginica virginica virginica virginica virginica ## 120 121 122 123 124 125 126 ## versicolor virginica virginica virginica virginica virginica virginica ## 127 128 129 130 131 132 133 ## virginica virginica virginica versicolor virginica virginica virginica ## 134 135 136 137 138 139 140 ## versicolor versicolor virginica virginica virginica virginica virginica ## 141 142 143 144 145 146 147 ## virginica virginica virginica virginica virginica virginica virginica ## 148 149 150 ## virginica virginica virginica ## Levels: setosa versicolor virginica Study what’s going on in predict(): ?predict.rpart So predict() uses the model to assign a predicted value to Species based on the rest of the iris dataset data. The accuracy of this prediction can be tested by comparing this vector to the original Species. mean(predicted == iris$Species) ## [1] 0.96 17.5 From the DataCamp course library(mlbench) data(&quot;Sonar&quot;) # First randomize the dataset. rows &lt;- sample(nrow(Sonar)) Sonar &lt;- Sonar[rows,] # The split it into testing and training sets. split &lt;- round(nrow(Sonar)*0.60) train &lt;- Sonar[1:split,] test &lt;- Sonar[(split+1):nrow(Sonar),] nrow(train)/nrow(Sonar) ## [1] 0.6009615 model &lt;- glm( Class ~ ., family = binomial(link = &quot;logit&quot;), train ) ## Warning: glm.fit: algorithm did not converge ## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred p &lt;- predict(model, test, type = &quot;response&quot;) summary(p) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.000000 0.000000 0.002428 0.438835 1.000000 1.000000 plot(p) p_class &lt;- as.factor(ifelse(p &gt; 0.1, &quot;M&quot;, &quot;R&quot;)) table(p_class, test[[&quot;Class&quot;]]) ## ## p_class M R ## M 11 26 ## R 35 11 confusionMatrix(p_class, test[[&quot;Class&quot;]]) ## Confusion Matrix and Statistics ## ## Reference ## Prediction M R ## M 11 26 ## R 35 11 ## ## Accuracy : 0.2651 ## 95% CI : (0.1742, 0.3734) ## No Information Rate : 0.5542 ## P-Value [Acc &gt; NIR] : 1.0000 ## ## Kappa : -0.4528 ## ## Mcnemar&#39;s Test P-Value : 0.3057 ## ## Sensitivity : 0.2391 ## Specificity : 0.2973 ## Pos Pred Value : 0.2973 ## Neg Pred Value : 0.2391 ## Prevalence : 0.5542 ## Detection Rate : 0.1325 ## Detection Prevalence : 0.4458 ## Balanced Accuracy : 0.2682 ## ## &#39;Positive&#39; Class : M ## According to Zach Mayer in DataCamp, manually evaluating classification threshholds is hard work and arbitrary: one would need to create dozens or hundreds of confusion matrices and then manually inspect them. Receiver operator curves add a new level of complexity and usefulness. To illustrate, we take the predicted probability of each Class for each case of the test set, and compare it with its actual Class: library(caTools) colAUC(p, test[[&quot;Class&quot;]], plotROC = TRUE) ## [,1] ## M vs. R 0.7532315 trainControl() in caret can use AUC (instead of accuracy), to tune the parameters of your models. The twoClassSummary() convenience function allows you to do this easily. When using twoClassSummary(), be sure to always include the argument classProbs = TRUE or your model will throw an error! (You cannot calculate AUC with just class predictions. You need to have class probabilities as well.) # Create trainControl object: myControl myControl &lt;- trainControl( method = &quot;cv&quot;, number = 10, summaryFunction = twoClassSummary, classProbs = TRUE, # IMPORTANT! verboseIter = TRUE ) # Train glm with custom trainControl: model model&lt;-train(Class~., data=Sonar, method=&quot;glm&quot;, trControl=myControl) ## Warning in train.default(x, y, weights = w, ...): The metric &quot;Accuracy&quot; was not ## in the result set. ROC will be used instead. ## + Fold01: parameter=none ## Warning: glm.fit: algorithm did not converge ## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred ## - Fold01: parameter=none ## + Fold02: parameter=none ## Warning: glm.fit: algorithm did not converge ## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred ## - Fold02: parameter=none ## + Fold03: parameter=none ## Warning: glm.fit: algorithm did not converge ## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred ## - Fold03: parameter=none ## + Fold04: parameter=none ## Warning: glm.fit: algorithm did not converge ## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred ## - Fold04: parameter=none ## + Fold05: parameter=none ## Warning: glm.fit: algorithm did not converge ## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred ## - Fold05: parameter=none ## + Fold06: parameter=none ## Warning: glm.fit: algorithm did not converge ## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred ## - Fold06: parameter=none ## + Fold07: parameter=none ## Warning: glm.fit: algorithm did not converge ## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred ## - Fold07: parameter=none ## + Fold08: parameter=none ## Warning: glm.fit: algorithm did not converge ## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred ## - Fold08: parameter=none ## + Fold09: parameter=none ## Warning: glm.fit: algorithm did not converge ## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred ## - Fold09: parameter=none ## + Fold10: parameter=none ## Warning: glm.fit: algorithm did not converge ## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred ## - Fold10: parameter=none ## Aggregating results ## Fitting final model on full training set ## Warning: glm.fit: algorithm did not converge ## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred # Print model to console model ## Generalized Linear Model ## ## 208 samples ## 60 predictor ## 2 classes: &#39;M&#39;, &#39;R&#39; ## ## No pre-processing ## Resampling: Cross-Validated (10 fold) ## Summary of sample sizes: 187, 187, 186, 188, 188, 187, ... ## Resampling results: ## ## ROC Sens Spec ## 0.7221086 0.7378788 0.67 So twoClassSummary to use AUC to tune the parameters for the model generates a much more accurate model than our random assignment for p. 17.6 Random forest with caret For this set, we’ll use the white wine quality data set from UC Irvine. wine &lt;- read.csv(&quot;http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv&quot;, sep = &quot;;&quot;) glimpse(wine) ## Rows: 4,898 ## Columns: 12 ## $ fixed.acidity &lt;dbl&gt; 7.0, 6.3, 8.1, 7.2, 7.2, 8.1, 6.2, 7.0, 6.3, 8.1,… ## $ volatile.acidity &lt;dbl&gt; 0.27, 0.30, 0.28, 0.23, 0.23, 0.28, 0.32, 0.27, 0… ## $ citric.acid &lt;dbl&gt; 0.36, 0.34, 0.40, 0.32, 0.32, 0.40, 0.16, 0.36, 0… ## $ residual.sugar &lt;dbl&gt; 20.70, 1.60, 6.90, 8.50, 8.50, 6.90, 7.00, 20.70,… ## $ chlorides &lt;dbl&gt; 0.045, 0.049, 0.050, 0.058, 0.058, 0.050, 0.045, … ## $ free.sulfur.dioxide &lt;dbl&gt; 45, 14, 30, 47, 47, 30, 30, 45, 14, 28, 11, 17, 1… ## $ total.sulfur.dioxide &lt;dbl&gt; 170, 132, 97, 186, 186, 97, 136, 170, 132, 129, 6… ## $ density &lt;dbl&gt; 1.0010, 0.9940, 0.9951, 0.9956, 0.9956, 0.9951, 0… ## $ pH &lt;dbl&gt; 3.00, 3.30, 3.26, 3.19, 3.19, 3.26, 3.18, 3.00, 3… ## $ sulphates &lt;dbl&gt; 0.45, 0.49, 0.44, 0.40, 0.40, 0.44, 0.47, 0.45, 0… ## $ alcohol &lt;dbl&gt; 8.8, 9.5, 10.1, 9.9, 9.9, 10.1, 9.6, 8.8, 9.5, 11… ## $ quality &lt;int&gt; 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 7, 5, 7, 6… # Note that quality is an integer, not a factor. **caret** seems to take this in stride. # Fit random forest: model model &lt;- train( quality~., tuneLength = 1, data = wine, method = &quot;ranger&quot;, trControl = trainControl( method = &quot;cv&quot;, number = 5, verboseIter = TRUE ) ) ## + Fold1: mtry=3, min.node.size=5, splitrule=variance ## - Fold1: mtry=3, min.node.size=5, splitrule=variance ## + Fold1: mtry=3, min.node.size=5, splitrule=extratrees ## - Fold1: mtry=3, min.node.size=5, splitrule=extratrees ## + Fold2: mtry=3, min.node.size=5, splitrule=variance ## - Fold2: mtry=3, min.node.size=5, splitrule=variance ## + Fold2: mtry=3, min.node.size=5, splitrule=extratrees ## - Fold2: mtry=3, min.node.size=5, splitrule=extratrees ## + Fold3: mtry=3, min.node.size=5, splitrule=variance ## - Fold3: mtry=3, min.node.size=5, splitrule=variance ## + Fold3: mtry=3, min.node.size=5, splitrule=extratrees ## - Fold3: mtry=3, min.node.size=5, splitrule=extratrees ## + Fold4: mtry=3, min.node.size=5, splitrule=variance ## - Fold4: mtry=3, min.node.size=5, splitrule=variance ## + Fold4: mtry=3, min.node.size=5, splitrule=extratrees ## - Fold4: mtry=3, min.node.size=5, splitrule=extratrees ## + Fold5: mtry=3, min.node.size=5, splitrule=variance ## - Fold5: mtry=3, min.node.size=5, splitrule=variance ## + Fold5: mtry=3, min.node.size=5, splitrule=extratrees ## - Fold5: mtry=3, min.node.size=5, splitrule=extratrees ## Aggregating results ## Selecting tuning parameters ## Fitting mtry = 3, splitrule = variance, min.node.size = 5 on full training set # Print model to console model ## Random Forest ## ## 4898 samples ## 11 predictor ## ## No pre-processing ## Resampling: Cross-Validated (5 fold) ## Summary of sample sizes: 3918, 3918, 3919, 3919, 3918 ## Resampling results across tuning parameters: ## ## splitrule RMSE Rsquared MAE ## variance 0.6050967 0.5413882 0.4391071 ## extratrees 0.6153818 0.5364792 0.4578305 ## ## Tuning parameter &#39;mtry&#39; was held constant at a value of 3 ## Tuning ## parameter &#39;min.node.size&#39; was held constant at a value of 5 ## RMSE was used to select the optimal model using the smallest value. ## The final values used for the model were mtry = 3, splitrule = variance ## and min.node.size = 5. plot(model) Let’s try this again with a longer tuneLength. This explores more models and potentially finds a better model. model &lt;- train( quality~., tuneLength = 10, data = wine, method = &quot;ranger&quot;, trControl = trainControl( method = &quot;cv&quot;, number = 5, verboseIter = TRUE ) ) ## + Fold1: mtry= 2, min.node.size=5, splitrule=variance ## - Fold1: mtry= 2, min.node.size=5, splitrule=variance ## + Fold1: mtry= 3, min.node.size=5, splitrule=variance ## - Fold1: mtry= 3, min.node.size=5, splitrule=variance ## + Fold1: mtry= 4, min.node.size=5, splitrule=variance ## - Fold1: mtry= 4, min.node.size=5, splitrule=variance ## + Fold1: mtry= 5, min.node.size=5, splitrule=variance ## - Fold1: mtry= 5, min.node.size=5, splitrule=variance ## + Fold1: mtry= 6, min.node.size=5, splitrule=variance ## - Fold1: mtry= 6, min.node.size=5, splitrule=variance ## + Fold1: mtry= 7, min.node.size=5, splitrule=variance ## - Fold1: mtry= 7, min.node.size=5, splitrule=variance ## + Fold1: mtry= 8, min.node.size=5, splitrule=variance ## - Fold1: mtry= 8, min.node.size=5, splitrule=variance ## + Fold1: mtry= 9, min.node.size=5, splitrule=variance ## - Fold1: mtry= 9, min.node.size=5, splitrule=variance ## + Fold1: mtry=10, min.node.size=5, splitrule=variance ## - Fold1: mtry=10, min.node.size=5, splitrule=variance ## + Fold1: mtry=11, min.node.size=5, splitrule=variance ## - Fold1: mtry=11, min.node.size=5, splitrule=variance ## + Fold1: mtry= 2, min.node.size=5, splitrule=extratrees ## - Fold1: mtry= 2, min.node.size=5, splitrule=extratrees ## + Fold1: mtry= 3, min.node.size=5, splitrule=extratrees ## - Fold1: mtry= 3, min.node.size=5, splitrule=extratrees ## + Fold1: mtry= 4, min.node.size=5, splitrule=extratrees ## - Fold1: mtry= 4, min.node.size=5, splitrule=extratrees ## + Fold1: mtry= 5, min.node.size=5, splitrule=extratrees ## - Fold1: mtry= 5, min.node.size=5, splitrule=extratrees ## + Fold1: mtry= 6, min.node.size=5, splitrule=extratrees ## - Fold1: mtry= 6, min.node.size=5, splitrule=extratrees ## + Fold1: mtry= 7, min.node.size=5, splitrule=extratrees ## - Fold1: mtry= 7, min.node.size=5, splitrule=extratrees ## + Fold1: mtry= 8, min.node.size=5, splitrule=extratrees ## - Fold1: mtry= 8, min.node.size=5, splitrule=extratrees ## + Fold1: mtry= 9, min.node.size=5, splitrule=extratrees ## - Fold1: mtry= 9, min.node.size=5, splitrule=extratrees ## + Fold1: mtry=10, min.node.size=5, splitrule=extratrees ## - Fold1: mtry=10, min.node.size=5, splitrule=extratrees ## + Fold1: mtry=11, min.node.size=5, splitrule=extratrees ## - Fold1: mtry=11, min.node.size=5, splitrule=extratrees ## + Fold2: mtry= 2, min.node.size=5, splitrule=variance ## - Fold2: mtry= 2, min.node.size=5, splitrule=variance ## + Fold2: mtry= 3, min.node.size=5, splitrule=variance ## - Fold2: mtry= 3, min.node.size=5, splitrule=variance ## + Fold2: mtry= 4, min.node.size=5, splitrule=variance ## - Fold2: mtry= 4, min.node.size=5, splitrule=variance ## + Fold2: mtry= 5, min.node.size=5, splitrule=variance ## - Fold2: mtry= 5, min.node.size=5, splitrule=variance ## + Fold2: mtry= 6, min.node.size=5, splitrule=variance ## - Fold2: mtry= 6, min.node.size=5, splitrule=variance ## + Fold2: mtry= 7, min.node.size=5, splitrule=variance ## - Fold2: mtry= 7, min.node.size=5, splitrule=variance ## + Fold2: mtry= 8, min.node.size=5, splitrule=variance ## - Fold2: mtry= 8, min.node.size=5, splitrule=variance ## + Fold2: mtry= 9, min.node.size=5, splitrule=variance ## - Fold2: mtry= 9, min.node.size=5, splitrule=variance ## + Fold2: mtry=10, min.node.size=5, splitrule=variance ## - Fold2: mtry=10, min.node.size=5, splitrule=variance ## + Fold2: mtry=11, min.node.size=5, splitrule=variance ## - Fold2: mtry=11, min.node.size=5, splitrule=variance ## + Fold2: mtry= 2, min.node.size=5, splitrule=extratrees ## - Fold2: mtry= 2, min.node.size=5, splitrule=extratrees ## + Fold2: mtry= 3, min.node.size=5, splitrule=extratrees ## - Fold2: mtry= 3, min.node.size=5, splitrule=extratrees ## + Fold2: mtry= 4, min.node.size=5, splitrule=extratrees ## - Fold2: mtry= 4, min.node.size=5, splitrule=extratrees ## + Fold2: mtry= 5, min.node.size=5, splitrule=extratrees ## - Fold2: mtry= 5, min.node.size=5, splitrule=extratrees ## + Fold2: mtry= 6, min.node.size=5, splitrule=extratrees ## - Fold2: mtry= 6, min.node.size=5, splitrule=extratrees ## + Fold2: mtry= 7, min.node.size=5, splitrule=extratrees ## - Fold2: mtry= 7, min.node.size=5, splitrule=extratrees ## + Fold2: mtry= 8, min.node.size=5, splitrule=extratrees ## - Fold2: mtry= 8, min.node.size=5, splitrule=extratrees ## + Fold2: mtry= 9, min.node.size=5, splitrule=extratrees ## - Fold2: mtry= 9, min.node.size=5, splitrule=extratrees ## + Fold2: mtry=10, min.node.size=5, splitrule=extratrees ## - Fold2: mtry=10, min.node.size=5, splitrule=extratrees ## + Fold2: mtry=11, min.node.size=5, splitrule=extratrees ## - Fold2: mtry=11, min.node.size=5, splitrule=extratrees ## + Fold3: mtry= 2, min.node.size=5, splitrule=variance ## - Fold3: mtry= 2, min.node.size=5, splitrule=variance ## + Fold3: mtry= 3, min.node.size=5, splitrule=variance ## - Fold3: mtry= 3, min.node.size=5, splitrule=variance ## + Fold3: mtry= 4, min.node.size=5, splitrule=variance ## - Fold3: mtry= 4, min.node.size=5, splitrule=variance ## + Fold3: mtry= 5, min.node.size=5, splitrule=variance ## - Fold3: mtry= 5, min.node.size=5, splitrule=variance ## + Fold3: mtry= 6, min.node.size=5, splitrule=variance ## - Fold3: mtry= 6, min.node.size=5, splitrule=variance ## + Fold3: mtry= 7, min.node.size=5, splitrule=variance ## - Fold3: mtry= 7, min.node.size=5, splitrule=variance ## + Fold3: mtry= 8, min.node.size=5, splitrule=variance ## - Fold3: mtry= 8, min.node.size=5, splitrule=variance ## + Fold3: mtry= 9, min.node.size=5, splitrule=variance ## - Fold3: mtry= 9, min.node.size=5, splitrule=variance ## + Fold3: mtry=10, min.node.size=5, splitrule=variance ## - Fold3: mtry=10, min.node.size=5, splitrule=variance ## + Fold3: mtry=11, min.node.size=5, splitrule=variance ## - Fold3: mtry=11, min.node.size=5, splitrule=variance ## + Fold3: mtry= 2, min.node.size=5, splitrule=extratrees ## - Fold3: mtry= 2, min.node.size=5, splitrule=extratrees ## + Fold3: mtry= 3, min.node.size=5, splitrule=extratrees ## - Fold3: mtry= 3, min.node.size=5, splitrule=extratrees ## + Fold3: mtry= 4, min.node.size=5, splitrule=extratrees ## - Fold3: mtry= 4, min.node.size=5, splitrule=extratrees ## + Fold3: mtry= 5, min.node.size=5, splitrule=extratrees ## - Fold3: mtry= 5, min.node.size=5, splitrule=extratrees ## + Fold3: mtry= 6, min.node.size=5, splitrule=extratrees ## - Fold3: mtry= 6, min.node.size=5, splitrule=extratrees ## + Fold3: mtry= 7, min.node.size=5, splitrule=extratrees ## - Fold3: mtry= 7, min.node.size=5, splitrule=extratrees ## + Fold3: mtry= 8, min.node.size=5, splitrule=extratrees ## - Fold3: mtry= 8, min.node.size=5, splitrule=extratrees ## + Fold3: mtry= 9, min.node.size=5, splitrule=extratrees ## - Fold3: mtry= 9, min.node.size=5, splitrule=extratrees ## + Fold3: mtry=10, min.node.size=5, splitrule=extratrees ## - Fold3: mtry=10, min.node.size=5, splitrule=extratrees ## + Fold3: mtry=11, min.node.size=5, splitrule=extratrees ## - Fold3: mtry=11, min.node.size=5, splitrule=extratrees ## + Fold4: mtry= 2, min.node.size=5, splitrule=variance ## - Fold4: mtry= 2, min.node.size=5, splitrule=variance ## + Fold4: mtry= 3, min.node.size=5, splitrule=variance ## - Fold4: mtry= 3, min.node.size=5, splitrule=variance ## + Fold4: mtry= 4, min.node.size=5, splitrule=variance ## - Fold4: mtry= 4, min.node.size=5, splitrule=variance ## + Fold4: mtry= 5, min.node.size=5, splitrule=variance ## - Fold4: mtry= 5, min.node.size=5, splitrule=variance ## + Fold4: mtry= 6, min.node.size=5, splitrule=variance ## - Fold4: mtry= 6, min.node.size=5, splitrule=variance ## + Fold4: mtry= 7, min.node.size=5, splitrule=variance ## - Fold4: mtry= 7, min.node.size=5, splitrule=variance ## + Fold4: mtry= 8, min.node.size=5, splitrule=variance ## - Fold4: mtry= 8, min.node.size=5, splitrule=variance ## + Fold4: mtry= 9, min.node.size=5, splitrule=variance ## - Fold4: mtry= 9, min.node.size=5, splitrule=variance ## + Fold4: mtry=10, min.node.size=5, splitrule=variance ## - Fold4: mtry=10, min.node.size=5, splitrule=variance ## + Fold4: mtry=11, min.node.size=5, splitrule=variance ## - Fold4: mtry=11, min.node.size=5, splitrule=variance ## + Fold4: mtry= 2, min.node.size=5, splitrule=extratrees ## - Fold4: mtry= 2, min.node.size=5, splitrule=extratrees ## + Fold4: mtry= 3, min.node.size=5, splitrule=extratrees ## - Fold4: mtry= 3, min.node.size=5, splitrule=extratrees ## + Fold4: mtry= 4, min.node.size=5, splitrule=extratrees ## - Fold4: mtry= 4, min.node.size=5, splitrule=extratrees ## + Fold4: mtry= 5, min.node.size=5, splitrule=extratrees ## - Fold4: mtry= 5, min.node.size=5, splitrule=extratrees ## + Fold4: mtry= 6, min.node.size=5, splitrule=extratrees ## - Fold4: mtry= 6, min.node.size=5, splitrule=extratrees ## + Fold4: mtry= 7, min.node.size=5, splitrule=extratrees ## - Fold4: mtry= 7, min.node.size=5, splitrule=extratrees ## + Fold4: mtry= 8, min.node.size=5, splitrule=extratrees ## - Fold4: mtry= 8, min.node.size=5, splitrule=extratrees ## + Fold4: mtry= 9, min.node.size=5, splitrule=extratrees ## - Fold4: mtry= 9, min.node.size=5, splitrule=extratrees ## + Fold4: mtry=10, min.node.size=5, splitrule=extratrees ## - Fold4: mtry=10, min.node.size=5, splitrule=extratrees ## + Fold4: mtry=11, min.node.size=5, splitrule=extratrees ## - Fold4: mtry=11, min.node.size=5, splitrule=extratrees ## + Fold5: mtry= 2, min.node.size=5, splitrule=variance ## - Fold5: mtry= 2, min.node.size=5, splitrule=variance ## + Fold5: mtry= 3, min.node.size=5, splitrule=variance ## - Fold5: mtry= 3, min.node.size=5, splitrule=variance ## + Fold5: mtry= 4, min.node.size=5, splitrule=variance ## - Fold5: mtry= 4, min.node.size=5, splitrule=variance ## + Fold5: mtry= 5, min.node.size=5, splitrule=variance ## - Fold5: mtry= 5, min.node.size=5, splitrule=variance ## + Fold5: mtry= 6, min.node.size=5, splitrule=variance ## - Fold5: mtry= 6, min.node.size=5, splitrule=variance ## + Fold5: mtry= 7, min.node.size=5, splitrule=variance ## - Fold5: mtry= 7, min.node.size=5, splitrule=variance ## + Fold5: mtry= 8, min.node.size=5, splitrule=variance ## - Fold5: mtry= 8, min.node.size=5, splitrule=variance ## + Fold5: mtry= 9, min.node.size=5, splitrule=variance ## - Fold5: mtry= 9, min.node.size=5, splitrule=variance ## + Fold5: mtry=10, min.node.size=5, splitrule=variance ## - Fold5: mtry=10, min.node.size=5, splitrule=variance ## + Fold5: mtry=11, min.node.size=5, splitrule=variance ## - Fold5: mtry=11, min.node.size=5, splitrule=variance ## + Fold5: mtry= 2, min.node.size=5, splitrule=extratrees ## - Fold5: mtry= 2, min.node.size=5, splitrule=extratrees ## + Fold5: mtry= 3, min.node.size=5, splitrule=extratrees ## - Fold5: mtry= 3, min.node.size=5, splitrule=extratrees ## + Fold5: mtry= 4, min.node.size=5, splitrule=extratrees ## - Fold5: mtry= 4, min.node.size=5, splitrule=extratrees ## + Fold5: mtry= 5, min.node.size=5, splitrule=extratrees ## - Fold5: mtry= 5, min.node.size=5, splitrule=extratrees ## + Fold5: mtry= 6, min.node.size=5, splitrule=extratrees ## - Fold5: mtry= 6, min.node.size=5, splitrule=extratrees ## + Fold5: mtry= 7, min.node.size=5, splitrule=extratrees ## - Fold5: mtry= 7, min.node.size=5, splitrule=extratrees ## + Fold5: mtry= 8, min.node.size=5, splitrule=extratrees ## - Fold5: mtry= 8, min.node.size=5, splitrule=extratrees ## + Fold5: mtry= 9, min.node.size=5, splitrule=extratrees ## - Fold5: mtry= 9, min.node.size=5, splitrule=extratrees ## + Fold5: mtry=10, min.node.size=5, splitrule=extratrees ## - Fold5: mtry=10, min.node.size=5, splitrule=extratrees ## + Fold5: mtry=11, min.node.size=5, splitrule=extratrees ## - Fold5: mtry=11, min.node.size=5, splitrule=extratrees ## Aggregating results ## Selecting tuning parameters ## Fitting mtry = 4, splitrule = variance, min.node.size = 5 on full training set # Print model to console model ## Random Forest ## ## 4898 samples ## 11 predictor ## ## No pre-processing ## Resampling: Cross-Validated (5 fold) ## Summary of sample sizes: 3919, 3918, 3918, 3918, 3919 ## Resampling results across tuning parameters: ## ## mtry splitrule RMSE Rsquared MAE ## 2 variance 0.6057267 0.5439626 0.4405916 ## 2 extratrees 0.6236281 0.5298696 0.4653787 ## 3 variance 0.6046583 0.5423307 0.4382451 ## 3 extratrees 0.6156828 0.5361785 0.4564330 ## 4 variance 0.6043205 0.5415035 0.4369536 ## 4 extratrees 0.6121588 0.5385053 0.4515880 ## 5 variance 0.6055318 0.5381417 0.4372017 ## 5 extratrees 0.6105919 0.5382888 0.4489989 ## 6 variance 0.6059000 0.5371010 0.4376776 ## 6 extratrees 0.6100430 0.5376337 0.4473954 ## 7 variance 0.6053503 0.5373499 0.4365124 ## 7 extratrees 0.6103668 0.5356061 0.4465320 ## 8 variance 0.6058807 0.5364227 0.4372000 ## 8 extratrees 0.6088559 0.5371926 0.4442014 ## 9 variance 0.6084825 0.5316505 0.4382170 ## 9 extratrees 0.6090639 0.5360376 0.4442829 ## 10 variance 0.6093909 0.5296893 0.4394500 ## 10 extratrees 0.6095042 0.5344968 0.4435984 ## 11 variance 0.6096074 0.5291148 0.4389384 ## 11 extratrees 0.6088682 0.5352417 0.4435641 ## ## Tuning parameter &#39;min.node.size&#39; was held constant at a value of 5 ## RMSE was used to select the optimal model using the smallest value. ## The final values used for the model were mtry = 4, splitrule = variance ## and min.node.size = 5. plot(model) 17.7 Random forest model and tuneGrid() Custom tuning of grids can be used in caret by using tuneGrid(). While it is the most flexible method for fitting caret models and allows complete control over how the model is fit, it requires significant knowledge of the model and dramatically increases run time. For my uses, most of the time I anticipate using tuneLength and the default settings in caret to build my random forest models. tuneGrid &lt;- data.frame( .mtry = c(2, 3, 7), .splitrule = &quot;variance&quot;, .min.node.size = 5 ) # Fit random forest: model model &lt;- train( quality ~ ., tuneGrid = tuneGrid, data = wine, method = &quot;ranger&quot;, trControl = trainControl( method = &quot;cv&quot;, number = 5, verboseIter = TRUE ) ) ## + Fold1: mtry=2, splitrule=variance, min.node.size=5 ## - Fold1: mtry=2, splitrule=variance, min.node.size=5 ## + Fold1: mtry=3, splitrule=variance, min.node.size=5 ## - Fold1: mtry=3, splitrule=variance, min.node.size=5 ## + Fold1: mtry=7, splitrule=variance, min.node.size=5 ## - Fold1: mtry=7, splitrule=variance, min.node.size=5 ## + Fold2: mtry=2, splitrule=variance, min.node.size=5 ## - Fold2: mtry=2, splitrule=variance, min.node.size=5 ## + Fold2: mtry=3, splitrule=variance, min.node.size=5 ## - Fold2: mtry=3, splitrule=variance, min.node.size=5 ## + Fold2: mtry=7, splitrule=variance, min.node.size=5 ## - Fold2: mtry=7, splitrule=variance, min.node.size=5 ## + Fold3: mtry=2, splitrule=variance, min.node.size=5 ## - Fold3: mtry=2, splitrule=variance, min.node.size=5 ## + Fold3: mtry=3, splitrule=variance, min.node.size=5 ## - Fold3: mtry=3, splitrule=variance, min.node.size=5 ## + Fold3: mtry=7, splitrule=variance, min.node.size=5 ## - Fold3: mtry=7, splitrule=variance, min.node.size=5 ## + Fold4: mtry=2, splitrule=variance, min.node.size=5 ## - Fold4: mtry=2, splitrule=variance, min.node.size=5 ## + Fold4: mtry=3, splitrule=variance, min.node.size=5 ## - Fold4: mtry=3, splitrule=variance, min.node.size=5 ## + Fold4: mtry=7, splitrule=variance, min.node.size=5 ## - Fold4: mtry=7, splitrule=variance, min.node.size=5 ## + Fold5: mtry=2, splitrule=variance, min.node.size=5 ## - Fold5: mtry=2, splitrule=variance, min.node.size=5 ## + Fold5: mtry=3, splitrule=variance, min.node.size=5 ## - Fold5: mtry=3, splitrule=variance, min.node.size=5 ## + Fold5: mtry=7, splitrule=variance, min.node.size=5 ## - Fold5: mtry=7, splitrule=variance, min.node.size=5 ## Aggregating results ## Selecting tuning parameters ## Fitting mtry = 3, splitrule = variance, min.node.size = 5 on full training set # Print model to console model ## Random Forest ## ## 4898 samples ## 11 predictor ## ## No pre-processing ## Resampling: Cross-Validated (5 fold) ## Summary of sample sizes: 3918, 3918, 3919, 3918, 3919 ## Resampling results across tuning parameters: ## ## mtry RMSE Rsquared MAE ## 2 0.6076591 0.5397497 0.4417339 ## 3 0.6056877 0.5399161 0.4378556 ## 7 0.6083201 0.5319077 0.4367244 ## ## Tuning parameter &#39;splitrule&#39; was held constant at a value of variance ## ## Tuning parameter &#39;min.node.size&#39; was held constant at a value of 5 ## RMSE was used to select the optimal model using the smallest value. ## The final values used for the model were mtry = 3, splitrule = variance ## and min.node.size = 5. # Plot model plot(model) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
