[
["index.html", "Bill’s Drills Book Chapter 1 Drills: Part of Every Healthy Intellectual Diet", " Bill’s Drills Book William McDonald 2020-09-06 Chapter 1 Drills: Part of Every Healthy Intellectual Diet The goal of this book is to organize my R drills into reasonable chunks, the better to understand my strengths and weaknesses, and to plan new forays into data science. "],
["bookdownplan.html", "Chapter 2 bookdown Tips for This Document 2.1 Basic conventions 2.2 Referencing other parts of the document 2.3 Inserting pictures 2.4 Referencing citations: 2.5 Nifty test figure.", " Chapter 2 bookdown Tips for This Document 2.1 Basic conventions the _bookdown.yml file contains a snippet that is important to inserting the word “Chapter” before the chapter number in each of the Rmd files. packages are indicated in bold, like dplyr (surround with double asterisks) programs, like RStudio or MS Word, are in regular typeface inline code and filenames are indicated in typerwriter face by surrounding with backticks: _bookdown.yml _output.yml is modified from that used by Xie in his bookdown-demo (Xie 2020); it evokes style.css, toc.css, preamble.tex, which are also borrowed from Xie. chapters are set in order by using adding 01, 02, 03, … before the name of their Rmd, like 01chpter.Rmd. Note that they can have short descriptive phrases, since the actual chapter titles are determined by the hashtag. index.Rmd always comes first in the book build, and contains the yml front matter. the most frequently used keyboard shortcuts from RStudio include: Option-Hyphen (the assignment operator) Shift-Control-c (comment code hashtag) Option-Command-i (code chunk) Shift-Control-m (pipe) 2.2 Referencing other parts of the document This is a good place to practice referencing figures. Say that I want to refer the reader back to my first starwars figure. See Figure 2.1. I can reference other pages in a similar fashion. See Chapter 10. Note that this works by referencing a {#label} placed in the chapter title. See Chapter 1 See Chapter 3 Note that the {#label} uses a single run-together word. It does not tolerate spaces and this cannot be overcome by ‘quoting’ it. 2.3 Inserting pictures Pictures can be included in the test-book_files subdirectories and referenced like this: Tpit immunohistochemical stain. Figure A silent corticotroph. Figure B gonadotroph Some of the subdirectories throw an error in building the book, so I settled on _bookdown_files/pathologyImages as the location. Also, I note that the build does not generate the caption unless the reference is on it’s own line. Also note that some controls on image size are available. For instance, the same image can be displayed at 50% size: Tpit immunohistochemical stain. Figure A silent corticotroph. Figure B gonadotroph 2.4 Referencing citations: In order to insert reference citations, one needs a .bib file in the project. I’ve included one in this project as book.bib. The yml header in Chapter 1 needs to have a \\(bibliography:\\) and \\(biblio-style:\\) line added. A separate packages.bib file is also used to hold the R packages cited. To insert a citation, use the citr Addin from RStudio. bookdown, for instance, is cited thusly (Xie 2020). Note that I need to figure out an adequate workflow of references. The convenience of Endnote in MS Word will not be available. Nonetheless, if I populate the book.bib and packages.bib files carefully, with .txt files generated in Endnote, I should be OK. For instance, a recent dump of my Endnote library is in bookFromEndnote.txt. This can be opened in RStudio, and I can copy-and-paste references from the .txt file to my book.bib. For instance, if I have a breast paper that I want to cite here (Stevens and Parekh 2016), I’d copy-and-paste the reference from bookFromEndnote.txt to book.bib. Of note, Yihui Xie includes a nifty bit of code to automatically generate a bib database for R packages: knitr::write_bib(c(.packages(), &#39;bookdown&#39;, &#39;knitr&#39;, &#39;rmarkdown&#39;, &#39;tidyverse&#39;, &#39;ComplexHeatmap&#39;), &#39;packages.bib&#39;) ## Warning in knitr::write_bib(c(.packages(), &quot;bookdown&quot;, &quot;knitr&quot;, &quot;rmarkdown&quot;, : ## package(s) ComplexHeatmap not found All packages are maintained in packages.bib. In the knitted document, references appear automatically at the end of a chapter. 2.5 Nifty test figure. First I need the help of the tidverse. library(tidyverse) Now to generate a figure. The code chunk contains the following: {r starfig-1, fig.cap='Starwars Figure 1'}. This labels the figure with a short name, starfig-1, and gives it the caption Starwars Figure 1. starwars %&gt;% filter(!is.na(species)) %&gt;% mutate(species = fct_lump(species, 5)) %&gt;% mutate(species = species %&gt;% fct_infreq() %&gt;% fct_rev()) %&gt;% ggplot()+ geom_bar(aes(species, fill = gender))+ coord_flip() Figure 2.1: Starwars Figure 1 References appear automatically at the end of a chapter. References "],
["dataexploration.html", "Chapter 3 Data Exploration 3.1 Counting things. The naming of parts. 3.2 fct_infreq 3.3 Summarize is another very useful function:", " Chapter 3 Data Exploration Data exploration is one of the most important aspects of data science and forms the cornerstone of my drills. Nonetheless, I have lots of room for improvement. I like Hadely Wickham’s writing and find his approach exceptionally clear. Therefore, I’ll use the tidyverse. library(tidyverse) 3.1 Counting things. The naming of parts. starwars %&gt;% filter(!is.na(species)) %&gt;% count(species = fct_lump(species, 5), sort = TRUE) %&gt;% mutate(species = fct_reorder(species, n)) %&gt;% ggplot(aes(species, n)) + geom_col() + coord_flip() Figure 3.1: Starwars Figure 1 I like stacked bars for their economy, but it’s easy to over do it. Supperimposing gender onto the columns seems easy… starwars %&gt;% filter(!is.na(species)) %&gt;% count(species = fct_lump(species, 5), gender = fct_lump(gender, 2), sort = TRUE) %&gt;% mutate(species = fct_reorder(species, n)) %&gt;% ggplot(aes(species, n, fill = gender)) + geom_col() + coord_flip() Figure 3.2: Starwars Figure 2 But note that I’ve got a problem: the Droids, which outnumber the Gungans, are now reordered to after the Gungans. This happens because the \\(n\\) that we’re counting comprises subcategories of species and gender. Only three Gungan males exist (and no females), but that is enough to tie the Droid NA category. The Droid NA category come after the Gungan category, presumably because male comes before NA, or because NA comes last (more likely). Exploring this, I see that I’m getting warning messages about the implicit NA’s in gender. Note that the following renders a slightly different plot. I still have not fixed the order of the species. starwars %&gt;% filter(!is.na(species)) %&gt;% count(species = fct_lump(species, 5), gender = fct_lump(gender, 2), sort = TRUE) %&gt;% mutate(gender = fct_explicit_na(gender), species = fct_reorder(species, n)) %&gt;% ggplot(aes(species, n, fill = gender)) + geom_col() + coord_flip() Figure 3.3: Starwars Figure 3 The trick here is to use group_by() and ungroup() wisely. starwars %&gt;% filter(!is.na(species)) %&gt;% mutate(species = fct_lump(species, 5)) %&gt;% group_by(species) %&gt;% mutate(typeCount = n()) %&gt;% ungroup() %&gt;% mutate(species = fct_reorder(species, typeCount)) %&gt;% ggplot()+ geom_bar(aes(species, fill = gender))+ coord_flip() Figure 3.4: Starwars Figure 4 As opposed to using count(), which progressively narrows the information available to be used, by using group_by()/mutate()/ungroup() with geom_bar() we have all of the variables still available for plotting. 3.2 fct_infreq As expected, Hadley Wickham and Garrett Grolemund solve this more simply in R4DS: starwars %&gt;% filter(!is.na(species)) %&gt;% mutate(species = fct_lump(species, 5)) %&gt;% mutate(species = species %&gt;% fct_infreq() %&gt;% fct_rev()) %&gt;% ggplot()+ geom_bar(aes(species, fill = gender))+ coord_flip() Figure 3.5: Starwars Figure 5 # Note that a single `mutate()` suffices to both lump factors, organize by frequency and reverse the order, as follows. starwars %&gt;% filter(!is.na(species)) %&gt;% mutate(species = fct_lump(species, 5) %&gt;% fct_infreq() %&gt;% fct_rev()) %&gt;% ggplot()+ geom_bar(aes(species, fill = gender))+ coord_flip() Figure 3.6: Starwars Figure 5 3.3 Summarize is another very useful function: starwars %&gt;% filter(!(is.na(species))) %&gt;% group_by(species) %&gt;% summarize(n=n(), mean = mean(height, na.rm = TRUE)) %&gt;% arrange(desc(n)) ## `summarise()` ungrouping output (override with `.groups` argument) ## # A tibble: 37 x 3 ## species n mean ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Human 35 177. ## 2 Droid 6 131. ## 3 Gungan 3 209. ## 4 Kaminoan 2 221 ## 5 Mirialan 2 168 ## 6 Twi&#39;lek 2 179 ## 7 Wookiee 2 231 ## 8 Zabrak 2 173 ## 9 Aleena 1 79 ## 10 Besalisk 1 198 ## # … with 27 more rows "],
["sampling.html", "Chapter 4 Sampling 4.1 Think about throwing a bunch of dice. 4.2 A keen way to divide up a dataset into testing and training components.", " Chapter 4 Sampling 4.1 Think about throwing a bunch of dice. sample(1:6, size=100, replace=TRUE) ## [1] 6 6 4 1 3 5 2 2 1 6 3 2 3 5 5 6 6 2 5 3 2 6 4 6 2 3 3 6 3 2 3 4 6 2 3 3 4 ## [38] 3 3 4 2 3 4 4 2 1 1 5 5 1 2 6 2 3 6 1 3 5 4 1 5 5 3 1 6 3 4 1 1 6 5 6 6 6 ## [75] 1 5 1 2 6 1 4 6 5 1 4 4 2 5 6 5 1 3 6 4 1 5 5 5 4 5 sample(1:6, size=100, replace=TRUE) %&gt;% table() ## . ## 1 2 3 4 5 6 ## 14 16 19 12 20 19 sample(1:6, size=100, replace=TRUE) %&gt;% table() %&gt;% prop.table() ## . ## 1 2 3 4 5 6 ## 0.14 0.14 0.20 0.16 0.18 0.18 4.2 A keen way to divide up a dataset into testing and training components. x &lt;- 1:10 y &lt;- 11:30 df &lt;- data.frame(x,y) df ## x y ## 1 1 11 ## 2 2 12 ## 3 3 13 ## 4 4 14 ## 5 5 15 ## 6 6 16 ## 7 7 17 ## 8 8 18 ## 9 9 19 ## 10 10 20 ## 11 1 21 ## 12 2 22 ## 13 3 23 ## 14 4 24 ## 15 5 25 ## 16 6 26 ## 17 7 27 ## 18 8 28 ## 19 9 29 ## 20 10 30 set.seed(0) train_indexes = sample(1:nrow(df), .7 * nrow(df)) train_set &lt;- df[train_indexes,] test_set &lt;- df[-train_indexes,] train_set ## x y ## 14 4 24 ## 4 4 14 ## 7 7 17 ## 1 1 11 ## 2 2 12 ## 13 3 23 ## 18 8 28 ## 11 1 21 ## 16 6 26 ## 15 5 25 ## 3 3 13 ## 17 7 27 ## 5 5 15 ## 8 8 18 test_set ## x y ## 6 6 16 ## 9 9 19 ## 10 10 20 ## 12 2 22 ## 19 9 29 ## 20 10 30 "],
["factorpractice.html", "Chapter 5 Factor Practice 5.1 The basic structure 5.2 Not all nominal data is a factor 5.3 Making variables into factors 5.4 Inspecting factors 5.5 fct_lump()", " Chapter 5 Factor Practice 5.1 The basic structure Let’s say that you have 100 cups of sizes small, medium, or large. cups &lt;- c(&quot;small&quot;, &quot;medium&quot;, &quot;large&quot;) set.seed(2020) manyCups &lt;- sample(cups, size = 100, replace = TRUE) table(manyCups) ## manyCups ## large medium small ## 25 39 36 str(manyCups) ## chr [1:100] &quot;large&quot; &quot;medium&quot; &quot;small&quot; &quot;small&quot; &quot;medium&quot; &quot;medium&quot; &quot;small&quot; ... Note that table() renders these in alphabetical order. It’s usually more useful to render them in order of magnitude by setting levels. sizesCups &lt;- factor(manyCups, levels = c(&quot;small&quot;, &quot;medium&quot;, &quot;large&quot;)) sizesCups ## [1] large medium small small medium medium small small medium medium ## [11] medium small medium large medium small medium medium medium large ## [21] medium large medium small large medium medium medium large medium ## [31] large large small small small medium large small small medium ## [41] large small small small large small small large medium medium ## [51] medium small large medium small medium large small small medium ## [61] small medium large medium large medium medium small large medium ## [71] large small medium large medium medium medium small small small ## [81] large medium medium small small medium small small medium small ## [91] large small large small small large large large medium small ## Levels: small medium large table(sizesCups) ## sizesCups ## small medium large ## 36 39 25 levels(sizesCups) ## [1] &quot;small&quot; &quot;medium&quot; &quot;large&quot; levels(manyCups) ## NULL The forcats package is designed to work with factors. Although I use it frequently, I haven’t generalized the ideas, or internalized them. That’s a mistake. The RStudio cheat sheet is a nice place to begin with this: https://rstudio.com/resources/cheatsheets/. Let’s use my favorite starwars illustration to help illustrate some of forcats’s usefulness. starwars %&gt;% filter(!is.na(species)) %&gt;% count(species, sort = TRUE) ## # A tibble: 37 x 2 ## species n ## &lt;chr&gt; &lt;int&gt; ## 1 Human 35 ## 2 Droid 6 ## 3 Gungan 3 ## 4 Kaminoan 2 ## 5 Mirialan 2 ## 6 Twi&#39;lek 2 ## 7 Wookiee 2 ## 8 Zabrak 2 ## 9 Aleena 1 ## 10 Besalisk 1 ## # … with 27 more rows The forcats cheat sheet contains a bunch of often-used functions that I rarely take the time to think about. 5.2 Not all nominal data is a factor Note that many categorical variables are not encoded as factors. This has certain advantages, since levels can sometimes be seen as complicating ballast that is dragged around by the variable. See, so instance, that the species variable is not encoded as a factor: class(starwars$species) ## [1] &quot;character&quot; See? species is character, not factor, class. 5.3 Making variables into factors The factor() function (or the as_factor() function) make a variable into a factor and allow the assignation of levels. class(factor(starwars$species)) ## [1] &quot;factor&quot; The levels() function is useful for returning these levels: levels(factor(starwars$species)) ## [1] &quot;Aleena&quot; &quot;Besalisk&quot; &quot;Cerean&quot; &quot;Chagrian&quot; ## [5] &quot;Clawdite&quot; &quot;Droid&quot; &quot;Dug&quot; &quot;Ewok&quot; ## [9] &quot;Geonosian&quot; &quot;Gungan&quot; &quot;Human&quot; &quot;Hutt&quot; ## [13] &quot;Iktotchi&quot; &quot;Kaleesh&quot; &quot;Kaminoan&quot; &quot;Kel Dor&quot; ## [17] &quot;Mirialan&quot; &quot;Mon Calamari&quot; &quot;Muun&quot; &quot;Nautolan&quot; ## [21] &quot;Neimodian&quot; &quot;Pau&#39;an&quot; &quot;Quermian&quot; &quot;Rodian&quot; ## [25] &quot;Skakoan&quot; &quot;Sullustan&quot; &quot;Tholothian&quot; &quot;Togruta&quot; ## [29] &quot;Toong&quot; &quot;Toydarian&quot; &quot;Trandoshan&quot; &quot;Twi&#39;lek&quot; ## [33] &quot;Vulptereen&quot; &quot;Wookiee&quot; &quot;Xexto&quot; &quot;Yoda&#39;s species&quot; ## [37] &quot;Zabrak&quot; levels() can also be used to set the levels. And additional structure can be observed with unclass(). Note that the default level order in species is alphabetical. unclass(factor(starwars$species)) ## [1] 11 6 6 11 11 11 11 6 11 11 11 11 34 11 24 12 11 11 36 11 11 6 31 11 11 ## [26] 18 11 11 8 26 11 21 11 10 10 10 NA 30 7 NA 11 37 32 32 33 35 29 11 3 20 ## [51] 37 27 13 23 16 4 11 11 11 9 17 17 11 11 11 11 5 2 15 15 11 1 6 25 19 ## [76] 28 14 34 11 NA 22 11 11 11 6 NA 11 ## attr(,&quot;levels&quot;) ## [1] &quot;Aleena&quot; &quot;Besalisk&quot; &quot;Cerean&quot; &quot;Chagrian&quot; ## [5] &quot;Clawdite&quot; &quot;Droid&quot; &quot;Dug&quot; &quot;Ewok&quot; ## [9] &quot;Geonosian&quot; &quot;Gungan&quot; &quot;Human&quot; &quot;Hutt&quot; ## [13] &quot;Iktotchi&quot; &quot;Kaleesh&quot; &quot;Kaminoan&quot; &quot;Kel Dor&quot; ## [17] &quot;Mirialan&quot; &quot;Mon Calamari&quot; &quot;Muun&quot; &quot;Nautolan&quot; ## [21] &quot;Neimodian&quot; &quot;Pau&#39;an&quot; &quot;Quermian&quot; &quot;Rodian&quot; ## [25] &quot;Skakoan&quot; &quot;Sullustan&quot; &quot;Tholothian&quot; &quot;Togruta&quot; ## [29] &quot;Toong&quot; &quot;Toydarian&quot; &quot;Trandoshan&quot; &quot;Twi&#39;lek&quot; ## [33] &quot;Vulptereen&quot; &quot;Wookiee&quot; &quot;Xexto&quot; &quot;Yoda&#39;s species&quot; ## [37] &quot;Zabrak&quot; 5.4 Inspecting factors We see that there are a ton of unique species in this list. fct_count(starwars$species, sort = TRUE) ## # A tibble: 38 x 2 ## f n ## &lt;fct&gt; &lt;int&gt; ## 1 Human 35 ## 2 Droid 6 ## 3 &lt;NA&gt; 4 ## 4 Gungan 3 ## 5 Kaminoan 2 ## 6 Mirialan 2 ## 7 Twi&#39;lek 2 ## 8 Wookiee 2 ## 9 Zabrak 2 ## 10 Aleena 1 ## # … with 28 more rows fct_unique(factor(starwars$species)) ## [1] Aleena Besalisk Cerean Chagrian Clawdite ## [6] Droid Dug Ewok Geonosian Gungan ## [11] Human Hutt Iktotchi Kaleesh Kaminoan ## [16] Kel Dor Mirialan Mon Calamari Muun Nautolan ## [21] Neimodian Pau&#39;an Quermian Rodian Skakoan ## [26] Sullustan Tholothian Togruta Toong Toydarian ## [31] Trandoshan Twi&#39;lek Vulptereen Wookiee Xexto ## [36] Yoda&#39;s species Zabrak ## 37 Levels: Aleena Besalisk Cerean Chagrian Clawdite Droid Dug ... Zabrak 5.5 fct_lump() We often don’t want to see all of the rare outcomes for a nominal variable, and are content to lump the uncommon ones together in an other category. starwars %&gt;% filter(!is.na(species)) %&gt;% mutate(species = fct_lump(species, 5)) %&gt;% count(species, sort = TRUE) ## # A tibble: 9 x 2 ## species n ## &lt;fct&gt; &lt;int&gt; ## 1 Human 35 ## 2 Other 29 ## 3 Droid 6 ## 4 Gungan 3 ## 5 Kaminoan 2 ## 6 Mirialan 2 ## 7 Twi&#39;lek 2 ## 8 Wookiee 2 ## 9 Zabrak 2 fct_lump() is will produce more than the requested number of categories (in this case 5), when ties are present in the last place. In this case, since 5 species each have 2 members, all of these species are listed. "],
["crossingtrial.html", "Chapter 6 Crossing Trial", " Chapter 6 Crossing Trial From David Robinson birthday paradox Rblogger at https://www.r-bloggers.com/the-birthday-paradox-puzzle-tidy-simulation-in-r/ library(tidyverse) summarized &lt;- crossing(people = seq(2, 50, 2), trial = 1:100) %&gt;% mutate(birthday = map(people, ~ sample(365, .x, replace = TRUE)), multiple = map_lgl(birthday, ~ any(duplicated(.x)))) %&gt;% group_by(people) %&gt;% summarize(chance = mean(multiple)) ## `summarise()` ungrouping output (override with `.groups` argument) ggplot(summarized, aes(people, chance)) + geom_line() + scale_y_continuous(labels = scales::percent_format()) + labs(y = &quot;Probability two have the same birthday&quot;) # Checking the work with pbirthday function summarized %&gt;% mutate(exact = map_dbl(people, pbirthday)) %&gt;% ggplot(aes(people, chance)) + geom_line() + geom_line(aes(y = exact), lty = 2, color = &quot;blue&quot;) + scale_y_continuous(labels = scales::percent_format()) + labs(y = &quot;Probability two have the same birthday&quot;) "],
["changenames.html", "Chapter 7 By Any Other Name 7.1 A financial example", " Chapter 7 By Any Other Name This deceptively simple-seeming idea gets complex quickly. The following YouTube was a nice description of the process: https://www.youtube.com/watch?v=Okc0IL5uTnA my.data &lt;- data.frame(colOne=1:3, column2=4:6, column_3=7:9) rownames(my.data) &lt;- c(&quot;ant&quot;, &quot;bee&quot;, &quot;cat&quot;) names(my.data) ## [1] &quot;colOne&quot; &quot;column2&quot; &quot;column_3&quot; colnames(my.data) ## [1] &quot;colOne&quot; &quot;column2&quot; &quot;column_3&quot; #make some changes names(my.data) &lt;- c(&quot;col_1&quot;, &quot;col_2&quot;, &quot;col_3&quot;) my.data ## col_1 col_2 col_3 ## ant 1 4 7 ## bee 2 5 8 ## cat 3 6 9 names(my.data)[3] &lt;- &quot;col.3&quot; my.data ## col_1 col_2 col.3 ## ant 1 4 7 ## bee 2 5 8 ## cat 3 6 9 names(my.data)[names(my.data)==&quot;col_2&quot;] ## [1] &quot;col_2&quot; my.data[&quot;col_2&quot;] ## col_2 ## ant 4 ## bee 5 ## cat 6 my.data$col_2 ## [1] 4 5 6 my.data[,2] ## [1] 4 5 6 names(my.data)[names(my.data)==&quot;col_2&quot;] &lt;- &quot;col.2&quot; my.data ## col_1 col.2 col.3 ## ant 1 4 7 ## bee 2 5 8 ## cat 3 6 9 names(my.data) &lt;- gsub(&quot;_&quot;, &quot;.&quot;, names(my.data)) my.data ## col.1 col.2 col.3 ## ant 1 4 7 ## bee 2 5 8 ## cat 3 6 9 rownames(my.data) ## [1] &quot;ant&quot; &quot;bee&quot; &quot;cat&quot; my.data$species &lt;- rownames(my.data) my.data ## col.1 col.2 col.3 species ## ant 1 4 7 ant ## bee 2 5 8 bee ## cat 3 6 9 cat rownames(my.data) &lt;- NULL my.data ## col.1 col.2 col.3 species ## 1 1 4 7 ant ## 2 2 5 8 bee ## 3 3 6 9 cat colnames(my.data) &lt;- c(&quot;good&quot;, &quot;better&quot;, &quot;best&quot;, &quot;species&quot;) my.data ## good better best species ## 1 1 4 7 ant ## 2 2 5 8 bee ## 3 3 6 9 cat keep &lt;- 2:ncol(my.data) my.data[,keep] ## better best species ## 1 4 7 ant ## 2 5 8 bee ## 3 6 9 cat 7.1 A financial example Dealing with financial data often means cleaning variable names and getting pesky dollar signs and commas out of downloaded files. Check out this example: library(tidyverse) First, load the tidyverse etf_data &lt;- tribble( ~Sign, ~&quot;Market Value&quot;, &quot;VTI&quot;, &quot;$172.22&quot;, &quot;VXUS&quot;, &quot;$52.99&quot; ) etf_data ## # A tibble: 2 x 2 ## Sign `Market Value` ## &lt;chr&gt; &lt;chr&gt; ## 1 VTI $172.22 ## 2 VXUS $52.99 # First let&#39;s address the crappy variable names: etf_data_namedOK &lt;- janitor::clean_names(etf_data) etf_data_namedOK ## # A tibble: 2 x 2 ## sign market_value ## &lt;chr&gt; &lt;chr&gt; ## 1 VTI $172.22 ## 2 VXUS $52.99 # Now remove the offending dollar signs and commas (if present) etf_data_namedOK$market_value &lt;- as.numeric(gsub(&#39;\\\\$|,&#39;,&#39;&#39;,as.character(etf_data_namedOK$market_value))) etf_data_namedOK ## # A tibble: 2 x 2 ## sign market_value ## &lt;chr&gt; &lt;dbl&gt; ## 1 VTI 172. ## 2 VXUS 53.0 # Don&#39;t be alarmed by the rounding behavior in the console. You can see that the data is intact. str(etf_data_namedOK) ## tibble [2 × 2] (S3: tbl_df/tbl/data.frame) ## $ sign : chr [1:2] &quot;VTI&quot; &quot;VXUS&quot; ## $ market_value: num [1:2] 172 53 glimpse(etf_data_namedOK) ## Rows: 2 ## Columns: 2 ## $ sign &lt;chr&gt; &quot;VTI&quot;, &quot;VXUS&quot; ## $ market_value &lt;dbl&gt; 172.22, 52.99 etf_data_namedOK$market_value ## [1] 172.22 52.99 "],
["correlation.html", "Chapter 8 Correlation Plots", " Chapter 8 Correlation Plots head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa iris %&gt;% select(-Species) %&gt;% cor() ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Sepal.Length 1.0000000 -0.1175698 0.8717538 0.8179411 ## Sepal.Width -0.1175698 1.0000000 -0.4284401 -0.3661259 ## Petal.Length 0.8717538 -0.4284401 1.0000000 0.9628654 ## Petal.Width 0.8179411 -0.3661259 0.9628654 1.0000000 M &lt;- iris %&gt;% select(-Species) %&gt;% cor(method = &quot;kendall&quot;) corrplot::corrplot(M) corrplot::corrplot(M, method = &quot;color&quot;) corrplot::corrplot(M, method = &quot;color&quot;, type = &quot;upper&quot;) corrplot::corrplot(M, method = &quot;color&quot;, type = &quot;upper&quot;, order = &quot;hclust&quot;) corrplot::corrplot(M, method = &quot;color&quot;, type = &quot;upper&quot;, order = &quot;hclust&quot;, addCoef.col = &quot;black&quot;) corrplot::corrplot(M, method = &quot;color&quot;, type = &quot;upper&quot;, order = &quot;hclust&quot;, addCoef.col = &quot;black&quot;, tl.col=&quot;black&quot;) corrplot::corrplot(M, method = &quot;color&quot;, type = &quot;upper&quot;, order = &quot;hclust&quot;, addCoef.col = &quot;black&quot;, tl.col=&quot;black&quot;, tl.srt = 45) "],
["ifelsecasewhen.html", "Chapter 9 if_else() and case_when(): Comparison 9.1 case_when() 9.2 Compare this with if_else()", " Chapter 9 if_else() and case_when(): Comparison 9.1 case_when() case_when() from https://www.rdocumentation.org/packages/dplyr/versions/0.7.8/topics/case_when x &lt;- 1:50 y &lt;- 51:100 df &lt;- data.frame(x,y) df ## x y ## 1 1 51 ## 2 2 52 ## 3 3 53 ## 4 4 54 ## 5 5 55 ## 6 6 56 ## 7 7 57 ## 8 8 58 ## 9 9 59 ## 10 10 60 ## 11 11 61 ## 12 12 62 ## 13 13 63 ## 14 14 64 ## 15 15 65 ## 16 16 66 ## 17 17 67 ## 18 18 68 ## 19 19 69 ## 20 20 70 ## 21 21 71 ## 22 22 72 ## 23 23 73 ## 24 24 74 ## 25 25 75 ## 26 26 76 ## 27 27 77 ## 28 28 78 ## 29 29 79 ## 30 30 80 ## 31 31 81 ## 32 32 82 ## 33 33 83 ## 34 34 84 ## 35 35 85 ## 36 36 86 ## 37 37 87 ## 38 38 88 ## 39 39 89 ## 40 40 90 ## 41 41 91 ## 42 42 92 ## 43 43 93 ## 44 44 94 ## 45 45 95 ## 46 46 96 ## 47 47 97 ## 48 48 98 ## 49 49 99 ## 50 50 100 case_when( x %% 35 == 0 ~ &quot;fizz buzz&quot;, x %% 5 == 0 ~ &quot;fizz&quot;, x %% 7 == 0 ~ &quot;buzz&quot;, TRUE ~ as.character(x) ) ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;fizz&quot; &quot;6&quot; ## [7] &quot;buzz&quot; &quot;8&quot; &quot;9&quot; &quot;fizz&quot; &quot;11&quot; &quot;12&quot; ## [13] &quot;13&quot; &quot;buzz&quot; &quot;fizz&quot; &quot;16&quot; &quot;17&quot; &quot;18&quot; ## [19] &quot;19&quot; &quot;fizz&quot; &quot;buzz&quot; &quot;22&quot; &quot;23&quot; &quot;24&quot; ## [25] &quot;fizz&quot; &quot;26&quot; &quot;27&quot; &quot;buzz&quot; &quot;29&quot; &quot;fizz&quot; ## [31] &quot;31&quot; &quot;32&quot; &quot;33&quot; &quot;34&quot; &quot;fizz buzz&quot; &quot;36&quot; ## [37] &quot;37&quot; &quot;38&quot; &quot;39&quot; &quot;fizz&quot; &quot;41&quot; &quot;buzz&quot; ## [43] &quot;43&quot; &quot;44&quot; &quot;fizz&quot; &quot;46&quot; &quot;47&quot; &quot;48&quot; ## [49] &quot;buzz&quot; &quot;fizz&quot; 9.2 Compare this with if_else() if_else(x %% 2 == 0, &quot;even&quot;, &quot;odd&quot;) ## [1] &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; ## [11] &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; ## [21] &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; ## [31] &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; ## [41] &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; "],
["subset.html", "Chapter 10 Subsetting 10.1 Subsetting using brackets 10.2 Subset using brackets by omitting the rows and columns we don’t want 10.3 Subset using brackets in combination with the which() function and the %in% operator 10.4 Subset using the subset() function 10.5 Subset using dyplyr’s filter() and select()", " Chapter 10 Subsetting From https://www.r-bloggers.com/5-ways-to-subset-a-data-frame-in-r/ Note: since this is down for maintenance, I will turn off evaluation on these chunks: education &lt;- read.csv(&quot;https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/education.csv&quot;, stringsAsFactors = FALSE) colnames(education) &lt;- c(&quot;X&quot;,&quot;State&quot;,&quot;Region&quot;,&quot;Urban.Population&quot;,&quot;Per.Capita.Income&quot;,&quot;Minor.Population&quot;,&quot;Education.Expenditures&quot;) glimpse(education) ## Rows: 50 ## Columns: 7 ## $ X &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,… ## $ State &lt;chr&gt; &quot;ME&quot;, &quot;NH&quot;, &quot;VT&quot;, &quot;MA&quot;, &quot;RI&quot;, &quot;CT&quot;, &quot;NY&quot;, &quot;NJ&quot;… ## $ Region &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2… ## $ Urban.Population &lt;int&gt; 508, 564, 322, 846, 871, 774, 856, 889, 715, 7… ## $ Per.Capita.Income &lt;int&gt; 3944, 4578, 4011, 5233, 4780, 5889, 5663, 5759… ## $ Minor.Population &lt;int&gt; 325, 323, 328, 305, 303, 307, 301, 310, 300, 3… ## $ Education.Expenditures &lt;int&gt; 235, 231, 270, 261, 300, 317, 387, 285, 300, 2… 10.1 Subsetting using brackets education[c(10:21),c(2,6:7)] ## State Minor.Population Education.Expenditures ## 10 OH 324 221 ## 11 IN 329 264 ## 12 IL 320 308 ## 13 MI 337 379 ## 14 WI 328 342 ## 15 MN 330 378 ## 16 IA 318 232 ## 17 MO 309 231 ## 18 ND 333 246 ## 19 SD 330 230 ## 20 NB 318 268 ## 21 KS 304 337 10.2 Subset using brackets by omitting the rows and columns we don’t want education[-c(1:9,22:50),-c(1,3:5)] ## State Minor.Population Education.Expenditures ## 10 OH 324 221 ## 11 IN 329 264 ## 12 IL 320 308 ## 13 MI 337 379 ## 14 WI 328 342 ## 15 MN 330 378 ## 16 IA 318 232 ## 17 MO 309 231 ## 18 ND 333 246 ## 19 SD 330 230 ## 20 NB 318 268 ## 21 KS 304 337 10.3 Subset using brackets in combination with the which() function and the %in% operator education[which(education$Region == 2),names(education) %in% c(&quot;State&quot;,&quot;Minor.Population&quot;,&quot;Education.Expenditures&quot;)] ## State Minor.Population Education.Expenditures ## 10 OH 324 221 ## 11 IN 329 264 ## 12 IL 320 308 ## 13 MI 337 379 ## 14 WI 328 342 ## 15 MN 330 378 ## 16 IA 318 232 ## 17 MO 309 231 ## 18 ND 333 246 ## 19 SD 330 230 ## 20 NB 318 268 ## 21 KS 304 337 10.4 Subset using the subset() function subset(education, Region == 2, select = c(&quot;State&quot;,&quot;Minor.Population&quot;,&quot;Education.Expenditures&quot;)) ## State Minor.Population Education.Expenditures ## 10 OH 324 221 ## 11 IN 329 264 ## 12 IL 320 308 ## 13 MI 337 379 ## 14 WI 328 342 ## 15 MN 330 378 ## 16 IA 318 232 ## 17 MO 309 231 ## 18 ND 333 246 ## 19 SD 330 230 ## 20 NB 318 268 ## 21 KS 304 337 10.5 Subset using dyplyr’s filter() and select() select(filter(education, Region == 2),c(State,Minor.Population:Education.Expenditures)) ## State Minor.Population Education.Expenditures ## 1 OH 324 221 ## 2 IN 329 264 ## 3 IL 320 308 ## 4 MI 337 379 ## 5 WI 328 342 ## 6 MN 330 378 ## 7 IA 318 232 ## 8 MO 309 231 ## 9 ND 333 246 ## 10 SD 330 230 ## 11 NB 318 268 ## 12 KS 304 337 "],
["simulating-data.html", "Chapter 11 Simulating data 11.1 Sample() 11.2 replicate() 11.3 sample() revisited 11.4 generating fixed levels ————————————————- 11.5 generating numerical sequences 11.6 seq_along() and seq_len(). 11.7 generating random data from a probability distribution 11.8 Normal distribution: 11.9 Binomial distribution: 11.10 Uniform distribution 11.11 Sampling from multiple distributions (building in a “difference”) 11.12 The good stuff: building in a difference based on a categorical variable 11.13 A demonstration of the Central Limit Theorem 11.14 Overlaying normal curve on histogram", " Chapter 11 Simulating data I’ve just begun to explore R, and I realize that many of my questions could be improved with example data. Generating this kind of data takes practice, though. Some good websites: https://clayford.github.io/dwir/dwr_12_generating_data.html https://cran.r-project.org/web/packages/simstudy/vignettes/simstudy.html https://aosmith.rbind.io/2018/08/29/getting-started-simulating-data/ Also, remember that R packages have a lot of great data. data() 11.1 Sample() Starting with Clayford’s nice (and long page): sample(5) #sample without replacement ## [1] 4 5 1 2 3 # or generate a random permutation of a vector: dat &lt;- c(10,12,18,16,18,9) sample(dat) ## [1] 10 12 18 18 16 9 # bootstrap resampling: sampling the same number of items WITH replacement. The bootstrap method is a resampling technique used to estimate statistics on a population by sampling a dataset with replacement. sample(dat, replace = TRUE) ## [1] 9 10 18 18 18 10 rm(dat) sample(state.abb, size = 10) ## [1] &quot;RI&quot; &quot;LA&quot; &quot;FL&quot; &quot;MD&quot; &quot;TX&quot; &quot;WV&quot; &quot;AK&quot; &quot;NE&quot; &quot;WA&quot; &quot;AZ&quot; # Using 1:6 and size=1, we can simulate the roll of a die: sample(1:6, size=1) ## [1] 1 # We can simulate the roll of a die 100 times by setting size=100 and # replace=TRUE sample(1:6, size=100, replace=TRUE) ## [1] 5 6 3 1 5 1 5 1 3 1 1 3 3 4 5 4 4 5 6 4 2 1 5 6 6 1 3 3 4 1 4 5 4 6 6 4 5 ## [38] 6 4 6 1 4 1 3 4 1 1 5 4 3 1 2 5 5 2 2 1 3 5 6 4 4 1 3 4 3 4 5 2 2 4 2 5 4 ## [75] 4 5 4 3 4 1 4 1 1 1 5 6 1 4 5 5 5 5 2 3 6 2 2 5 4 1 # sample produces a vector, so we can manipulate it as we would any other # vector. For example, simulate a 100 die rolls and tally up the totals using # table() and prop.table(): table(sample(1:6, size=100, replace=TRUE)) ## ## 1 2 3 4 5 6 ## 8 27 19 17 19 10 prop.table(table(sample(1:6, size=100, replace=TRUE))) ## ## 1 2 3 4 5 6 ## 0.15 0.11 0.19 0.19 0.14 0.22 table(sample(state.abb, size = 1000, replace = TRUE)) ## ## AK AL AR AZ CA CO CT DE FL GA HI IA ID IL IN KS KY LA MA MD ME MI MN MO MS MT ## 19 14 14 24 23 19 28 17 25 20 25 23 21 23 16 21 17 10 18 20 19 30 24 19 21 23 ## NC ND NE NH NJ NM NV NY OH OK OR PA RI SC SD TN TX UT VA VT WA WI WV WY ## 18 23 18 23 10 18 19 13 19 23 15 25 26 17 18 19 20 24 19 22 17 14 28 19 prop.table(table(sample(state.abb, size = 1000, replace = TRUE))) ## ## AK AL AR AZ CA CO CT DE FL GA HI IA ID ## 0.016 0.021 0.024 0.013 0.018 0.023 0.025 0.020 0.030 0.015 0.026 0.020 0.024 ## IL IN KS KY LA MA MD ME MI MN MO MS MT ## 0.029 0.027 0.024 0.020 0.017 0.021 0.022 0.021 0.021 0.025 0.016 0.015 0.015 ## NC ND NE NH NJ NM NV NY OH OK OR PA RI ## 0.018 0.018 0.014 0.018 0.013 0.022 0.021 0.022 0.022 0.017 0.022 0.016 0.017 ## SC SD TN TX UT VA VT WA WI WV WY ## 0.016 0.018 0.017 0.028 0.021 0.019 0.011 0.019 0.020 0.025 0.018 # using the forward-pipe operator: %&gt;% library(magrittr) ## ## Attaching package: &#39;magrittr&#39; ## The following object is masked from &#39;package:purrr&#39;: ## ## set_names ## The following object is masked from &#39;package:tidyr&#39;: ## ## extract sample(1:6, size=100, replace=TRUE) %&gt;% table() %&gt;% prop.table() ## . ## 1 2 3 4 5 6 ## 0.16 0.19 0.13 0.14 0.21 0.17 # Or simulate rolling two dice and summing the total: sum(sample(1:6, size=2, replace=TRUE)) ## [1] 9 # same thing with %&gt;% sample(6, size=2, replace=TRUE) %&gt;% sum() ## [1] 4 # simulate rolling two dice 100 times by updating the sample &quot;space&quot; sample(2:12, size=100, replace=TRUE) ## [1] 3 12 5 5 4 4 4 6 3 9 2 10 12 8 8 4 2 8 9 7 8 8 9 12 8 ## [26] 8 12 6 11 2 5 2 8 3 3 3 8 4 4 5 4 9 4 11 4 7 7 4 5 2 ## [51] 9 7 5 5 12 3 7 2 3 6 6 6 2 11 6 6 8 4 12 12 8 10 3 11 6 ## [76] 12 7 11 6 3 9 2 11 3 9 10 5 9 4 3 9 4 12 8 5 5 10 7 9 6 # proportion of &quot;snake-eyes&quot; in 1000 rolls mean(sample(2:12, size = 1000, replace = TRUE) == 2) ## [1] 0.101 11.2 replicate() We can use the replicate() function to replicate samples. The replicate() function allows you to replicate an expression as many times as you specify. The basix syntax is replicate(n, expr) where n is the number of replications and expr is the expression you want to replicate. # Roll 2 dice and keep the largest number, 10,000 times: rolls &lt;- replicate(n=1e5, expr = max(sample(1:6, size=2, replace=TRUE))) # calculate proportions: prop.table(table(rolls)) ## rolls ## 1 2 3 4 5 6 ## 0.02813 0.08285 0.13635 0.19458 0.25246 0.30563 barplot(table(rolls)) rm(rolls) 11.3 sample() revisited The sample function also has a prob argument that allows you to assign probabilities to your items. For example to simulate the flip of a loaded coin, with Tails having probability 0.65: flips &lt;- sample(c(&quot;H&quot;,&quot;T&quot;), 1000, replace=TRUE, prob = c(0.35,0.65)) prop.table(table(flips)) ## flips ## H T ## 0.323 0.677 rm(flips) Coins are nice, but we can also use sample to generate practical data, for example males and females. A web site says UVa has 11,632 female students and 10,353 male students as of Fall 2015. uva &lt;- c(11632, 10353) # female, male round(uva/sum(uva),2) ## [1] 0.53 0.47 Note how elegantly this answers a basic question. Nice! We can generate a fake random sample of 500 UVa students with a weighted sampling scheme like so: students &lt;- sample(c(&quot;female&quot;,&quot;male&quot;), 500, replace=TRUE, prob = c(0.53, 0.47)) prop.table(table(students)) ## students ## female male ## 0.462 0.538 rm(students, uva) When used with subsetting brackets, sample() can be used to create training and test sets. For example, say we want to build some sort of predictive model using our training data. We may want to use half our data to build the model and then use the other half to evaluate its performance. train &lt;- sample(nrow(iris), size= nrow(iris)/2) # train is a random sample of numbers from 1 - 365. We can treat these like row numbers. irisTrain &lt;- iris[train,] irisTest &lt;- iris[-train,] # confirm no intersection dplyr::intersect(irisTrain, irisTest) ## [1] Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &lt;0 rows&gt; (or 0-length row.names) rm(train, irisTest, irisTrain) 11.4 generating fixed levels ————————————————- Often generating data means creating a series of fixed levels, such as 10 males and 10 females. The rep() function can be useful for this. Below we replicate 10 each of “M” and “F”: rep(c(&quot;M&quot;,&quot;F&quot;), each=10) ## [1] &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; ## [20] &quot;F&quot; rep(c(&quot;M&quot;,&quot;F&quot;), times=10) ## [1] &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; ## [20] &quot;F&quot; rep(c(&quot;M&quot;,&quot;F&quot;), length.out = 15) ## [1] &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; # or just length, for short rep(c(&quot;M&quot;,&quot;F&quot;), length = 15) ## [1] &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; # Notice that all these generated a character vector. To use as a &quot;factor&quot;, we would need to wrap it in the factor() function. factor(rep(c(&quot;M&quot;,&quot;F&quot;), each=10)) ## [1] M M M M M M M M M M F F F F F F F F F F ## Levels: F M # A function specifically for creating factors is the gl() function. gl = # &quot;generate levels&quot;. Below we generate a factor with 2 levels of 10 each and # labels of &quot;M&quot; and &quot;F&quot;. Notice the result is a factor. gl(n = 2, k = 10, labels = c(&quot;M&quot;,&quot;F&quot;)) ## [1] M M M M M M M M M M F F F F F F F F F F ## Levels: M F # A more common occurence is combinations of fixed levels, say gender, # education, and status. A function that helps create every combination of # levels is expand.grid(). Below we generate every combination of the levels # provided for gender, education, and status. Notice the first factors vary # fastest. expand.grid(gender=c(&quot;M&quot;,&quot;F&quot;), education=c(&quot;HS&quot;,&quot;College&quot;,&quot;Advanced&quot;), status=c(&quot;Single&quot;,&quot;Married&quot;,&quot;Divorced&quot;,&quot;Widowed&quot;)) ## gender education status ## 1 M HS Single ## 2 F HS Single ## 3 M College Single ## 4 F College Single ## 5 M Advanced Single ## 6 F Advanced Single ## 7 M HS Married ## 8 F HS Married ## 9 M College Married ## 10 F College Married ## 11 M Advanced Married ## 12 F Advanced Married ## 13 M HS Divorced ## 14 F HS Divorced ## 15 M College Divorced ## 16 F College Divorced ## 17 M Advanced Divorced ## 18 F Advanced Divorced ## 19 M HS Widowed ## 20 F HS Widowed ## 21 M College Widowed ## 22 F College Widowed ## 23 M Advanced Widowed ## 24 F Advanced Widowed # Notice that creates a data frame that we can save: DF &lt;- expand.grid(gender=c(&quot;M&quot;,&quot;F&quot;), education=c(&quot;HS&quot;,&quot;College&quot;,&quot;Advanced&quot;), status=c(&quot;Single&quot;,&quot;Married&quot;,&quot;Divorced&quot;,&quot;Widowed&quot;)) class(DF) ## [1] &quot;data.frame&quot; rm(DF) Or imagine an experiment where 3 people throw 3 different kinds of paper airplanes, made of 3 paper types (3x3 = 9 planes), throwing each plane 8 times. schedule &lt;- expand.grid(thrower=c(&quot;Clay&quot;,&quot;Rod&quot;,&quot;Kevin&quot;), paper=c(&quot;18&quot;, &quot;20&quot;, &quot;24&quot;), design=c(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;), rep=1:8) # Randomize and drop the rep column. The sample(nrow(schedule)) code scrambles the numbers 1 through 216, which I then use to randomly shuffle the schedule of throws. k &lt;- sample(nrow(schedule)) schedule &lt;- schedule[k,1:3] head(schedule, n = 10) ## thrower paper design ## 104 Rod 20 c ## 146 Rod 18 b ## 139 Clay 20 a ## 79 Clay 24 c ## 10 Clay 18 b ## 94 Clay 20 b ## 112 Clay 20 a ## 183 Kevin 18 c ## 196 Clay 24 a ## 35 Rod 24 a # output to csv file for logging &quot;distance flown&quot; data write.csv(schedule, file=&quot;throwLog.csv&quot;, row.names=FALSE) rm(k, schedule) This is a great way to set up an experiment, but I’d like to also add data for the throw, based on interesting distributions (normal, etc.). How would I generate samples for each contestant that was based on slightly different distributions? What sort of distribution? See this page to get a quick refresher on common distributions: https://www.analyticsvidhya.com/blog/2017/09/6-probability-distributions-data-science/. Note also that ?distributions gives you the distributions in {stats}. Persevere for a time. 11.5 generating numerical sequences # The seq() function allows you to generate sequences of numbers: seq(from = 0, to = 10, by = 2) ## [1] 0 2 4 6 8 10 seq(0, 10, 0.2) ## [1] 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 2.0 2.2 2.4 2.6 2.8 ## [16] 3.0 3.2 3.4 3.6 3.8 4.0 4.2 4.4 4.6 4.8 5.0 5.2 5.4 5.6 5.8 ## [31] 6.0 6.2 6.4 6.6 6.8 7.0 7.2 7.4 7.6 7.8 8.0 8.2 8.4 8.6 8.8 ## [46] 9.0 9.2 9.4 9.6 9.8 10.0 # Go backwards seq(1000, 0, -100) ## [1] 1000 900 800 700 600 500 400 300 200 100 0 # The seq() function has a length.out argument that allows you to specify the # size of the vector you want to create. It automatically calculates the # increment. We usually just abbreviate to length seq(1, 10, length = 30) ## [1] 1.000000 1.310345 1.620690 1.931034 2.241379 2.551724 2.862069 ## [8] 3.172414 3.482759 3.793103 4.103448 4.413793 4.724138 5.034483 ## [15] 5.344828 5.655172 5.965517 6.275862 6.586207 6.896552 7.206897 ## [22] 7.517241 7.827586 8.137931 8.448276 8.758621 9.068966 9.379310 ## [29] 9.689655 10.000000 # The colon operator(:) also allows you to generate regular sequences in steps # of 1. 1:10 ## [1] 1 2 3 4 5 6 7 8 9 10 10:-10 # reverse direction ## [1] 10 9 8 7 6 5 4 3 2 1 0 -1 -2 -3 -4 -5 -6 -7 -8 ## [20] -9 -10 # When used with factors, the colon operator generates an interaction factor: f1 &lt;- gl(n = 2, k = 3); f1 ## [1] 1 1 1 2 2 2 ## Levels: 1 2 f2 &lt;- gl(n = 3, k = 2, labels = c(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;)); f2 ## [1] a a b b c c ## Levels: a b c f1:f2 ## [1] 1:a 1:a 1:b 2:b 2:c 2:c ## Levels: 1:a 1:b 1:c 2:a 2:b 2:c rm(f1,f2) The last step seems akin to perfectly shuffling two decks of cards (the decks must be of equal length). 11.6 seq_along() and seq_len(). seq_along() returns the indices of a vector while seq_len(n) returns an integer vector of 1:n. seq_along(100:120) ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 seq_along(state.abb) ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ## [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 seq_len(12) ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 11.7 generating random data from a probability distribution A central idea in inferential statistics is that the distribution of data can often be approximated by a theoretical distribution. R provides functions for working with several well-known theoretical distributions, including the ability to generate data from those distributions. A common one is the rnorm() function which generates data from a Normal distribution. In R, the functions for theoretical distributions take the form of dxxx, pxxx, qxxx and rxxx. dxxx is for the probability density/mass function (dnorm) pxxx is for the cumulative distribution function (pnorm) qxxx is for the quantile function (qnorm) rxxx is for random variate generation (rnorm) For random variate generation we’re interested in the rxxx variety. 11.8 Normal distribution: # 10 random draws from N(100,5) rnorm(n = 10, mean = 100, sd = 5) ## [1] 101.27360 88.61725 112.49156 99.30521 103.86910 103.87714 100.71628 ## [8] 100.07492 102.82459 108.60936 11.9 Binomial distribution: # 10 random draws from b(1,0.5) # AKA, 10 coin flips (size is the number of trials) rbinom(n = 10, size = 1, prob = 0.5) ## [1] 1 0 1 0 1 1 1 0 1 1 # 10 random draws from b(1,0.8) # AKA, 10 coin flips with a coin loaded Heads (or Tails) 80% of time rbinom(n = 10, size = 1, prob = 0.8) ## [1] 0 1 1 1 1 1 1 1 1 1 # 10 random draws from b(10,0.5) # AKA, 10 results of 10 coin flips rbinom(n = 10, size = 10, prob = 0.5) ## [1] 9 4 8 6 2 6 5 4 4 5 # We can use a binomial distribution to simulate dichotmous answers such as # Yes/No or success/fail. Simulate a vector of responses where respondents are 65% likely to say Yes (1) versus No (0) rbinom(n = 10, size = 1, prob = 0.65) ## [1] 1 1 0 1 1 1 1 1 0 1 # could also just use sample sample(c(&quot;Y&quot;,&quot;N&quot;), size = 10, replace = TRUE, prob = c(.65, .35)) ## [1] &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; &quot;N&quot; &quot;Y&quot; 11.10 Uniform distribution # 10 random draws from a uniform distribution u(0,100) runif(10,0,100) ## [1] 50.34837 88.96280 18.03323 17.74219 99.83278 47.54181 63.35148 10.48299 ## [9] 52.38249 78.17431 # A uniform distribution can be good for random sampling. Let&#39;s say we want to sample about 10% of iris data: k &lt;- runif(nrow(iris),0,1) # [0,1] interval is default sbSamp &lt;- iris[k &lt; 0.1, ] # sample about 10% of rows dim(sbSamp) ## [1] 21 5 # dplyr does this as well without the need for runif; and it&#39;s precise in its # sampling fraction. sbSamp &lt;- dplyr::sample_frac(iris, 0.1) # sample exactly 10% of rows dim(sbSamp) ## [1] 15 5 rm(sbSamp, k) 11.11 Sampling from multiple distributions (building in a “difference”) The arguments to rxxx functions can take vectors! This means we can use one function call to generate draws from multiple distributions. # alternating random values from N(10,4) and N(100,40) rnorm(10, mean = c(2,100),sd = c(2,40)) ## [1] 2.602207 64.321100 2.032922 121.054752 3.694822 148.521727 ## [7] 6.572839 106.641653 -1.274637 112.095525 # 30 random draws, 10 each from N(10,4), N(90,4) and N(400,4) rnorm(30, mean = rep(c(10,90,400),each=10), sd = 4) ## [1] 13.442189 11.814276 8.042744 11.032804 6.725487 7.644664 ## [7] 15.005589 7.799846 9.824663 2.408001 91.457085 86.801938 ## [13] 93.875747 87.623842 80.591457 97.105845 85.647415 87.239971 ## [19] 90.069110 95.125852 400.054585 405.090048 396.088488 412.025435 ## [25] 398.472211 403.735081 402.763459 401.535412 402.840150 397.813341 # 100 random draws, 50 each from b(5,0.5) and b(50,0.5) rbinom(n = 100, size = rep(c(5,50),each=50), prob = 0.5) ## [1] 3 3 2 2 1 5 2 3 3 2 0 2 3 4 3 2 3 1 2 1 2 2 4 3 4 ## [26] 4 1 3 3 4 4 1 0 3 2 3 3 3 4 5 3 0 3 2 1 2 2 5 1 1 ## [51] 26 26 23 25 24 25 20 22 29 24 28 23 22 24 25 26 23 27 25 30 28 20 27 22 22 ## [76] 24 31 28 21 25 31 21 19 26 20 24 24 31 33 23 26 25 26 24 25 19 25 23 25 24 # Combined with matrix(), one can generate &quot;multiple&quot; random samples from a # distribution. For example, draw 5 random samples of size 10 from a N(10,1): matrix(rnorm(10*5,10,1),ncol=5) ## [,1] [,2] [,3] [,4] [,5] ## [1,] 9.447972 9.538527 9.696858 9.759624 10.780563 ## [2,] 9.186559 8.195187 10.005517 9.681449 11.507238 ## [3,] 10.154476 9.539031 9.816230 9.542359 8.672465 ## [4,] 9.269497 11.519775 9.330705 10.654095 10.296286 ## [5,] 9.887437 10.051347 9.204726 9.646104 9.201882 ## [6,] 10.204350 10.380006 8.620772 9.134985 8.987121 ## [7,] 7.680437 8.269766 8.899391 9.975712 8.768231 ## [8,] 10.130204 9.136561 8.210755 10.485433 8.617155 ## [9,] 10.580088 8.363873 11.332057 11.925225 10.130335 ## [10,] 10.495338 7.587297 8.773753 12.057087 9.040655 Note that in the last example, we technically drew one sample of size 50 and then laid it out in a 10x5 matrix. 11.12 The good stuff: building in a difference based on a categorical variable Using ifelse() we can generate different data based on a TRUE/FALSE condition. Let’s say we have treated and untreated subjects. I’d like to generate Normal data that differs based on the treatment. trtmt &lt;- sample(c(&quot;Treated&quot;,&quot;Untreated&quot;), size = 20, replace = TRUE) ifelse(trtmt==&quot;Treated&quot;, yes = rnorm(20, 10, 1), no = rnorm(20, 20, 1)) ## [1] 11.269806 21.174261 19.671301 21.154222 10.841186 19.213505 18.774548 ## [8] 20.011264 11.944670 7.922051 9.684268 8.993571 10.883327 9.937337 ## [15] 10.794244 11.805633 19.555977 19.877443 9.056013 11.552978 Notice we have to make the length of the yes/no arguments the SAME LENGTH as the trtmt==“Treated” logical vector! What happens if we use rnorm(n=1,…)? # What about more than two groups? n &lt;- 200 trtmt &lt;- sample(LETTERS[1:6], size = n, replace = TRUE) # Say we want to generate differnt Normal data for each group. One way is to do a for-loop with multiple if statements: val &lt;- numeric(n) # empty vector for(i in seq_along(trtmt)){ if(trtmt[i]==&quot;A&quot;) val[i] &lt;- rnorm(1, 10, 2) else if(trtmt[i]==&quot;B&quot;) val[i] &lt;- rnorm(1, 20, 4) else if(trtmt[i]==&quot;C&quot;) val[i] &lt;- rnorm(1, 30, 6) else if(trtmt[i]==&quot;D&quot;) val[i] &lt;- rnorm(1, 40, 8) else if(trtmt[i]==&quot;E&quot;) val[i] &lt;- rnorm(1, 50, 10) else val[i] &lt;- rnorm(1, 60, 12) } val ## [1] 45.992560 48.982344 49.399854 45.516514 10.676699 35.124499 20.265080 ## [8] 47.581770 14.878112 45.413712 11.357480 63.283800 9.883827 28.293539 ## [15] 60.452161 32.656760 56.514417 51.838345 43.936117 30.027446 19.263259 ## [22] 60.464722 63.459196 46.499838 35.106385 67.213020 10.880616 24.836219 ## [29] 62.951318 89.467154 28.839372 10.606887 5.211013 49.459236 64.947507 ## [36] 48.794828 20.073872 46.111825 27.683859 29.258611 20.240426 49.183589 ## [43] 55.414896 46.574597 20.929737 30.073268 50.181540 36.626265 15.108838 ## [50] 47.421117 30.012539 10.100785 38.004888 9.744244 61.651021 75.028867 ## [57] 55.459792 49.772753 15.975207 56.759800 41.536383 78.139842 30.186176 ## [64] 43.845403 34.957620 23.563697 16.424558 45.234899 9.567564 18.155764 ## [71] 55.902732 9.928592 20.463486 17.218049 20.478613 52.111570 61.458349 ## [78] 52.741171 43.880201 64.295319 38.250871 46.807814 37.701207 42.894603 ## [85] 58.527341 51.387697 28.061232 68.022564 47.817200 61.532431 18.916613 ## [92] 20.586886 12.796927 60.817507 67.262284 52.793643 56.362606 10.453136 ## [99] 55.355385 79.775377 55.885538 6.321130 10.455023 34.372688 45.210716 ## [106] 24.578482 43.647554 38.997247 40.825033 26.945351 74.393373 54.967133 ## [113] 9.087258 6.307758 48.193639 16.632089 34.264439 48.386827 21.224931 ## [120] 52.889906 9.821750 8.678911 32.942246 56.441727 47.632831 10.825619 ## [127] 15.379115 46.287730 34.448537 9.895360 10.866303 22.072714 45.391778 ## [134] 32.606082 44.783565 39.484887 8.706220 7.871810 46.643885 32.989702 ## [141] 8.637186 22.168010 19.144363 29.931845 45.358880 8.253083 25.792824 ## [148] 27.801426 27.684344 65.556022 55.246059 17.254815 45.860939 24.928664 ## [155] 9.881571 11.145898 67.372791 12.729997 30.948257 14.646221 16.711073 ## [162] 12.884234 38.626557 54.663416 38.333691 41.236715 32.247244 26.350852 ## [169] 24.071387 59.131274 6.512511 11.718129 58.977558 35.766888 30.624316 ## [176] 46.158992 25.097236 34.060443 30.777397 67.000129 58.627577 22.697905 ## [183] 26.059931 45.623929 46.444505 14.620989 11.054679 26.315198 44.605097 ## [190] 57.882760 48.632574 47.737238 15.249730 16.429656 6.217521 54.898402 ## [197] 16.285624 27.310308 30.218217 33.461003 A more R-like way would be to take advantage of vectorized functions. First create a data frame with one row for each group and the mean and standard deviations we want to use to generate the data for that group. dat &lt;- data.frame(g=LETTERS[1:6],mean=seq(10,60,10),sd=seq(2,12,2)) dat ## g mean sd ## 1 A 10 2 ## 2 B 20 4 ## 3 C 30 6 ## 4 D 40 8 ## 5 E 50 10 ## 6 F 60 12 dat is currently a petite little dataframe of 6 rows. Now sample the row numbers (1 - 6) WITH replacement. We can use these to randomly sample the data frame rows. ASIDE: Recall that we can repeatedly call a row or element using subsetting brackets. For example, call the first row of iris 5 times: iris[c(1,1,1,1,1),] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 1.1 5.1 3.5 1.4 0.2 setosa ## 1.2 5.1 3.5 1.4 0.2 setosa ## 1.3 5.1 3.5 1.4 0.2 setosa ## 1.4 5.1 3.5 1.4 0.2 setosa Let’s exploit that to randomly sample with replacement our data frame of groups: n &lt;- 200 k &lt;- sample(1:6, n, replace = TRUE) dat &lt;- dat[k,] str(dat) ## &#39;data.frame&#39;: 200 obs. of 3 variables: ## $ g : chr &quot;B&quot; &quot;A&quot; &quot;F&quot; &quot;E&quot; ... ## $ mean: num 20 10 60 50 10 20 40 20 50 20 ... ## $ sd : num 4 2 12 10 2 4 8 4 10 4 ... # Now generate our data for each group using ONE call to rnorm. dat$vals &lt;- rnorm(n, mean=dat$mean, sd=dat$sd) head(dat) ## g mean sd vals ## 2 B 20 4 23.728101 ## 1 A 10 2 11.588683 ## 6 F 60 12 67.188632 ## 5 E 50 10 43.799144 ## 1.1 A 10 2 9.971849 ## 2.1 B 20 4 19.147462 This is pretty neat. We go from one little dataframe to a larger one in a few lines of code. Mean and SD can be varied by the class, “g” in this case. 11.13 A demonstration of the Central Limit Theorem The Central Limit Theorem states that the sum of a large number of independent random variables will be approximately normally distributed almost regardless of their individual distributions. We can demonstrate this using various rxxx functions. # sum 6 values from 6 different distributions (sample size = 6) n &lt;- 1e4 # simulate 1000 times clt &lt;- rexp(n, rate = 1) + rbinom(n,10,0.4) + rchisq(n,df = 6) + rnorm(n, 12, 12) + rpois(n, lambda = 3) + rt(n, df = 7) hist(clt, freq=FALSE) # overlay a normal density curve X &lt;- seq(min(clt),max(clt),length = 500) # x Y &lt;- dnorm(X, mean = mean(clt), sd = sd(clt)) # f(x) = dnorm lines(X,Y,type = &quot;l&quot;, col=&quot;blue&quot;) # plot (x,y) coordinates as a &quot;blue&quot; line (&quot;l&quot;) rm(X, Y, clt) Let’s unpack some of this: clt1 &lt;- rexp(n, rate = 1) hist(clt1, freq=FALSE) clt2 &lt;- rbinom(n,10,0.4) hist(clt2, freq=FALSE) clt3 &lt;- rchisq(n,df = 6) hist(clt3, freq=FALSE) clt4 &lt;-rnorm(n, 12, 12) hist(clt4, freq=FALSE) clt5 &lt;- rpois(n, lambda = 3) hist(clt5, freq=FALSE) clt6 &lt;- rt(n, df = 7) hist(clt6, freq=FALSE) # All of this base R graphing is clunky and doesn&#39;t lend itself to modification as well as ggplot() figures. library(tidyverse) df &lt;- data.frame(clt1, clt2, clt3, clt4, clt5, clt6) df %&gt;% ggplot(aes(clt3)) + geom_histogram(bins = 30) df %&gt;% ggplot(aes(clt3)) + geom_density() 11.14 Overlaying normal curve on histogram The following solution was on StackOverflow at https://stackoverflow.com/questions/6967664/ggplot2-histogram-with-normal-curve set.seed(1) df1 &lt;- data.frame(PF = 10*rnorm(1000)) ggplot(df1, aes(x = PF)) + geom_histogram(aes(y =..density..), breaks = seq(-40, 40, by = 5), colour = &quot;black&quot;, fill = &quot;white&quot;) + stat_function(fun = dnorm, args = list(mean = mean(df1$PF), sd = sd(df1$PF)), color = &quot;blue&quot;) From the {ggplot2} help: “This stat makes it easy to superimpose a function on top of an existing plot. The function is called with a grid of evenly spaced values along the x axis, and the results are drawn (by default) with a line.” Note how stat_function() lends itself to quick addition: simply feed the correct fun and args to the function. Now accomplish this for clt3 ggplot(df, aes(x = clt3)) + geom_histogram(aes(y =..density..), breaks = seq(0, 30, by = 1), colour = &quot;black&quot;, fill = &quot;white&quot;) + stat_function(fun = dchisq, args = list(df = 6), color = &quot;blue&quot;) + labs(title = &quot;chi-squared distribution&quot;) Note how the args in dchisq includes only the df = 6. No mean needs to be calculated (as in dnorm). Now accomplish this for clt1 ggplot(df, aes(x = clt1)) + geom_histogram(aes(y =..density..), breaks = seq(0, 8, by = .5), colour = &quot;black&quot;, fill = &quot;white&quot;) + stat_function(fun = dexp, args = list(rate = 1), color = &quot;blue&quot;) + labs(title = &quot;exponential distribution&quot;) "],
["functions.html", "Chapter 12 Functions", " Chapter 12 Functions library(tidyverse) From R4DS and the Solution book for R4DS: x &lt;- c(1:10, rep(NA,3)) cV &lt;- function(x){ sd(x, na.rm = TRUE)/mean(x, na.rm = TRUE) } xVar &lt;- function(x) { n &lt;- length(x[!is.na(x)]) m &lt;- mean(x, na.rm = TRUE) sq_err &lt;- (x - m)^2 sum(sq_err, na.rm = TRUE) / (n - 1) } From Richie Cotton’s DataCamp introductory course on function writing: roll_die &lt;- function(n_die){ die_sides &lt;- 1:6 sample(die_sides, n_die, replace = TRUE) } roll_die(6) ## [1] 3 3 2 6 4 5 Let’s apply some of these simple ideas to D&amp;D. Say I play a character that can cast the sleep spell. This scales to different levels. At first level, one rolls 5 six-sided die. sleep &lt;- function(){ sum(sample(1:8, size = 5, replace = TRUE)) } sleep() ## [1] 28 If cast at higher levels, the spell adds 2 die per level above first: 7 die at second level, 9 die at third level, etc. Let’s address this by adding a level variable to our function. sleep_scaled &lt;- function(level){ if(level &gt; 1){add_die = (level-1)*2 } else{ add_die = 0 } sum(sample(1:8, size = 5 + add_die, replace = TRUE)) } A couple of things can be added to avoid the following goofy mishaps (or at least render useful error codes: sleep_scaled(0) ## [1] 27 # sleep_scaled(&quot;rex&quot;) First we load Richie Cotton’s package {assertive}. library(assertive) ## ## Attaching package: &#39;assertive&#39; ## The following objects are masked from &#39;package:magrittr&#39;: ## ## is_greater_than, is_less_than ## The following objects are masked from &#39;package:purrr&#39;: ## ## is_atomic, is_character, is_double, is_empty, is_formula, ## is_function, is_integer, is_list, is_logical, is_null, is_numeric, ## is_vector ## The following object is masked from &#39;package:tibble&#39;: ## ## has_rownames Then we get to work on the function: sleep_scaled &lt;- function(level = 1){ # assert_is_numeric(level) if(any(is_non_positive(level))){ return(&quot;x contains nonpositive values, so the spell makes no sense&quot;) } if(level &gt; 1){add_die = (level-1)*2 } else{ add_die = 0 } sum(sample(1:8, size = 5 + add_die, replace = TRUE)) } sleep_scaled(0) ## [1] &quot;x contains nonpositive values, so the spell makes no sense&quot; sleep_scaled() ## [1] 23 sleep_scaled(2) ## [1] 28 # sleep_scaled(&quot;joseph&quot;) Now, it would be useful to see the distribution of these rolls, to predict whether the spell would be effective. hist(replicate(10000, sleep_scaled()), breaks = 70) "],
["relativerisk.html", "Chapter 13 Relative versus absolute risk: display", " Chapter 13 Relative versus absolute risk: display The following is adopted from https://www.r-bloggers.com/lying-with-statistics-one-beer-a-day-will-kill-you/ personograph allows for cute displays of individuals in big groups library(personograph) ## Loading required package: grImport ## Loading required package: grid ## Loading required package: XML library(tidyverse) Start with 2000 people. Some of them will have problems without alcohol exposure, about 18, in fact. The blogger choses 2000 people to start with because \\(0.7*18=1\\) Note that this doesn’t stratify for any other health problems, age, socio-economic status, etc. n &lt;- 2000 probl_wo_alc &lt;- 18 / n data &lt;- list(first = probl_wo_alc, second = 1-probl_wo_alc) personograph(data, colors = list(first = &quot;black&quot;, second = &quot;#efefef&quot;), fig.title = &quot;18 of 2000 people with health problems&quot;, draw.legend = FALSE, n.icons = n, dimensions = c(20, 100), plot.width = 0.97) Now we illustrate the affect of 500 mL of alcohol per day. According to the Lancet article, the relative risk of serious illness following consumption of about 25 mL ethanol (500 mL beer at 5% ABV) increases by about 7%. probl_w_alc &lt;- 1 / n data_2 &lt;- list(first = probl_wo_alc, second = probl_w_alc, third = 1-(probl_wo_alc+probl_w_alc)) personograph(data_2, colors = list(first = &quot;black&quot;, second = &quot;red&quot;, third = &quot;#efefef&quot;), fig.title = &quot;About 1 additional case with half a litre of beer per day&quot;, draw.legend = FALSE, n.icons = n, dimensions = c(20, 100), plot.width = 0.97) "],
["references.html", "References", " References "],
["dimensionalityreduction.html", "Chapter 14 Dimensionality Reduction 14.1 Experiment in showing dimensionality reduction for pathologists", " Chapter 14 Dimensionality Reduction library(tidyverse) library(plot3D) 14.1 Experiment in showing dimensionality reduction for pathologists df &lt;- tibble( diagnostic_class = rep(letters[1:3], 100), x = rnorm(300, mean = 1, sd = 0.1), y = rnorm(300, mean = 1, sd = 0.1), z = rnorm(300, mean = 1, sd = 0.1) ) scatter3D(df$x, df$y, df$z) "]
]
