[
["index.html", "Bill’s Drills Book Chapter 1 Drills: Part of Every Healthy Intellectual Diet", " Bill’s Drills Book William McDonald 2020-05-13 Chapter 1 Drills: Part of Every Healthy Intellectual Diet The goal of this book is to organize my R drills into reasonable chunks, the better to understand my strengths and weaknesses, and to plan new forays into data science. "],
["bookdownplan.html", "Chapter 2 bookdown Tips for This Document 2.1 Basic conventions 2.2 Referencing other parts of the document 2.3 Inserting pictures 2.4 Referencing citations:", " Chapter 2 bookdown Tips for This Document 2.1 Basic conventions the _bookdown.yml file contains a snippet that is important to inserting the word “Chapter” before the chapter number in each of the Rmd files. packages are indicated in bold, like dplyr inline code and filenames are indicated in typerwriter face using backticks, like _bookdown.yml _output.yml is modified from that used by Xie in his bookdown-demo (Xie 2020); it evokes style.css, toc.css, preamble.tex, which are also borrowed from Xie. chapters are set in order by using adding 01, 02, 03, … before the name of their Rmd, like 01chpter.Rmd. Note that they can have short descriptive phrases, since the actual chapter titles are determined by the hashtag. index.Rmd always comes first in the book build, and contains the yml front matter. 2.2 Referencing other parts of the document This is a good place to practice referencing figures. Say that I want to refer the reader back to my first starwars figure. See Figure 3.1. I can reference other pages in a similar fashion. See Chapter 10. Note that this works by referencing a {#label} placed in the chapter title. See Chapter 1 See Chapter 3 Note that the {#label} uses a single run-together word. It does not tolerate spaces and this cannot be overcome by ‘quoting’ it. 2.3 Inserting pictures Pictures can be included in the test-book_files subdirectories and referenced like this: Tpit immunohistochemical stain. Figure A silent corticotroph. Figure B gonadotroph Some of the subdirectories throw an error in building the book, so I settled on _bookdown_files/pathologyImages as the location. Also, I note that the build does not generate the caption unless the reference is on it’s own line. Also note that some controls on image size are available. For instance, the same image can be displayed at 50% size: Tpit immunohistochemical stain. Figure A silent corticotroph. Figure B gonadotroph 2.4 Referencing citations: In order to insert citations, one needs a .bib file in the project. I’ve included one in this project as book.bib. The yml header in Chapter 1 needs to have a \\(bibliography:\\) and \\(biblio-style:\\) line added. To insert a citation, use the citr Addin from RStudio. bookdown, for instance, is cited thusly (Xie 2020). Note that I need to figure out an adequate workflow of references. The convenience of Endnote in MS Word will not be available. Nonetheless, if I populate the book.bib and packages.bib files carefully, with .txt files generated in Endnote, I should be OK. For instance, a recent dump of my Endnote library is in bookFromEndnote.txt. This can be opened in RStudio, and I can copy-and-paste references from the .txt file to my book.bib. For instance, if I have a breast paper that I want to cite here (Stevens and Parekh 2016), I’d copy-and-paste the reference from bookFromEndnote.txt to book.bib. Of note, Yihui Xie includes a nifty bit of code to automatically generate a bib database for R packages: knitr::write_bib(c(.packages(), &#39;bookdown&#39;, &#39;knitr&#39;, &#39;rmarkdown&#39;, &#39;tidyverse&#39;, &#39;ComplexHeatmap&#39;), &#39;packages.bib&#39;) References appear automatically at the end of a chapter. References "],
["dataexploration.html", "Chapter 3 Data Exploration 3.1 Counting things. The naming of parts. 3.2 Summarize is another very useful function:", " Chapter 3 Data Exploration Data exploration is one of the most important aspects of data science and forms the cornerstone of my drills. Nonetheless, I have lots of room for improvement. I like Hadely Wickham’s writing and find his approach exceptionally clear. Therefore, I’ll use the tidyverse. library(tidyverse) 3.1 Counting things. The naming of parts. starwars %&gt;% filter(!is.na(species)) %&gt;% count(species = fct_lump(species, 5), sort = TRUE) %&gt;% mutate(species = fct_reorder(species, n)) %&gt;% ggplot(aes(species, n)) + geom_col() + coord_flip() Figure 3.1: Starwars Figure 1 I like stacked bars for their economy, but it’s easy to over do it. Supperimposing gender onto the columns seems easy… starwars %&gt;% filter(!is.na(species)) %&gt;% count(species = fct_lump(species, 5), gender = fct_lump(gender, 2), sort = TRUE) %&gt;% mutate(species = fct_reorder(species, n)) %&gt;% ggplot(aes(species, n, fill = gender)) + geom_col() + coord_flip() ## Warning: Factor `gender` contains implicit NA, consider using ## `forcats::fct_explicit_na` Figure 3.2: Starwars Figure 2 But note that I’ve got a problem: the Droids, which outnumber the Gungans, are now reordered to after the Gungans. This happens because the \\(n\\) that we’re counting comprises subcategories of species and gender. Only three Gungan males exist (and no females), but that is enough to tie the Droid NA category. The Droid NA category come after the Gungan category, presumably because male comes before NA, or because NA comes last (more likely). Exploring this, I see that I’m getting warning messages about the implicit NA’s in gender. Note that the following renders a slightly different plot. I still have not fixed the order of the species. starwars %&gt;% filter(!is.na(species)) %&gt;% count(species = fct_lump(species, 5), gender = fct_lump(gender, 2), sort = TRUE) %&gt;% mutate(gender = fct_explicit_na(gender), species = fct_reorder(species, n)) %&gt;% ggplot(aes(species, n, fill = gender)) + geom_col() + coord_flip() ## Warning: Factor `gender` contains implicit NA, consider using ## `forcats::fct_explicit_na` Figure 3.3: Starwars Figure 3 The trick here is to use group_by() and ungroup() wisely. starwars %&gt;% filter(!is.na(species)) %&gt;% mutate(species = fct_lump(species, 5)) %&gt;% group_by(species) %&gt;% mutate(typeCount = n()) %&gt;% ungroup() %&gt;% mutate(species = fct_reorder(species, typeCount)) %&gt;% ggplot()+ geom_bar(aes(species, fill = gender))+ coord_flip() Figure 3.4: Starwars Figure 4 As opposed to using count(), which progressively narrows the information available to be used, by using group_by()/mutate()/ungroup() with geom_bar() we have all of the variables still available for plotting. 3.2 Summarize is another very useful function: starwars %&gt;% filter(!(is.na(species))) %&gt;% group_by(species) %&gt;% summarize(n=n(), mean = mean(height, na.rm = TRUE)) %&gt;% arrange(desc(n)) ## # A tibble: 37 x 3 ## species n mean ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Human 35 177. ## 2 Droid 5 140 ## 3 Gungan 3 209. ## 4 Kaminoan 2 221 ## 5 Mirialan 2 168 ## 6 Twi&#39;lek 2 179 ## 7 Wookiee 2 231 ## 8 Zabrak 2 173 ## 9 Aleena 1 79 ## 10 Besalisk 1 198 ## # … with 27 more rows "],
["sampling.html", "Chapter 4 Sampling 4.1 Think about throwing a bunch of dice. 4.2 A keen way to divide up a dataset into testing and training components.", " Chapter 4 Sampling 4.1 Think about throwing a bunch of dice. sample(1:6, size=100, replace=TRUE) ## [1] 1 5 6 6 2 3 1 2 3 2 3 1 1 6 5 3 5 6 3 5 2 6 2 2 5 3 6 1 3 3 3 5 3 5 1 4 3 ## [38] 2 3 2 3 6 6 6 5 3 3 4 1 3 6 1 1 1 3 6 2 3 2 3 1 6 2 1 4 4 2 6 5 6 2 1 1 5 ## [75] 6 6 5 5 3 2 1 2 1 2 1 5 5 3 5 3 4 1 6 3 2 5 5 6 4 6 sample(1:6, size=100, replace=TRUE) %&gt;% table() ## . ## 1 2 3 4 5 6 ## 17 14 17 14 19 19 sample(1:6, size=100, replace=TRUE) %&gt;% table() %&gt;% prop.table() ## . ## 1 2 3 4 5 6 ## 0.13 0.14 0.14 0.19 0.10 0.30 4.2 A keen way to divide up a dataset into testing and training components. x &lt;- 1:10 y &lt;- 11:30 df &lt;- data.frame(x,y) df ## x y ## 1 1 11 ## 2 2 12 ## 3 3 13 ## 4 4 14 ## 5 5 15 ## 6 6 16 ## 7 7 17 ## 8 8 18 ## 9 9 19 ## 10 10 20 ## 11 1 21 ## 12 2 22 ## 13 3 23 ## 14 4 24 ## 15 5 25 ## 16 6 26 ## 17 7 27 ## 18 8 28 ## 19 9 29 ## 20 10 30 set.seed(0) train_indexes = sample(1:nrow(df), .7 * nrow(df)) train_set &lt;- df[train_indexes,] test_set &lt;- df[-train_indexes,] train_set ## x y ## 14 4 24 ## 4 4 14 ## 7 7 17 ## 1 1 11 ## 2 2 12 ## 13 3 23 ## 18 8 28 ## 11 1 21 ## 16 6 26 ## 15 5 25 ## 3 3 13 ## 17 7 27 ## 5 5 15 ## 8 8 18 test_set ## x y ## 6 6 16 ## 9 9 19 ## 10 10 20 ## 12 2 22 ## 19 9 29 ## 20 10 30 "],
["factorpractice.html", "Chapter 5 Factor Practice", " Chapter 5 Factor Practice cups &lt;- c(&quot;small&quot;, &quot;medium&quot;, &quot;large&quot;) manyCups &lt;- sample(cups, size = 100, replace = TRUE) sizesCups &lt;- factor(manyCups, levels = c(&quot;small&quot;, &quot;medium&quot;, &quot;large&quot;)) sizesCups ## [1] medium medium medium medium large small large small small small ## [11] small medium small small medium medium medium small large small ## [21] large medium medium medium medium large medium small large medium ## [31] small small large medium medium large large medium medium medium ## [41] medium small medium medium medium medium small large large medium ## [51] large large medium large large small small small small large ## [61] medium large small small medium small small small small large ## [71] medium small small large large large medium medium medium large ## [81] medium medium large large large small medium medium small large ## [91] large medium large medium small medium small large large small ## Levels: small medium large "],
["crossingtrial.html", "Chapter 6 Crossing Trial", " Chapter 6 Crossing Trial From David Robinson birthday paradox Rblogger at https://www.r-bloggers.com/the-birthday-paradox-puzzle-tidy-simulation-in-r/ summarized &lt;- crossing(people = seq(2, 50, 2), trial = 1:100) %&gt;% mutate(birthday = map(people, ~ sample(365, .x, replace = TRUE)), multiple = map_lgl(birthday, ~ any(duplicated(.x)))) %&gt;% group_by(people) %&gt;% summarize(chance = mean(multiple)) ggplot(summarized, aes(people, chance)) + geom_line() + scale_y_continuous(labels = scales::percent_format()) + labs(y = &quot;Probability two have the same birthday&quot;) # Checking the work with pbirthday function summarized %&gt;% mutate(exact = map_dbl(people, pbirthday)) %&gt;% ggplot(aes(people, chance)) + geom_line() + geom_line(aes(y = exact), lty = 2, color = &quot;blue&quot;) + scale_y_continuous(labels = scales::percent_format()) + labs(y = &quot;Probability two have the same birthday&quot;) "],
["changenames.html", "Chapter 7 By Any Other Name", " Chapter 7 By Any Other Name This deceptively simple-seeming idea gets complex quickly. The following YouTube was a nice description of the process: https://www.youtube.com/watch?v=Okc0IL5uTnA my.data &lt;- data.frame(colOne=1:3, column2=4:6, column_3=7:9) rownames(my.data) &lt;- c(&quot;ant&quot;, &quot;bee&quot;, &quot;cat&quot;) names(my.data) ## [1] &quot;colOne&quot; &quot;column2&quot; &quot;column_3&quot; colnames(my.data) ## [1] &quot;colOne&quot; &quot;column2&quot; &quot;column_3&quot; #make some changes names(my.data) &lt;- c(&quot;col_1&quot;, &quot;col_2&quot;, &quot;col_3&quot;) my.data ## col_1 col_2 col_3 ## ant 1 4 7 ## bee 2 5 8 ## cat 3 6 9 names(my.data)[3] &lt;- &quot;col.3&quot; my.data ## col_1 col_2 col.3 ## ant 1 4 7 ## bee 2 5 8 ## cat 3 6 9 names(my.data)[names(my.data)==&quot;col_2&quot;] ## [1] &quot;col_2&quot; my.data[&quot;col_2&quot;] ## col_2 ## ant 4 ## bee 5 ## cat 6 my.data$col_2 ## [1] 4 5 6 my.data[,2] ## [1] 4 5 6 names(my.data)[names(my.data)==&quot;col_2&quot;] &lt;- &quot;col.2&quot; my.data ## col_1 col.2 col.3 ## ant 1 4 7 ## bee 2 5 8 ## cat 3 6 9 names(my.data) &lt;- gsub(&quot;_&quot;, &quot;.&quot;, names(my.data)) my.data ## col.1 col.2 col.3 ## ant 1 4 7 ## bee 2 5 8 ## cat 3 6 9 rownames(my.data) ## [1] &quot;ant&quot; &quot;bee&quot; &quot;cat&quot; my.data$species &lt;- rownames(my.data) my.data ## col.1 col.2 col.3 species ## ant 1 4 7 ant ## bee 2 5 8 bee ## cat 3 6 9 cat rownames(my.data) &lt;- NULL my.data ## col.1 col.2 col.3 species ## 1 1 4 7 ant ## 2 2 5 8 bee ## 3 3 6 9 cat colnames(my.data) &lt;- c(&quot;good&quot;, &quot;better&quot;, &quot;best&quot;, &quot;species&quot;) my.data ## good better best species ## 1 1 4 7 ant ## 2 2 5 8 bee ## 3 3 6 9 cat keep &lt;- 2:ncol(my.data) my.data[,keep] ## better best species ## 1 4 7 ant ## 2 5 8 bee ## 3 6 9 cat "],
["correlation.html", "Chapter 8 Correlation Plots", " Chapter 8 Correlation Plots head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa iris %&gt;% select(-Species) %&gt;% cor() ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Sepal.Length 1.0000000 -0.1175698 0.8717538 0.8179411 ## Sepal.Width -0.1175698 1.0000000 -0.4284401 -0.3661259 ## Petal.Length 0.8717538 -0.4284401 1.0000000 0.9628654 ## Petal.Width 0.8179411 -0.3661259 0.9628654 1.0000000 M &lt;- iris %&gt;% select(-Species) %&gt;% cor(method = &quot;kendall&quot;) corrplot::corrplot(M) corrplot::corrplot(M, method = &quot;color&quot;) corrplot::corrplot(M, method = &quot;color&quot;, type = &quot;upper&quot;) corrplot::corrplot(M, method = &quot;color&quot;, type = &quot;upper&quot;, order = &quot;hclust&quot;) corrplot::corrplot(M, method = &quot;color&quot;, type = &quot;upper&quot;, order = &quot;hclust&quot;, addCoef.col = &quot;black&quot;) corrplot::corrplot(M, method = &quot;color&quot;, type = &quot;upper&quot;, order = &quot;hclust&quot;, addCoef.col = &quot;black&quot;, tl.col=&quot;black&quot;) corrplot::corrplot(M, method = &quot;color&quot;, type = &quot;upper&quot;, order = &quot;hclust&quot;, addCoef.col = &quot;black&quot;, tl.col=&quot;black&quot;, tl.srt = 45) "],
["ifelsecasewhen.html", "Chapter 9 if_else() and case_when(): Comparison 9.1 case_when() 9.2 Compare this with if_else()", " Chapter 9 if_else() and case_when(): Comparison 9.1 case_when() case_when() from https://www.rdocumentation.org/packages/dplyr/versions/0.7.8/topics/case_when x &lt;- 1:50 y &lt;- 51:100 df &lt;- data.frame(x,y) df ## x y ## 1 1 51 ## 2 2 52 ## 3 3 53 ## 4 4 54 ## 5 5 55 ## 6 6 56 ## 7 7 57 ## 8 8 58 ## 9 9 59 ## 10 10 60 ## 11 11 61 ## 12 12 62 ## 13 13 63 ## 14 14 64 ## 15 15 65 ## 16 16 66 ## 17 17 67 ## 18 18 68 ## 19 19 69 ## 20 20 70 ## 21 21 71 ## 22 22 72 ## 23 23 73 ## 24 24 74 ## 25 25 75 ## 26 26 76 ## 27 27 77 ## 28 28 78 ## 29 29 79 ## 30 30 80 ## 31 31 81 ## 32 32 82 ## 33 33 83 ## 34 34 84 ## 35 35 85 ## 36 36 86 ## 37 37 87 ## 38 38 88 ## 39 39 89 ## 40 40 90 ## 41 41 91 ## 42 42 92 ## 43 43 93 ## 44 44 94 ## 45 45 95 ## 46 46 96 ## 47 47 97 ## 48 48 98 ## 49 49 99 ## 50 50 100 case_when( x %% 35 == 0 ~ &quot;fizz buzz&quot;, x %% 5 == 0 ~ &quot;fizz&quot;, x %% 7 == 0 ~ &quot;buzz&quot;, TRUE ~ as.character(x) ) ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;fizz&quot; &quot;6&quot; ## [7] &quot;buzz&quot; &quot;8&quot; &quot;9&quot; &quot;fizz&quot; &quot;11&quot; &quot;12&quot; ## [13] &quot;13&quot; &quot;buzz&quot; &quot;fizz&quot; &quot;16&quot; &quot;17&quot; &quot;18&quot; ## [19] &quot;19&quot; &quot;fizz&quot; &quot;buzz&quot; &quot;22&quot; &quot;23&quot; &quot;24&quot; ## [25] &quot;fizz&quot; &quot;26&quot; &quot;27&quot; &quot;buzz&quot; &quot;29&quot; &quot;fizz&quot; ## [31] &quot;31&quot; &quot;32&quot; &quot;33&quot; &quot;34&quot; &quot;fizz buzz&quot; &quot;36&quot; ## [37] &quot;37&quot; &quot;38&quot; &quot;39&quot; &quot;fizz&quot; &quot;41&quot; &quot;buzz&quot; ## [43] &quot;43&quot; &quot;44&quot; &quot;fizz&quot; &quot;46&quot; &quot;47&quot; &quot;48&quot; ## [49] &quot;buzz&quot; &quot;fizz&quot; 9.2 Compare this with if_else() if_else(x %% 2 == 0, &quot;even&quot;, &quot;odd&quot;) ## [1] &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; ## [11] &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; ## [21] &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; ## [31] &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; ## [41] &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; &quot;odd&quot; &quot;even&quot; "],
["subset.html", "Chapter 10 Subsetting 10.1 Subsetting using brackets 10.2 Subset using brackets by omitting the rows and columns we don’t want 10.3 Subset using brackets in combination with the which() function and the %in% operator 10.4 Subset using the subset() function 10.5 Subset using dyplyr’s filter() and select()", " Chapter 10 Subsetting From https://www.r-bloggers.com/5-ways-to-subset-a-data-frame-in-r/ Note: since this is down for maintenance, I will turn off evaluation on these chunks: education &lt;- read.csv(&quot;https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/education.csv&quot;, stringsAsFactors = FALSE) colnames(education) &lt;- c(&quot;X&quot;,&quot;State&quot;,&quot;Region&quot;,&quot;Urban.Population&quot;,&quot;Per.Capita.Income&quot;,&quot;Minor.Population&quot;,&quot;Education.Expenditures&quot;) glimpse(education) ## Rows: 50 ## Columns: 7 ## $ X &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,… ## $ State &lt;chr&gt; &quot;ME&quot;, &quot;NH&quot;, &quot;VT&quot;, &quot;MA&quot;, &quot;RI&quot;, &quot;CT&quot;, &quot;NY&quot;, &quot;NJ&quot;… ## $ Region &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2… ## $ Urban.Population &lt;int&gt; 508, 564, 322, 846, 871, 774, 856, 889, 715, 7… ## $ Per.Capita.Income &lt;int&gt; 3944, 4578, 4011, 5233, 4780, 5889, 5663, 5759… ## $ Minor.Population &lt;int&gt; 325, 323, 328, 305, 303, 307, 301, 310, 300, 3… ## $ Education.Expenditures &lt;int&gt; 235, 231, 270, 261, 300, 317, 387, 285, 300, 2… 10.1 Subsetting using brackets education[c(10:21),c(2,6:7)] ## State Minor.Population Education.Expenditures ## 10 OH 324 221 ## 11 IN 329 264 ## 12 IL 320 308 ## 13 MI 337 379 ## 14 WI 328 342 ## 15 MN 330 378 ## 16 IA 318 232 ## 17 MO 309 231 ## 18 ND 333 246 ## 19 SD 330 230 ## 20 NB 318 268 ## 21 KS 304 337 10.2 Subset using brackets by omitting the rows and columns we don’t want education[-c(1:9,22:50),-c(1,3:5)] ## State Minor.Population Education.Expenditures ## 10 OH 324 221 ## 11 IN 329 264 ## 12 IL 320 308 ## 13 MI 337 379 ## 14 WI 328 342 ## 15 MN 330 378 ## 16 IA 318 232 ## 17 MO 309 231 ## 18 ND 333 246 ## 19 SD 330 230 ## 20 NB 318 268 ## 21 KS 304 337 10.3 Subset using brackets in combination with the which() function and the %in% operator education[which(education$Region == 2),names(education) %in% c(&quot;State&quot;,&quot;Minor.Population&quot;,&quot;Education.Expenditures&quot;)] ## State Minor.Population Education.Expenditures ## 10 OH 324 221 ## 11 IN 329 264 ## 12 IL 320 308 ## 13 MI 337 379 ## 14 WI 328 342 ## 15 MN 330 378 ## 16 IA 318 232 ## 17 MO 309 231 ## 18 ND 333 246 ## 19 SD 330 230 ## 20 NB 318 268 ## 21 KS 304 337 10.4 Subset using the subset() function subset(education, Region == 2, select = c(&quot;State&quot;,&quot;Minor.Population&quot;,&quot;Education.Expenditures&quot;)) ## State Minor.Population Education.Expenditures ## 10 OH 324 221 ## 11 IN 329 264 ## 12 IL 320 308 ## 13 MI 337 379 ## 14 WI 328 342 ## 15 MN 330 378 ## 16 IA 318 232 ## 17 MO 309 231 ## 18 ND 333 246 ## 19 SD 330 230 ## 20 NB 318 268 ## 21 KS 304 337 10.5 Subset using dyplyr’s filter() and select() select(filter(education, Region == 2),c(State,Minor.Population:Education.Expenditures)) ## State Minor.Population Education.Expenditures ## 1 OH 324 221 ## 2 IN 329 264 ## 3 IL 320 308 ## 4 MI 337 379 ## 5 WI 328 342 ## 6 MN 330 378 ## 7 IA 318 232 ## 8 MO 309 231 ## 9 ND 333 246 ## 10 SD 330 230 ## 11 NB 318 268 ## 12 KS 304 337 "],
["simulating-data.html", "Chapter 11 Simulating data 11.1 Sample() 11.2 replicate() 11.3 sample() revisited 11.4 generating fixed levels ————————————————- 11.5 generating numerical sequences 11.6 seq_along() and seq_len(). 11.7 generating random data from a probability distribution 11.8 Normal distribution: 11.9 Binomial distribution: 11.10 Uniform distribution 11.11 Sampling from multiple distributions (building in a “difference”) 11.12 The good stuff: building in a difference based on a categorical variable 11.13 A demonstration of the Central Limit Theorem 11.14 Overlaying normal curve on histogram", " Chapter 11 Simulating data I’ve just begun to explore R, and I realize that many of my questions could be improved with example data. Generating this kind of data takes practice, though. Some good websites: https://clayford.github.io/dwir/dwr_12_generating_data.html https://cran.r-project.org/web/packages/simstudy/vignettes/simstudy.html https://aosmith.rbind.io/2018/08/29/getting-started-simulating-data/ Also, remember that R packages have a lot of great data. data() 11.1 Sample() Starting with Clayford’s nice (and long page): sample(5) #sample without replacement ## [1] 5 4 2 1 3 # or generate a random permutation of a vector: dat &lt;- c(10,12,18,16,18,9) sample(dat) ## [1] 18 18 9 16 12 10 # bootstrap resampling: sampling the same number of items WITH replacement. The bootstrap method is a resampling technique used to estimate statistics on a population by sampling a dataset with replacement. sample(dat, replace = TRUE) ## [1] 12 9 18 10 16 18 rm(dat) sample(state.abb, size = 10) ## [1] &quot;FL&quot; &quot;NV&quot; &quot;KS&quot; &quot;OH&quot; &quot;PA&quot; &quot;MO&quot; &quot;NY&quot; &quot;OR&quot; &quot;SC&quot; &quot;WA&quot; # Using 1:6 and size=1, we can simulate the roll of a die: sample(1:6, size=1) ## [1] 2 # We can simulate the roll of a die 100 times by setting size=100 and # replace=TRUE sample(1:6, size=100, replace=TRUE) ## [1] 5 1 3 2 3 5 2 3 2 1 2 2 4 2 1 3 1 6 5 5 6 2 3 1 4 2 1 2 3 4 1 4 5 1 3 4 5 ## [38] 6 1 6 6 2 2 4 2 1 4 1 3 4 5 5 5 4 6 3 2 1 2 5 6 4 3 5 4 3 6 5 5 6 4 2 6 4 ## [75] 4 2 5 3 4 2 5 1 1 1 3 5 5 1 1 2 6 4 5 5 5 5 4 4 1 3 # sample produces a vector, so we can manipulate it as we would any other # vector. For example, simulate a 100 die rolls and tally up the totals using # table() and prop.table(): table(sample(1:6, size=100, replace=TRUE)) ## ## 1 2 3 4 5 6 ## 15 22 11 17 18 17 prop.table(table(sample(1:6, size=100, replace=TRUE))) ## ## 1 2 3 4 5 6 ## 0.14 0.09 0.24 0.17 0.19 0.17 table(sample(state.abb, size = 1000, replace = TRUE)) ## ## AK AL AR AZ CA CO CT DE FL GA HI IA ID IL IN KS KY LA MA MD ME MI MN MO MS MT ## 19 20 22 20 22 17 15 21 10 22 18 13 20 24 15 31 21 28 12 21 13 18 12 19 13 27 ## NC ND NE NH NJ NM NV NY OH OK OR PA RI SC SD TN TX UT VA VT WA WI WV WY ## 23 23 20 28 20 26 20 20 18 16 21 20 23 13 26 29 21 20 24 18 22 21 18 17 prop.table(table(sample(state.abb, size = 1000, replace = TRUE))) ## ## AK AL AR AZ CA CO CT DE FL GA HI IA ID ## 0.032 0.022 0.023 0.018 0.016 0.026 0.015 0.019 0.015 0.013 0.021 0.017 0.029 ## IL IN KS KY LA MA MD ME MI MN MO MS MT ## 0.020 0.021 0.018 0.027 0.024 0.018 0.015 0.032 0.020 0.020 0.028 0.020 0.019 ## NC ND NE NH NJ NM NV NY OH OK OR PA RI ## 0.021 0.015 0.022 0.017 0.023 0.014 0.014 0.024 0.013 0.018 0.024 0.023 0.022 ## SC SD TN TX UT VA VT WA WI WV WY ## 0.016 0.022 0.028 0.017 0.021 0.013 0.022 0.017 0.014 0.018 0.014 # using the forward-pipe operator: %&gt;% library(magrittr) ## ## Attaching package: &#39;magrittr&#39; ## The following object is masked from &#39;package:purrr&#39;: ## ## set_names ## The following object is masked from &#39;package:tidyr&#39;: ## ## extract sample(1:6, size=100, replace=TRUE) %&gt;% table() %&gt;% prop.table() ## . ## 1 2 3 4 5 6 ## 0.19 0.20 0.20 0.10 0.17 0.14 # Or simulate rolling two dice and summing the total: sum(sample(1:6, size=2, replace=TRUE)) ## [1] 3 # same thing with %&gt;% sample(6, size=2, replace=TRUE) %&gt;% sum() ## [1] 7 # simulate rolling two dice 100 times by updating the sample &quot;space&quot; sample(2:12, size=100, replace=TRUE) ## [1] 12 12 3 12 7 4 2 8 3 9 9 9 4 9 4 11 11 4 11 10 12 2 4 12 9 ## [26] 3 12 5 9 12 7 7 4 11 5 6 7 6 4 4 3 9 11 5 7 3 11 9 3 8 ## [51] 3 8 12 12 5 12 4 8 4 11 4 10 6 9 4 6 8 12 5 9 5 10 6 11 11 ## [76] 3 10 11 12 11 11 11 10 12 4 5 2 2 7 5 2 9 7 3 4 11 7 8 3 4 # proportion of &quot;snake-eyes&quot; in 1000 rolls mean(sample(2:12, size = 1000, replace = TRUE) == 2) ## [1] 0.093 11.2 replicate() We can use the replicate() function to replicate samples. The replicate() function allows you to replicate an expression as many times as you specify. The basix syntax is replicate(n, expr) where n is the number of replications and expr is the expression you want to replicate. # Roll 2 dice and keep the largest number, 10,000 times: rolls &lt;- replicate(n=1e5, expr = max(sample(1:6, size=2, replace=TRUE))) # calculate proportions: prop.table(table(rolls)) ## rolls ## 1 2 3 4 5 6 ## 0.02787 0.08357 0.14052 0.19263 0.25027 0.30514 barplot(table(rolls)) rm(rolls) 11.3 sample() revisited The sample function also has a prob argument that allows you to assign probabilities to your items. For example to simulate the flip of a loaded coin, with Tails having probability 0.65: flips &lt;- sample(c(&quot;H&quot;,&quot;T&quot;), 1000, replace=TRUE, prob = c(0.35,0.65)) prop.table(table(flips)) ## flips ## H T ## 0.328 0.672 rm(flips) Coins are nice, but we can also use sample to generate practical data, for example males and females. A web site says UVa has 11,632 female students and 10,353 male students as of Fall 2015. uva &lt;- c(11632, 10353) # female, male round(uva/sum(uva),2) ## [1] 0.53 0.47 Note how elegantly this answers a basic question. Nice! We can generate a fake random sample of 500 UVa students with a weighted sampling scheme like so: students &lt;- sample(c(&quot;female&quot;,&quot;male&quot;), 500, replace=TRUE, prob = c(0.53, 0.47)) prop.table(table(students)) ## students ## female male ## 0.54 0.46 rm(students, uva) When used with subsetting brackets, sample() can be used to create training and test sets. For example, say we want to build some sort of predictive model using our training data. We may want to use half our data to build the model and then use the other half to evaluate its performance. train &lt;- sample(nrow(iris), size= nrow(iris)/2) # train is a random sample of numbers from 1 - 365. We can treat these like row numbers. irisTrain &lt;- iris[train,] irisTest &lt;- iris[-train,] # confirm no intersection dplyr::intersect(irisTrain, irisTest) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.8 2.7 5.1 1.9 virginica rm(train, irisTest, irisTrain) 11.4 generating fixed levels ————————————————- Often generating data means creating a series of fixed levels, such as 10 males and 10 females. The rep() function can be useful for this. Below we replicate 10 each of “M” and “F”: rep(c(&quot;M&quot;,&quot;F&quot;), each=10) ## [1] &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; ## [20] &quot;F&quot; rep(c(&quot;M&quot;,&quot;F&quot;), times=10) ## [1] &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; ## [20] &quot;F&quot; rep(c(&quot;M&quot;,&quot;F&quot;), length.out = 15) ## [1] &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; # or just length, for short rep(c(&quot;M&quot;,&quot;F&quot;), length = 15) ## [1] &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; # Notice that all these generated a character vector. To use as a &quot;factor&quot;, we would need to wrap it in the factor() function. factor(rep(c(&quot;M&quot;,&quot;F&quot;), each=10)) ## [1] M M M M M M M M M M F F F F F F F F F F ## Levels: F M # A function specifically for creating factors is the gl() function. gl = # &quot;generate levels&quot;. Below we generate a factor with 2 levels of 10 each and # labels of &quot;M&quot; and &quot;F&quot;. Notice the result is a factor. gl(n = 2, k = 10, labels = c(&quot;M&quot;,&quot;F&quot;)) ## [1] M M M M M M M M M M F F F F F F F F F F ## Levels: M F # A more common occurence is combinations of fixed levels, say gender, # education, and status. A function that helps create every combination of # levels is expand.grid(). Below we generate every combination of the levels # provided for gender, education, and status. Notice the first factors vary # fastest. expand.grid(gender=c(&quot;M&quot;,&quot;F&quot;), education=c(&quot;HS&quot;,&quot;College&quot;,&quot;Advanced&quot;), status=c(&quot;Single&quot;,&quot;Married&quot;,&quot;Divorced&quot;,&quot;Widowed&quot;)) ## gender education status ## 1 M HS Single ## 2 F HS Single ## 3 M College Single ## 4 F College Single ## 5 M Advanced Single ## 6 F Advanced Single ## 7 M HS Married ## 8 F HS Married ## 9 M College Married ## 10 F College Married ## 11 M Advanced Married ## 12 F Advanced Married ## 13 M HS Divorced ## 14 F HS Divorced ## 15 M College Divorced ## 16 F College Divorced ## 17 M Advanced Divorced ## 18 F Advanced Divorced ## 19 M HS Widowed ## 20 F HS Widowed ## 21 M College Widowed ## 22 F College Widowed ## 23 M Advanced Widowed ## 24 F Advanced Widowed # Notice that creates a data frame that we can save: DF &lt;- expand.grid(gender=c(&quot;M&quot;,&quot;F&quot;), education=c(&quot;HS&quot;,&quot;College&quot;,&quot;Advanced&quot;), status=c(&quot;Single&quot;,&quot;Married&quot;,&quot;Divorced&quot;,&quot;Widowed&quot;)) class(DF) ## [1] &quot;data.frame&quot; rm(DF) Or imagine an experiment where 3 people throw 3 different kinds of paper airplanes, made of 3 paper types (3x3 = 9 planes), throwing each plane 8 times. schedule &lt;- expand.grid(thrower=c(&quot;Clay&quot;,&quot;Rod&quot;,&quot;Kevin&quot;), paper=c(&quot;18&quot;, &quot;20&quot;, &quot;24&quot;), design=c(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;), rep=1:8) # Randomize and drop the rep column. The sample(nrow(schedule)) code scrambles the numbers 1 through 216, which I then use to randomly shuffle the schedule of throws. k &lt;- sample(nrow(schedule)) schedule &lt;- schedule[k,1:3] head(schedule, n = 10) ## thrower paper design ## 199 Clay 18 b ## 146 Rod 18 b ## 139 Clay 20 a ## 182 Rod 18 c ## 131 Rod 20 c ## 121 Clay 20 b ## 18 Kevin 24 b ## 186 Kevin 20 c ## 20 Rod 18 c ## 197 Rod 24 a # output to csv file for logging &quot;distance flown&quot; data write.csv(schedule, file=&quot;throwLog.csv&quot;, row.names=FALSE) rm(k, schedule) This is a great way to set up an experiment, but I’d like to also add data for the throw, based on interesting distributions (normal, etc.). How would I generate samples for each contestant that was based on slightly different distributions? What sort of distribution? See this page to get a quick refresher on common distributions: https://www.analyticsvidhya.com/blog/2017/09/6-probability-distributions-data-science/. Note also that ?distributions gives you the distributions in {stats}. Persevere for a time. 11.5 generating numerical sequences # The seq() function allows you to generate sequences of numbers: seq(from = 0, to = 10, by = 2) ## [1] 0 2 4 6 8 10 seq(0, 10, 0.2) ## [1] 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 2.0 2.2 2.4 2.6 2.8 ## [16] 3.0 3.2 3.4 3.6 3.8 4.0 4.2 4.4 4.6 4.8 5.0 5.2 5.4 5.6 5.8 ## [31] 6.0 6.2 6.4 6.6 6.8 7.0 7.2 7.4 7.6 7.8 8.0 8.2 8.4 8.6 8.8 ## [46] 9.0 9.2 9.4 9.6 9.8 10.0 # Go backwards seq(1000, 0, -100) ## [1] 1000 900 800 700 600 500 400 300 200 100 0 # The seq() function has a length.out argument that allows you to specify the # size of the vector you want to create. It automatically calculates the # increment. We usually just abbreviate to length seq(1, 10, length = 30) ## [1] 1.000000 1.310345 1.620690 1.931034 2.241379 2.551724 2.862069 ## [8] 3.172414 3.482759 3.793103 4.103448 4.413793 4.724138 5.034483 ## [15] 5.344828 5.655172 5.965517 6.275862 6.586207 6.896552 7.206897 ## [22] 7.517241 7.827586 8.137931 8.448276 8.758621 9.068966 9.379310 ## [29] 9.689655 10.000000 # The colon operator(:) also allows you to generate regular sequences in steps # of 1. 1:10 ## [1] 1 2 3 4 5 6 7 8 9 10 10:-10 # reverse direction ## [1] 10 9 8 7 6 5 4 3 2 1 0 -1 -2 -3 -4 -5 -6 -7 -8 ## [20] -9 -10 # When used with factors, the colon operator generates an interaction factor: f1 &lt;- gl(n = 2, k = 3); f1 ## [1] 1 1 1 2 2 2 ## Levels: 1 2 f2 &lt;- gl(n = 3, k = 2, labels = c(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;)); f2 ## [1] a a b b c c ## Levels: a b c f1:f2 ## [1] 1:a 1:a 1:b 2:b 2:c 2:c ## Levels: 1:a 1:b 1:c 2:a 2:b 2:c rm(f1,f2) The last step seems akin to perfectly shuffling two decks of cards (the decks must be of equal length). 11.6 seq_along() and seq_len(). seq_along() returns the indices of a vector while seq_len(n) returns an integer vector of 1:n. seq_along(100:120) ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 seq_along(state.abb) ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ## [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 seq_len(12) ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 11.7 generating random data from a probability distribution A central idea in inferential statistics is that the distribution of data can often be approximated by a theoretical distribution. R provides functions for working with several well-known theoretical distributions, including the ability to generate data from those distributions. A common one is the rnorm() function which generates data from a Normal distribution. In R, the functions for theoretical distributions take the form of dxxx, pxxx, qxxx and rxxx. dxxx is for the probability density/mass function (dnorm) pxxx is for the cumulative distribution function (pnorm) qxxx is for the quantile function (qnorm) rxxx is for random variate generation (rnorm) For random variate generation we’re interested in the rxxx variety. 11.8 Normal distribution: # 10 random draws from N(100,5) rnorm(n = 10, mean = 100, sd = 5) ## [1] 95.66993 96.93959 93.87119 98.15503 108.59453 99.28320 94.30730 ## [8] 102.50581 93.27080 98.65353 11.9 Binomial distribution: # 10 random draws from b(1,0.5) # AKA, 10 coin flips (size is the number of trials) rbinom(n = 10, size = 1, prob = 0.5) ## [1] 1 1 1 0 1 1 1 0 1 0 # 10 random draws from b(1,0.8) # AKA, 10 coin flips with a coin loaded Heads (or Tails) 80% of time rbinom(n = 10, size = 1, prob = 0.8) ## [1] 1 1 1 1 1 0 1 1 1 0 # 10 random draws from b(10,0.5) # AKA, 10 results of 10 coin flips rbinom(n = 10, size = 10, prob = 0.5) ## [1] 5 6 4 2 5 3 5 7 6 3 # We can use a binomial distribution to simulate dichotmous answers such as # Yes/No or success/fail. Simulate a vector of responses where respondents are 65% likely to say Yes (1) versus No (0) rbinom(n = 10, size = 1, prob = 0.65) ## [1] 1 1 0 1 1 1 1 0 1 0 # could also just use sample sample(c(&quot;Y&quot;,&quot;N&quot;), size = 10, replace = TRUE, prob = c(.65, .35)) ## [1] &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; &quot;N&quot; &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; 11.10 Uniform distribution # 10 random draws from a uniform distribution u(0,100) runif(10,0,100) ## [1] 60.326980 73.283454 10.113435 61.390940 25.128734 59.507974 92.516590 ## [8] 1.090762 1.082432 26.157247 # A uniform distribution can be good for random sampling. Let&#39;s say we want to sample about 10% of iris data: k &lt;- runif(nrow(iris),0,1) # [0,1] interval is default sbSamp &lt;- iris[k &lt; 0.1, ] # sample about 10% of rows dim(sbSamp) ## [1] 17 5 # dplyr does this as well without the need for runif; and it&#39;s precise in its # sampling fraction. sbSamp &lt;- dplyr::sample_frac(iris, 0.1) # sample exactly 10% of rows dim(sbSamp) ## [1] 15 5 rm(sbSamp, k) 11.11 Sampling from multiple distributions (building in a “difference”) The arguments to rxxx functions can take vectors! This means we can use one function call to generate draws from multiple distributions. # alternating random values from N(10,4) and N(100,40) rnorm(10, mean = c(2,100),sd = c(2,40)) ## [1] 3.4780530 100.0473848 -0.9160729 126.5839546 2.2481878 31.5422218 ## [7] 4.2862139 124.8887630 0.5034521 86.9648960 # 30 random draws, 10 each from N(10,4), N(90,4) and N(400,4) rnorm(30, mean = rep(c(10,90,400),each=10), sd = 4) ## [1] 7.293508 19.639453 3.924593 8.225864 7.175903 7.391683 ## [7] 6.591222 8.746446 12.196931 13.198499 99.520178 86.514731 ## [13] 90.376221 93.506773 90.063370 87.698771 91.558452 81.415876 ## [19] 83.241770 84.475469 395.164557 403.326198 402.503808 397.540535 ## [25] 406.222133 399.418309 396.399917 400.717691 394.538219 399.473333 # 100 random draws, 50 each from b(5,0.5) and b(50,0.5) rbinom(n = 100, size = rep(c(5,50),each=50), prob = 0.5) ## [1] 3 3 1 1 1 2 1 2 3 2 1 2 5 4 2 3 2 4 3 3 1 4 4 4 4 ## [26] 2 3 2 3 1 1 1 1 4 2 3 3 3 4 2 3 4 2 3 3 1 0 2 2 5 ## [51] 26 19 22 29 23 29 23 22 26 35 26 23 27 28 24 27 27 26 26 24 27 24 28 16 21 ## [76] 23 28 20 22 25 28 22 25 30 27 25 29 29 24 28 25 22 25 21 30 28 31 28 25 20 # Combined with matrix(), one can generate &quot;multiple&quot; random samples from a # distribution. For example, draw 5 random samples of size 10 from a N(10,1): matrix(rnorm(10*5,10,1),ncol=5) ## [,1] [,2] [,3] [,4] [,5] ## [1,] 11.332861 11.400865 8.769827 8.810924 9.029461 ## [2,] 10.035283 8.433844 9.381177 9.525557 9.398117 ## [3,] 10.496715 11.290449 8.971141 9.706275 10.434732 ## [4,] 9.517007 9.185832 12.107094 9.597588 9.597808 ## [5,] 10.247553 9.482852 9.743374 9.241108 9.847012 ## [6,] 11.858210 10.849336 9.445144 8.948363 9.505161 ## [7,] 9.546841 10.345423 9.039206 9.142356 10.760739 ## [8,] 9.039082 8.674918 11.558537 10.425124 9.811335 ## [9,] 9.518707 9.591150 10.619315 11.824144 9.667609 ## [10,] 9.207467 8.949413 9.771530 9.659081 11.109012 Note that in the last example, we technically drew one sample of size 50 and then laid it out in a 10x5 matrix. 11.12 The good stuff: building in a difference based on a categorical variable Using ifelse() we can generate different data based on a TRUE/FALSE condition. Let’s say we have treated and untreated subjects. I’d like to generate Normal data that differs based on the treatment. trtmt &lt;- sample(c(&quot;Treated&quot;,&quot;Untreated&quot;), size = 20, replace = TRUE) ifelse(trtmt==&quot;Treated&quot;, yes = rnorm(20, 10, 1), no = rnorm(20, 20, 1)) ## [1] 21.015208 10.902627 9.142717 9.696938 9.683289 20.463172 20.236671 ## [8] 19.549284 19.558152 20.102505 7.803139 8.879669 9.410191 10.798966 ## [15] 9.068286 10.657873 20.217372 11.767911 9.931248 11.132092 Notice we have to make the length of the yes/no arguments the SAME LENGTH as the trtmt==“Treated” logical vector! What happens if we use rnorm(n=1,…)? # What about more than two groups? n &lt;- 200 trtmt &lt;- sample(LETTERS[1:6], size = n, replace = TRUE) # Say we want to generate differnt Normal data for each group. One way is to do a for-loop with multiple if statements: val &lt;- numeric(n) # empty vector for(i in seq_along(trtmt)){ if(trtmt[i]==&quot;A&quot;) val[i] &lt;- rnorm(1, 10, 2) else if(trtmt[i]==&quot;B&quot;) val[i] &lt;- rnorm(1, 20, 4) else if(trtmt[i]==&quot;C&quot;) val[i] &lt;- rnorm(1, 30, 6) else if(trtmt[i]==&quot;D&quot;) val[i] &lt;- rnorm(1, 40, 8) else if(trtmt[i]==&quot;E&quot;) val[i] &lt;- rnorm(1, 50, 10) else val[i] &lt;- rnorm(1, 60, 12) } val ## [1] 11.576376 9.465103 18.275351 42.031274 45.563227 41.332462 24.833032 ## [8] 42.691672 40.744736 49.839709 48.709138 9.140163 53.761520 7.556632 ## [15] 55.170821 45.567743 19.882858 9.441267 29.355899 21.854935 41.837018 ## [22] 20.847891 10.577338 53.994109 11.756548 7.220519 35.605797 20.602421 ## [29] 22.494072 23.460312 77.272943 8.083332 50.191954 44.710898 35.851786 ## [36] 15.227514 36.406731 7.629116 22.142077 46.214166 29.967466 57.336725 ## [43] 11.565971 66.447415 10.287138 11.361467 14.925814 40.228507 36.535038 ## [50] 12.579261 79.615106 63.708583 36.752670 7.442945 28.897760 23.752219 ## [57] 56.837868 47.786744 8.976672 37.284647 23.177804 19.440649 12.169583 ## [64] 73.423544 28.170850 22.354030 28.736339 42.352745 8.309049 45.972741 ## [71] 36.180210 71.510068 48.076684 23.123753 44.510092 32.208610 17.285662 ## [78] 51.708670 38.888889 40.239945 19.856443 51.841459 11.116210 10.201142 ## [85] 10.731335 15.530799 25.867331 13.562846 78.238912 71.711494 21.023212 ## [92] 53.096569 34.340418 42.060234 22.412097 47.359702 14.419714 50.694225 ## [99] 23.365908 23.004778 20.989515 66.045645 31.510570 31.206626 46.958690 ## [106] 68.825559 21.832495 28.566367 38.870232 27.790953 47.581605 56.614140 ## [113] 11.058591 18.954572 54.668096 59.020574 39.165581 11.091255 48.491145 ## [120] 64.562534 54.176034 42.888166 60.696432 7.418108 23.238997 9.421419 ## [127] 73.738707 26.924804 14.870279 13.724914 9.337480 25.781511 68.176093 ## [134] 14.270560 52.080972 71.493883 35.365105 64.200543 44.373374 44.819049 ## [141] 59.315340 36.343243 36.255372 39.430310 31.269215 76.636012 19.782770 ## [148] 8.641738 27.402907 54.055081 23.951215 8.191447 37.277908 52.530782 ## [155] 39.701506 21.416825 59.400033 69.243008 49.193184 11.718405 53.574984 ## [162] 33.507361 39.308784 52.606870 9.253777 63.638915 11.232726 33.299307 ## [169] 32.582860 25.835494 23.319721 73.039736 24.149536 10.244137 8.794697 ## [176] 21.474519 12.588297 9.987547 26.512094 12.781433 41.539991 8.606029 ## [183] 70.952206 24.017570 15.773603 47.551492 43.257415 47.640365 37.928899 ## [190] 36.086770 56.328465 60.242036 20.711093 12.439874 31.923822 35.771169 ## [197] 47.532915 22.668178 30.793951 49.884352 A more R-like way would be to take advantage of vectorized functions. First create a data frame with one row for each group and the mean and standard deviations we want to use to generate the data for that group. dat &lt;- data.frame(g=LETTERS[1:6],mean=seq(10,60,10),sd=seq(2,12,2)) dat ## g mean sd ## 1 A 10 2 ## 2 B 20 4 ## 3 C 30 6 ## 4 D 40 8 ## 5 E 50 10 ## 6 F 60 12 dat is currently a petite little dataframe of 6 rows. Now sample the row numbers (1 - 6) WITH replacement. We can use these to randomly sample the data frame rows. ASIDE: Recall that we can repeatedly call a row or element using subsetting brackets. For example, call the first row of iris 5 times: iris[c(1,1,1,1,1),] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 1.1 5.1 3.5 1.4 0.2 setosa ## 1.2 5.1 3.5 1.4 0.2 setosa ## 1.3 5.1 3.5 1.4 0.2 setosa ## 1.4 5.1 3.5 1.4 0.2 setosa Let’s exploit that to randomly sample with replacement our data frame of groups: n &lt;- 200 k &lt;- sample(1:6, n, replace = TRUE) dat &lt;- dat[k,] str(dat) ## &#39;data.frame&#39;: 200 obs. of 3 variables: ## $ g : Factor w/ 6 levels &quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,..: 5 6 1 5 1 5 4 2 6 5 ... ## $ mean: num 50 60 10 50 10 50 40 20 60 50 ... ## $ sd : num 10 12 2 10 2 10 8 4 12 10 ... # Now generate our data for each group using ONE call to rnorm. dat$vals &lt;- rnorm(n, mean=dat$mean, sd=dat$sd) head(dat) ## g mean sd vals ## 5 E 50 10 53.555407 ## 6 F 60 12 58.975390 ## 1 A 10 2 9.436031 ## 5.1 E 50 10 66.783189 ## 1.1 A 10 2 11.565873 ## 5.2 E 50 10 43.187463 This is pretty neat. We go from one little dataframe to a larger one in a few lines of code. Mean and SD can be varied by the class, “g” in this case. 11.13 A demonstration of the Central Limit Theorem The Central Limit Theorem states that the sum of a large number of independent random variables will be approximately normally distributed almost regardless of their individual distributions. We can demonstrate this using various rxxx functions. # sum 6 values from 6 different distributions (sample size = 6) n &lt;- 1e4 # simulate 1000 times clt &lt;- rexp(n, rate = 1) + rbinom(n,10,0.4) + rchisq(n,df = 6) + rnorm(n, 12, 12) + rpois(n, lambda = 3) + rt(n, df = 7) hist(clt, freq=FALSE) # overlay a normal density curve X &lt;- seq(min(clt),max(clt),length = 500) # x Y &lt;- dnorm(X, mean = mean(clt), sd = sd(clt)) # f(x) = dnorm lines(X,Y,type = &quot;l&quot;, col=&quot;blue&quot;) # plot (x,y) coordinates as a &quot;blue&quot; line (&quot;l&quot;) rm(X, Y, clt) Let’s unpack some of this: clt1 &lt;- rexp(n, rate = 1) hist(clt1, freq=FALSE) clt2 &lt;- rbinom(n,10,0.4) hist(clt2, freq=FALSE) clt3 &lt;- rchisq(n,df = 6) hist(clt3, freq=FALSE) clt4 &lt;-rnorm(n, 12, 12) hist(clt4, freq=FALSE) clt5 &lt;- rpois(n, lambda = 3) hist(clt5, freq=FALSE) clt6 &lt;- rt(n, df = 7) hist(clt6, freq=FALSE) # All of this base R graphing is clunky and doesn&#39;t lend itself to modification as well as ggplot() figures. library(tidyverse) df &lt;- data.frame(clt1, clt2, clt3, clt4, clt5, clt6) df %&gt;% ggplot(aes(clt3)) + geom_histogram(bins = 30) df %&gt;% ggplot(aes(clt3)) + geom_density() 11.14 Overlaying normal curve on histogram The following solution was on StackOverflow at https://stackoverflow.com/questions/6967664/ggplot2-histogram-with-normal-curve set.seed(1) df1 &lt;- data.frame(PF = 10*rnorm(1000)) ggplot(df1, aes(x = PF)) + geom_histogram(aes(y =..density..), breaks = seq(-40, 40, by = 5), colour = &quot;black&quot;, fill = &quot;white&quot;) + stat_function(fun = dnorm, args = list(mean = mean(df1$PF), sd = sd(df1$PF)), color = &quot;blue&quot;) From the {ggplot2} help: “This stat makes it easy to superimpose a function on top of an existing plot. The function is called with a grid of evenly spaced values along the x axis, and the results are drawn (by default) with a line.” Note how stat_function() lends itself to quick addition: simply feed the correct fun and args to the function. Now accomplish this for clt3 ggplot(df, aes(x = clt3)) + geom_histogram(aes(y =..density..), breaks = seq(0, 30, by = 1), colour = &quot;black&quot;, fill = &quot;white&quot;) + stat_function(fun = dchisq, args = list(df = 6), color = &quot;blue&quot;) + labs(title = &quot;chi-squared distribution&quot;) Note how the args in dchisq includes only the df = 6. No mean needs to be calculated (as in dnorm). Now accomplish this for clt1 ggplot(df, aes(x = clt1)) + geom_histogram(aes(y =..density..), breaks = seq(0, 8, by = .5), colour = &quot;black&quot;, fill = &quot;white&quot;) + stat_function(fun = dexp, args = list(rate = 1), color = &quot;blue&quot;) + labs(title = &quot;exponential distribution&quot;) "],
["functions.html", "Chapter 12 Functions", " Chapter 12 Functions library(tidyverse) From R4DS and the Solution book for R4DS: x &lt;- c(1:10, rep(NA,3)) cV &lt;- function(x){ sd(x, na.rm = TRUE)/mean(x, na.rm = TRUE) } xVar &lt;- function(x) { n &lt;- length(x[!is.na(x)]) m &lt;- mean(x, na.rm = TRUE) sq_err &lt;- (x - m)^2 sum(sq_err, na.rm = TRUE) / (n - 1) } "],
["references.html", "References", " References "]
]
