<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 17 Modeling | Bill’s Drills Book</title>
  <meta name="description" content="Chapter 17 Modeling | Bill’s Drills Book" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 17 Modeling | Bill’s Drills Book" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="https://github.com/wliammd/billsDrills" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 17 Modeling | Bill’s Drills Book" />
  
  
  

<meta name="author" content="William McDonald" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="knncv.html"/>
<link rel="next" href="moremodeling.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bill's Drills Book</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Drills: Part of Every Healthy Intellectual Diet</a></li>
<li class="chapter" data-level="2" data-path="bookdownplan.html"><a href="bookdownplan.html"><i class="fa fa-check"></i><b>2</b> <strong>bookdown</strong> Tips for This Document</a>
<ul>
<li class="chapter" data-level="2.1" data-path="bookdownplan.html"><a href="bookdownplan.html#basic-conventions"><i class="fa fa-check"></i><b>2.1</b> Basic conventions</a></li>
<li class="chapter" data-level="2.2" data-path="bookdownplan.html"><a href="bookdownplan.html#rstudio-tip-preview-in-viewer-pane"><i class="fa fa-check"></i><b>2.2</b> RStudio Tip: Preview in Viewer Pane</a></li>
<li class="chapter" data-level="2.3" data-path="bookdownplan.html"><a href="bookdownplan.html#inserting-pictures"><i class="fa fa-check"></i><b>2.3</b> Inserting pictures</a></li>
<li class="chapter" data-level="2.4" data-path="bookdownplan.html"><a href="bookdownplan.html#referencing-other-parts-of-the-document"><i class="fa fa-check"></i><b>2.4</b> Referencing other parts of the document</a></li>
<li class="chapter" data-level="2.5" data-path="bookdownplan.html"><a href="bookdownplan.html#referencing-citations"><i class="fa fa-check"></i><b>2.5</b> Referencing citations:</a></li>
<li class="chapter" data-level="2.6" data-path="bookdownplan.html"><a href="bookdownplan.html#figures."><i class="fa fa-check"></i><b>2.6</b> Figures.</a></li>
<li class="chapter" data-level="2.7" data-path="bookdownplan.html"><a href="bookdownplan.html#working-with-github"><i class="fa fa-check"></i><b>2.7</b> Working with Github</a></li>
<li class="chapter" data-level="2.8" data-path="bookdownplan.html"><a href="bookdownplan.html#working-with-a-lot-of-packages"><i class="fa fa-check"></i><b>2.8</b> Working with a lot of packages</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="datashape.html"><a href="datashape.html"><i class="fa fa-check"></i><b>3</b> Shape of Data</a>
<ul>
<li class="chapter" data-level="3.1" data-path="datashape.html"><a href="datashape.html#making-data-frames"><i class="fa fa-check"></i><b>3.1</b> Making data frames</a></li>
<li class="chapter" data-level="3.2" data-path="datashape.html"><a href="datashape.html#the-humble-table"><i class="fa fa-check"></i><b>3.2</b> The humble table</a></li>
<li class="chapter" data-level="3.3" data-path="datashape.html"><a href="datashape.html#gather-spread-pivoting-in-the-tidyverse"><i class="fa fa-check"></i><b>3.3</b> Gather, spread, pivoting in the tidyverse</a></li>
<li class="chapter" data-level="3.4" data-path="datashape.html"><a href="datashape.html#gathering-steam"><i class="fa fa-check"></i><b>3.4</b> Gathering steam…</a></li>
<li class="chapter" data-level="3.5" data-path="datashape.html"><a href="datashape.html#spread-your-wings"><i class="fa fa-check"></i><b>3.5</b> Spread your wings</a></li>
<li class="chapter" data-level="3.6" data-path="datashape.html"><a href="datashape.html#missing-data-ich-vemisse-dich"><i class="fa fa-check"></i><b>3.6</b> Missing Data: Ich vemisse Dich!</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="datashape.html"><a href="datashape.html#you-completeme"><i class="fa fa-check"></i><b>3.6.1</b> You complete(me)</a></li>
<li class="chapter" data-level="3.6.2" data-path="datashape.html"><a href="datashape.html#filling-in-the-gaps"><i class="fa fa-check"></i><b>3.6.2</b> fill(ing) in the gaps</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="datashape.html"><a href="datashape.html#pivoting-to-something-new"><i class="fa fa-check"></i><b>3.7</b> Pivoting to something new</a></li>
<li class="chapter" data-level="3.8" data-path="datashape.html"><a href="datashape.html#larger-structures"><i class="fa fa-check"></i><b>3.8</b> Larger structures</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="changenames.html"><a href="changenames.html"><i class="fa fa-check"></i><b>4</b> By Any Other Name</a>
<ul>
<li class="chapter" data-level="4.1" data-path="changenames.html"><a href="changenames.html#a-financial-example"><i class="fa fa-check"></i><b>4.1</b> A financial example</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="factorpractice.html"><a href="factorpractice.html"><i class="fa fa-check"></i><b>5</b> Factor Practice</a>
<ul>
<li class="chapter" data-level="5.1" data-path="factorpractice.html"><a href="factorpractice.html#the-basic-structure"><i class="fa fa-check"></i><b>5.1</b> The basic structure</a></li>
<li class="chapter" data-level="5.2" data-path="factorpractice.html"><a href="factorpractice.html#not-all-nominal-data-is-a-factor"><i class="fa fa-check"></i><b>5.2</b> Not all nominal data is a factor</a></li>
<li class="chapter" data-level="5.3" data-path="factorpractice.html"><a href="factorpractice.html#making-variables-into-factors"><i class="fa fa-check"></i><b>5.3</b> Making variables into factors</a></li>
<li class="chapter" data-level="5.4" data-path="factorpractice.html"><a href="factorpractice.html#inspecting-factors"><i class="fa fa-check"></i><b>5.4</b> Inspecting factors</a></li>
<li class="chapter" data-level="5.5" data-path="factorpractice.html"><a href="factorpractice.html#fct_lump"><i class="fa fa-check"></i><b>5.5</b> fct_lump()</a></li>
<li class="chapter" data-level="5.6" data-path="factorpractice.html"><a href="factorpractice.html#fct_infreq-and-fct_rev"><i class="fa fa-check"></i><b>5.6</b> fct_infreq() and fct_rev()</a></li>
<li class="chapter" data-level="5.7" data-path="factorpractice.html"><a href="factorpractice.html#additional-practice"><i class="fa fa-check"></i><b>5.7</b> Additional practice</a></li>
<li class="chapter" data-level="5.8" data-path="factorpractice.html"><a href="factorpractice.html#reordering-factors"><i class="fa fa-check"></i><b>5.8</b> Reordering Factors</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="factorpractice.html"><a href="factorpractice.html#fct_reorder2-another-way-to-improve-legibility"><i class="fa fa-check"></i><b>5.8.1</b> fct_reorder2(): another way to improve legibility</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="subset.html"><a href="subset.html"><i class="fa fa-check"></i><b>6</b> Subsetting</a>
<ul>
<li class="chapter" data-level="6.1" data-path="subset.html"><a href="subset.html#subsetting-using-brackets"><i class="fa fa-check"></i><b>6.1</b> Subsetting using brackets</a></li>
<li class="chapter" data-level="6.2" data-path="subset.html"><a href="subset.html#subset-using-brackets-by-omitting-the-rows-and-columns-we-dont-want"><i class="fa fa-check"></i><b>6.2</b> Subset using brackets by omitting the rows and columns we don’t want</a></li>
<li class="chapter" data-level="6.3" data-path="subset.html"><a href="subset.html#subset-using-brackets-in-combination-with-the-which-function-and-the-in-operator"><i class="fa fa-check"></i><b>6.3</b> Subset using brackets in combination with the which() function and the %in% operator</a></li>
<li class="chapter" data-level="6.4" data-path="subset.html"><a href="subset.html#subset-using-the-subset-function"><i class="fa fa-check"></i><b>6.4</b> Subset using the subset() function</a></li>
<li class="chapter" data-level="6.5" data-path="subset.html"><a href="subset.html#subset-using-dyplyrs-filter-and-select"><i class="fa fa-check"></i><b>6.5</b> Subset using dyplyr’s filter() and select()</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="dataexploration.html"><a href="dataexploration.html"><i class="fa fa-check"></i><b>7</b> Data Exploration</a>
<ul>
<li class="chapter" data-level="7.1" data-path="dataexploration.html"><a href="dataexploration.html#counting-things.-the-naming-of-parts."><i class="fa fa-check"></i><b>7.1</b> Counting things. The naming of parts.</a></li>
<li class="chapter" data-level="7.2" data-path="dataexploration.html"><a href="dataexploration.html#fct_infreq"><i class="fa fa-check"></i><b>7.2</b> fct_infreq</a></li>
<li class="chapter" data-level="7.3" data-path="dataexploration.html"><a href="dataexploration.html#weight-weight-dont-tell-me"><i class="fa fa-check"></i><b>7.3</b> Weight weight, don’t tell me!</a></li>
<li class="chapter" data-level="7.4" data-path="dataexploration.html"><a href="dataexploration.html#summarize-is-another-very-useful-function"><i class="fa fa-check"></i><b>7.4</b> Summarize is another very useful function:</a></li>
<li class="chapter" data-level="7.5" data-path="dataexploration.html"><a href="dataexploration.html#graphical-displays"><i class="fa fa-check"></i><b>7.5</b> Graphical displays</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="dataexploration.html"><a href="dataexploration.html#joyplots"><i class="fa fa-check"></i><b>7.5.1</b> Joyplots</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="dataexploration.html"><a href="dataexploration.html#relative-versus-absolute-risk"><i class="fa fa-check"></i><b>7.6</b> Relative versus absolute risk</a></li>
<li class="chapter" data-level="7.7" data-path="dataexploration.html"><a href="dataexploration.html#removing-duplicates"><i class="fa fa-check"></i><b>7.7</b> Removing duplicates</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="sampling.html"><a href="sampling.html"><i class="fa fa-check"></i><b>8</b> Sampling</a>
<ul>
<li class="chapter" data-level="8.1" data-path="sampling.html"><a href="sampling.html#think-about-throwing-a-bunch-of-dice."><i class="fa fa-check"></i><b>8.1</b> Think about throwing a bunch of dice.</a></li>
<li class="chapter" data-level="8.2" data-path="sampling.html"><a href="sampling.html#a-keen-way-to-divide-up-a-dataset-into-testing-and-training-components."><i class="fa fa-check"></i><b>8.2</b> A keen way to divide up a dataset into testing and training components.</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="simulating.html"><a href="simulating.html"><i class="fa fa-check"></i><b>9</b> Simulating data</a>
<ul>
<li class="chapter" data-level="9.1" data-path="simulating.html"><a href="simulating.html#sample"><i class="fa fa-check"></i><b>9.1</b> Sample()</a></li>
<li class="chapter" data-level="9.2" data-path="simulating.html"><a href="simulating.html#replicate"><i class="fa fa-check"></i><b>9.2</b> replicate()</a></li>
<li class="chapter" data-level="9.3" data-path="simulating.html"><a href="simulating.html#sample-revisited"><i class="fa fa-check"></i><b>9.3</b> sample() revisited</a></li>
<li class="chapter" data-level="9.4" data-path="simulating.html"><a href="simulating.html#generating-fixed-levels--"><i class="fa fa-check"></i><b>9.4</b> generating fixed levels ————————————————-</a></li>
<li class="chapter" data-level="9.5" data-path="simulating.html"><a href="simulating.html#generating-numerical-sequences"><i class="fa fa-check"></i><b>9.5</b> generating numerical sequences</a></li>
<li class="chapter" data-level="9.6" data-path="simulating.html"><a href="simulating.html#seq_along-and-seq_len."><i class="fa fa-check"></i><b>9.6</b> seq_along() and seq_len().</a></li>
<li class="chapter" data-level="9.7" data-path="simulating.html"><a href="simulating.html#generating-random-data-from-a-probability-distribution"><i class="fa fa-check"></i><b>9.7</b> generating random data from a probability distribution</a></li>
<li class="chapter" data-level="9.8" data-path="simulating.html"><a href="simulating.html#normal-distribution"><i class="fa fa-check"></i><b>9.8</b> Normal distribution:</a></li>
<li class="chapter" data-level="9.9" data-path="simulating.html"><a href="simulating.html#binomial-distribution"><i class="fa fa-check"></i><b>9.9</b> Binomial distribution:</a></li>
<li class="chapter" data-level="9.10" data-path="simulating.html"><a href="simulating.html#uniform-distribution"><i class="fa fa-check"></i><b>9.10</b> Uniform distribution</a></li>
<li class="chapter" data-level="9.11" data-path="simulating.html"><a href="simulating.html#sampling-from-multiple-distributions-building-in-a-difference"><i class="fa fa-check"></i><b>9.11</b> Sampling from multiple distributions (building in a “difference”)</a></li>
<li class="chapter" data-level="9.12" data-path="simulating.html"><a href="simulating.html#the-good-stuff-building-in-a-difference-based-on-a-categorical-variable"><i class="fa fa-check"></i><b>9.12</b> The good stuff: building in a difference based on a categorical variable</a></li>
<li class="chapter" data-level="9.13" data-path="simulating.html"><a href="simulating.html#a-demonstration-of-the-central-limit-theorem"><i class="fa fa-check"></i><b>9.13</b> A demonstration of the Central Limit Theorem</a></li>
<li class="chapter" data-level="9.14" data-path="simulating.html"><a href="simulating.html#overlaying-normal-curve-on-histogram"><i class="fa fa-check"></i><b>9.14</b> Overlaying normal curve on histogram</a></li>
<li class="chapter" data-level="9.15" data-path="simulating.html"><a href="simulating.html#crossing-trial"><i class="fa fa-check"></i><b>9.15</b> Crossing trial</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="functions.html"><a href="functions.html"><i class="fa fa-check"></i><b>10</b> Functions</a>
<ul>
<li class="chapter" data-level="10.1" data-path="functions.html"><a href="functions.html#a-little-dungeons-dragons-tm-to-spice-it-up"><i class="fa fa-check"></i><b>10.1</b> A little Dungeons &amp; Dragons (tm) to spice it up</a></li>
<li class="chapter" data-level="10.2" data-path="functions.html"><a href="functions.html#geometric-and-harmonic-means"><i class="fa fa-check"></i><b>10.2</b> Geometric and harmonic means</a></li>
<li class="chapter" data-level="10.3" data-path="functions.html"><a href="functions.html#for-loop"><i class="fa fa-check"></i><b>10.3</b> for loop</a></li>
<li class="chapter" data-level="10.4" data-path="functions.html"><a href="functions.html#case_when"><i class="fa fa-check"></i><b>10.4</b> case_when()</a></li>
<li class="chapter" data-level="10.5" data-path="functions.html"><a href="functions.html#compare-this-with-if_else"><i class="fa fa-check"></i><b>10.5</b> Compare this with if_else()</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="correlation.html"><a href="correlation.html"><i class="fa fa-check"></i><b>11</b> Correlation Plots</a></li>
<li class="chapter" data-level="12" data-path="dimensionalityreduction.html"><a href="dimensionalityreduction.html"><i class="fa fa-check"></i><b>12</b> Dimensionality Reduction</a>
<ul>
<li class="chapter" data-level="12.1" data-path="dimensionalityreduction.html"><a href="dimensionalityreduction.html#background"><i class="fa fa-check"></i><b>12.1</b> Background</a></li>
<li class="chapter" data-level="12.2" data-path="dimensionalityreduction.html"><a href="dimensionalityreduction.html#experiment-in-showing-dimensionality-reduction-for-pathologists"><i class="fa fa-check"></i><b>12.2</b> Experiment in showing dimensionality reduction for pathologists</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="dimensionalityreduction.html"><a href="dimensionalityreduction.html#principle-component-analysis"><i class="fa fa-check"></i><b>12.2.1</b> Principle component analysis</a></li>
<li class="chapter" data-level="12.2.2" data-path="dimensionalityreduction.html"><a href="dimensionalityreduction.html#t-distributed-stochastic-neighbor-embedding"><i class="fa fa-check"></i><b>12.2.2</b> t-distributed stochastic neighbor embedding</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>13</b> Clustering</a></li>
<li class="chapter" data-level="14" data-path="regex.html"><a href="regex.html"><i class="fa fa-check"></i><b>14</b> Regular expressions</a>
<ul>
<li class="chapter" data-level="14.1" data-path="regex.html"><a href="regex.html#seeking-patterns"><i class="fa fa-check"></i><b>14.1</b> Seeking patterns</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="census.html"><a href="census.html"><i class="fa fa-check"></i><b>15</b> US_Census_Data_Kyle_Walker_Presentation_YouTube</a>
<ul>
<li class="chapter" data-level="15.1" data-path="census.html"><a href="census.html#variables"><i class="fa fa-check"></i><b>15.1</b> Variables</a></li>
<li class="chapter" data-level="15.2" data-path="census.html"><a href="census.html#part-2-wrangling-census-data-with-tidyverse-tools"><i class="fa fa-check"></i><b>15.2</b> Part 2: Wrangling Census Data with <strong>tidyverse</strong> Tools</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="census.html"><a href="census.html#normalizing-the-data-with-mutate."><i class="fa fa-check"></i><b>15.2.1</b> Normalizing the data with <code>mutate()</code>.</a></li>
<li class="chapter" data-level="15.2.2" data-path="census.html"><a href="census.html#group_by-and-summarize-in-census-analysis"><i class="fa fa-check"></i><b>15.2.2</b> <code>group_by()</code> and <code>summarize()</code> in census analysis</a></li>
<li class="chapter" data-level="15.2.3" data-path="census.html"><a href="census.html#margin-of-error-considerations"><i class="fa fa-check"></i><b>15.2.3</b> Margin of error considerations</a></li>
<li class="chapter" data-level="15.2.4" data-path="census.html"><a href="census.html#visualizing-margins-of-error"><i class="fa fa-check"></i><b>15.2.4</b> Visualizing margins of error</a></li>
<li class="chapter" data-level="15.2.5" data-path="census.html"><a href="census.html#get_estimates-and-how-to-use-them"><i class="fa fa-check"></i><b>15.2.5</b> <code>get_estimates()</code> and how to use them</a></li>
<li class="chapter" data-level="15.2.6" data-path="census.html"><a href="census.html#ggbeeswarm-automates-some-jitter-considerations"><i class="fa fa-check"></i><b>15.2.6</b> <code>ggbeeswarm()</code> automates some jitter considerations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="knncv.html"><a href="knncv.html"><i class="fa fa-check"></i><b>16</b> <strong>K Nearest Neighbors Revisited: Cross Validation Added</strong> Tips for This Document</a></li>
<li class="chapter" data-level="17" data-path="modeling.html"><a href="modeling.html"><i class="fa fa-check"></i><b>17</b> Modeling</a>
<ul>
<li class="chapter" data-level="17.1" data-path="modeling.html"><a href="modeling.html#resources"><i class="fa fa-check"></i><b>17.1</b> Resources:</a></li>
<li class="chapter" data-level="17.2" data-path="modeling.html"><a href="modeling.html#classification-what-im-really-interested-in"><i class="fa fa-check"></i><b>17.2</b> Classification: what I’m really interested in</a></li>
<li class="chapter" data-level="17.3" data-path="modeling.html"><a href="modeling.html#class-imbalance-a-critical-issue-in-pituitary-adenoma-classification"><i class="fa fa-check"></i><b>17.3</b> Class imbalance: a critical issue in pituitary adenoma classification</a></li>
<li class="chapter" data-level="17.4" data-path="modeling.html"><a href="modeling.html#modeling-notes"><i class="fa fa-check"></i><b>17.4</b> Modeling notes</a></li>
<li class="chapter" data-level="17.5" data-path="modeling.html"><a href="modeling.html#out-of-sample-error-example"><i class="fa fa-check"></i><b>17.5</b> Out of sample error example</a></li>
<li class="chapter" data-level="17.6" data-path="modeling.html"><a href="modeling.html#a-regression-example-from-the-course-this-time-using-caret"><i class="fa fa-check"></i><b>17.6</b> A regression example from the course, this time using <strong>caret</strong></a></li>
<li class="chapter" data-level="17.7" data-path="modeling.html"><a href="modeling.html#classification"><i class="fa fa-check"></i><b>17.7</b> Classification</a>
<ul>
<li class="chapter" data-level="17.7.1" data-path="modeling.html"><a href="modeling.html#an-rpart-classification-example."><i class="fa fa-check"></i><b>17.7.1</b> An <strong>rpart</strong> classification example.</a></li>
</ul></li>
<li class="chapter" data-level="17.8" data-path="modeling.html"><a href="modeling.html#from-the-datacamp-course"><i class="fa fa-check"></i><b>17.8</b> From the DataCamp course</a></li>
<li class="chapter" data-level="17.9" data-path="modeling.html"><a href="modeling.html#random-forest-with-caret"><i class="fa fa-check"></i><b>17.9</b> Random forest with <strong>caret</strong></a></li>
<li class="chapter" data-level="17.10" data-path="modeling.html"><a href="modeling.html#random-forest-model-and-tunegrid"><i class="fa fa-check"></i><b>17.10</b> Random forest model and <code>tuneGrid()</code></a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="moremodeling.html"><a href="moremodeling.html"><i class="fa fa-check"></i><b>18</b> More modeling</a>
<ul>
<li class="chapter" data-level="18.1" data-path="moremodeling.html"><a href="moremodeling.html#glmnet-models"><i class="fa fa-check"></i><b>18.1</b> <code>glmnet</code> models</a>
<ul>
<li class="chapter" data-level="18.1.1" data-path="moremodeling.html"><a href="moremodeling.html#parameters-for-tuning-glmnet-models"><i class="fa fa-check"></i><b>18.1.1</b> Parameters for tuning <code>glmnet</code> models</a></li>
<li class="chapter" data-level="18.1.2" data-path="moremodeling.html"><a href="moremodeling.html#an-iris-example-of-glmnet"><i class="fa fa-check"></i><b>18.1.2</b> An iris example of <code>glmnet</code></a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="moremodeling.html"><a href="moremodeling.html#imputation-discussion"><i class="fa fa-check"></i><b>18.2</b> Imputation discussion</a></li>
<li class="chapter" data-level="18.3" data-path="moremodeling.html"><a href="moremodeling.html#multiple-preprocessing-methods"><i class="fa fa-check"></i><b>18.3</b> Multiple preprocessing methods</a></li>
<li class="chapter" data-level="18.4" data-path="moremodeling.html"><a href="moremodeling.html#handling-low-information-predictors"><i class="fa fa-check"></i><b>18.4</b> Handling low-information predictors</a></li>
<li class="chapter" data-level="18.5" data-path="moremodeling.html"><a href="moremodeling.html#max-kuhn-on-reusing-a-traincontrol"><i class="fa fa-check"></i><b>18.5</b> Max Kuhn on reusing a trainControl</a></li>
<li class="chapter" data-level="18.6" data-path="moremodeling.html"><a href="moremodeling.html#comparing-models"><i class="fa fa-check"></i><b>18.6</b> Comparing models</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="github.html"><a href="github.html"><i class="fa fa-check"></i><b>19</b> Working with GitHub</a>
<ul>
<li class="chapter" data-level="19.1" data-path="github.html"><a href="github.html#basic-idea"><i class="fa fa-check"></i><b>19.1</b> Basic idea</a></li>
<li class="chapter" data-level="19.2" data-path="github.html"><a href="github.html#a-couple-invaluable-websites"><i class="fa fa-check"></i><b>19.2</b> A couple invaluable websites</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="explainingmachinelearning.html"><a href="explainingmachinelearning.html"><i class="fa fa-check"></i><b>20</b> What is machine learning?</a>
<ul>
<li class="chapter" data-level="20.1" data-path="explainingmachinelearning.html"><a href="explainingmachinelearning.html#machine-learning-for-mds"><i class="fa fa-check"></i><b>20.1</b> Machine learning for MD’s</a></li>
<li class="chapter" data-level="20.2" data-path="explainingmachinelearning.html"><a href="explainingmachinelearning.html#supervised-versus-unsuperised-learning"><i class="fa fa-check"></i><b>20.2</b> Supervised versus unsuperised learning</a></li>
<li class="chapter" data-level="20.3" data-path="explainingmachinelearning.html"><a href="explainingmachinelearning.html#classification-versus-regression"><i class="fa fa-check"></i><b>20.3</b> Classification versus regression</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bill’s Drills Book</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="modeling" class="section level1" number="17">
<h1><span class="header-section-number">Chapter 17</span> Modeling</h1>
<div class="sourceCode" id="cb659"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb659-1"><a href="modeling.html#cb659-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb659-2"><a href="modeling.html#cb659-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span></code></pre></div>
<div id="resources" class="section level2" number="17.1">
<h2><span class="header-section-number">17.1</span> Resources:</h2>
<p>Stefania Ashby has nice observations and comments her code very well at <a href="https://neurospection.netlify.app/post/machine-learning-basics-with-caret" class="uri">https://neurospection.netlify.app/post/machine-learning-basics-with-caret</a></p>
</div>
<div id="classification-what-im-really-interested-in" class="section level2" number="17.2">
<h2><span class="header-section-number">17.2</span> Classification: what I’m really interested in</h2>
<p>Four types of classification are common in ML. See <a href="https://machinelearningmastery.com/types-of-classification-in-machine-learning/" class="uri">https://machinelearningmastery.com/types-of-classification-in-machine-learning/</a>. Jason Brownlee’s list includes:</p>
<ul>
<li>Binary</li>
<li>Multi-class</li>
<li>Multi-label</li>
<li>Imbalanced</li>
</ul>
<p>I think that binary, multiclass, and multilabel can all be imbalanced or balanced.</p>
<p>While multilabel classification is interesting (see, for example, <a href="https://www.r-bloggers.com/2017/03/multilabel-classification-with-mlr/" class="uri">https://www.r-bloggers.com/2017/03/multilabel-classification-with-mlr/</a>), it will not be addressed in these notes.</p>
</div>
<div id="class-imbalance-a-critical-issue-in-pituitary-adenoma-classification" class="section level2" number="17.3">
<h2><span class="header-section-number">17.3</span> Class imbalance: a critical issue in pituitary adenoma classification</h2>
<p>Fundamental to modeling pituitary adenoma classification is the notion of <strong>class imbalance</strong>, which must be acknowledged in the modeling process, even if my options to address it are limited.</p>
<p>Resources for class imbalance:</p>
<ul>
<li><a href="https://www.svds.com/learning-imbalanced-classes/" class="uri">https://www.svds.com/learning-imbalanced-classes/</a></li>
<li><a href="https://dpmartin42.github.io/posts/r/imbalanced-classes-part-1" class="uri">https://dpmartin42.github.io/posts/r/imbalanced-classes-part-1</a></li>
<li><a href="https://rstudio-pubs-static.s3.amazonaws.com/607601_57a11284917f4d79933f4c4db3d41713.html" class="uri">https://rstudio-pubs-static.s3.amazonaws.com/607601_57a11284917f4d79933f4c4db3d41713.html</a></li>
</ul>
<p>One of the cleanest approaches to datasets with marked class imbalances is seen in the DKFZ approach to DNA methylation profile classes. Their extensive use of dimension reduction, especially t-SNE plots, seems to graphically address the problem. A small cloud, remote from other clouds in a t-SNE plot, makes a pretty compelling argument for the existence of a separate class.</p>
</div>
<div id="modeling-notes" class="section level2" number="17.4">
<h2><span class="header-section-number">17.4</span> Modeling notes</h2>
<p>Notes on/inspired by the Machine Learning with caret in R DataCamp course. I’d like to better understand machine learning, especially as it pertains to classification problems. Most discussions begin with regression examples, so these will also be addressed in order to build a better foundation. This is the general approach of James, Witten, Hastie and Tibshirani in An Introduction to Statistical Learning with Applications in R, 2nd edition<span class="citation"><sup><a href="#ref-RN5383" role="doc-biblioref">7</a></sup></span> too.</p>
<p>But let’s back up and consider the whole rationale behind modeling: according to Haley Wickham in <code>R4DS</code>,</p>
<blockquote>
<p>The goal of a model is to provide a simple low-dimensional summary of a dataset.</p>
</blockquote>
<p>Modeling is a mode of <code>supervised learning</code>, which can be divided into <code>classification</code> and <code>regression</code>.</p>
<p><strong>Root mean squared error</strong>, <code>RMSE</code>, is an important concept in regression problems. For a review of what is meant by RMSE, see this Wikipedia page: <a href="https://en.wikipedia.org/wiki/Root-mean-square_deviation" class="uri">https://en.wikipedia.org/wiki/Root-mean-square_deviation</a>. The units RMSE are the same as the original data, so it is very interpretable.</p>
<p>It’s worth taking a more careful look at RMSE, and practicing with it, to illustrate the underlying methods of regression before we get into <strong>caret</strong>.</p>
<div class="sourceCode" id="cb660"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb660-1"><a href="modeling.html#cb660-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(diamonds)</span></code></pre></div>
<pre><code>## Rows: 53,940
## Columns: 10
## $ carat   &lt;dbl&gt; 0.23, 0.21, 0.23, 0.29, 0.31, 0.24, 0.24, 0.26, 0.22, 0.23, 0.…
## $ cut     &lt;ord&gt; Ideal, Premium, Good, Premium, Good, Very Good, Very Good, Ver…
## $ color   &lt;ord&gt; E, E, E, I, J, J, I, H, E, H, J, J, F, J, E, E, I, J, J, J, I,…
## $ clarity &lt;ord&gt; SI2, SI1, VS1, VS2, SI2, VVS2, VVS1, SI1, VS2, VS1, SI1, VS1, …
## $ depth   &lt;dbl&gt; 61.5, 59.8, 56.9, 62.4, 63.3, 62.8, 62.3, 61.9, 65.1, 59.4, 64…
## $ table   &lt;dbl&gt; 55, 61, 65, 58, 58, 57, 57, 55, 61, 61, 55, 56, 61, 54, 62, 58…
## $ price   &lt;int&gt; 326, 326, 327, 334, 335, 336, 336, 337, 337, 338, 339, 340, 34…
## $ x       &lt;dbl&gt; 3.95, 3.89, 4.05, 4.20, 4.34, 3.94, 3.95, 4.07, 3.87, 4.00, 4.…
## $ y       &lt;dbl&gt; 3.98, 3.84, 4.07, 4.23, 4.35, 3.96, 3.98, 4.11, 3.78, 4.05, 4.…
## $ z       &lt;dbl&gt; 2.43, 2.31, 2.31, 2.63, 2.75, 2.48, 2.47, 2.53, 2.49, 2.39, 2.…</code></pre>
<div class="sourceCode" id="cb662"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb662-1"><a href="modeling.html#cb662-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit lm model: model</span></span>
<span id="cb662-2"><a href="modeling.html#cb662-2" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(price <span class="sc">~</span> ., diamonds)</span>
<span id="cb662-3"><a href="modeling.html#cb662-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb662-4"><a href="modeling.html#cb662-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on full data: p</span></span>
<span id="cb662-5"><a href="modeling.html#cb662-5" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, diamonds)</span>
<span id="cb662-6"><a href="modeling.html#cb662-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb662-7"><a href="modeling.html#cb662-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute errors: error</span></span>
<span id="cb662-8"><a href="modeling.html#cb662-8" aria-hidden="true" tabindex="-1"></a>error <span class="ot">&lt;-</span> p <span class="sc">-</span> diamonds<span class="sc">$</span>price</span>
<span id="cb662-9"><a href="modeling.html#cb662-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb662-10"><a href="modeling.html#cb662-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate RMSE</span></span>
<span id="cb662-11"><a href="modeling.html#cb662-11" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">mean</span>(error<span class="sc">^</span><span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] 1129.843</code></pre>
<p>Note that the RMSE in this case is $1129.84, which is in keeping with what we know about the price of diamonds, which range from $326 to $18823 and average $3932.8.</p>
<p>Within-sample RMSE always overestimates model accuracy–the model only “knows” what it has encountered, not what the rest of the universe holds in store. Hence, out-of-sample data is checked with the model by some means. A separate “validation set” of sample points is provided (as we did when we moved from exploration to validation in our first pituitary adenoma paper).</p>
<p>Zach Mayer states this another way:</p>
<blockquote>
<p>In-sample validation almost guarantees overfitting.</p>
</blockquote>
<p>So in the wide world and blue, this is perhaps the nicest intellectual defense of study abroad, of learning the perspectives, habits, and languages of others in order to avoid overfitting of our mental models to local norms.</p>
<p>Sample size cannot always grow, however: samples are expensive. <strong>caret</strong> simulates the process of having a validation set and permits the progressive refinement of a model.</p>
</div>
<div id="out-of-sample-error-example" class="section level2" number="17.5">
<h2><span class="header-section-number">17.5</span> Out of sample error example</h2>
<p>This example from the DataCamp course divides <code>diamonds</code> into test and training sets. Note the assumptions that get built into the process: the use of 80% train/20% test, for instance. How does one arrive at this figure?</p>
<div class="sourceCode" id="cb664"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb664-1"><a href="modeling.html#cb664-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed</span></span>
<span id="cb664-2"><a href="modeling.html#cb664-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb664-3"><a href="modeling.html#cb664-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb664-4"><a href="modeling.html#cb664-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Shuffle row indices in case the data set is</span></span>
<span id="cb664-5"><a href="modeling.html#cb664-5" aria-hidden="true" tabindex="-1"></a><span class="co"># inhomogeneous: rows</span></span>
<span id="cb664-6"><a href="modeling.html#cb664-6" aria-hidden="true" tabindex="-1"></a>rows <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">nrow</span>(diamonds))</span>
<span id="cb664-7"><a href="modeling.html#cb664-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb664-8"><a href="modeling.html#cb664-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Randomly order data</span></span>
<span id="cb664-9"><a href="modeling.html#cb664-9" aria-hidden="true" tabindex="-1"></a>shuffled_diamonds <span class="ot">&lt;-</span> diamonds[rows, ]</span>
<span id="cb664-10"><a href="modeling.html#cb664-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb664-11"><a href="modeling.html#cb664-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Determine row to split on: split</span></span>
<span id="cb664-12"><a href="modeling.html#cb664-12" aria-hidden="true" tabindex="-1"></a>split <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">nrow</span>(diamonds) <span class="sc">*</span> <span class="fl">0.8</span>)</span>
<span id="cb664-13"><a href="modeling.html#cb664-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb664-14"><a href="modeling.html#cb664-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Create train</span></span>
<span id="cb664-15"><a href="modeling.html#cb664-15" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> diamonds[<span class="dv">1</span><span class="sc">:</span>split, ]</span>
<span id="cb664-16"><a href="modeling.html#cb664-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb664-17"><a href="modeling.html#cb664-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Create test</span></span>
<span id="cb664-18"><a href="modeling.html#cb664-18" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> diamonds[(split <span class="sc">+</span> <span class="dv">1</span>)<span class="sc">:</span><span class="fu">nrow</span>(diamonds), ]</span>
<span id="cb664-19"><a href="modeling.html#cb664-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb664-20"><a href="modeling.html#cb664-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit lm model on train: model</span></span>
<span id="cb664-21"><a href="modeling.html#cb664-21" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(price <span class="sc">~</span> ., train)</span>
<span id="cb664-22"><a href="modeling.html#cb664-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb664-23"><a href="modeling.html#cb664-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on test: p</span></span>
<span id="cb664-24"><a href="modeling.html#cb664-24" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, test)</span>
<span id="cb664-25"><a href="modeling.html#cb664-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb664-26"><a href="modeling.html#cb664-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute errors: error</span></span>
<span id="cb664-27"><a href="modeling.html#cb664-27" aria-hidden="true" tabindex="-1"></a>error <span class="ot">&lt;-</span> p <span class="sc">-</span> test<span class="sc">$</span>price</span>
<span id="cb664-28"><a href="modeling.html#cb664-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb664-29"><a href="modeling.html#cb664-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate RMSE</span></span>
<span id="cb664-30"><a href="modeling.html#cb664-30" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">mean</span>(error<span class="sc">^</span><span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] 796.8922</code></pre>
<p>So the RMSE for the model of diamond price, as measured by dividing the set this way, is $796.89.</p>
</div>
<div id="a-regression-example-from-the-course-this-time-using-caret" class="section level2" number="17.6">
<h2><span class="header-section-number">17.6</span> A regression example from the course, this time using <strong>caret</strong></h2>
<p>Note that the <code>train()</code> function has the method characteristic that can choose the type of model and that the <code>trainControl()</code> function has a method that determines cross validation. The number characteristic refers to the number of folds of cross validation. 10-fold cross validation is common, but takes more time than the use of smaller numbers. 5-fold will be used here to improve the speed of the processing.</p>
<div class="sourceCode" id="cb666"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb666-1"><a href="modeling.html#cb666-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb666-2"><a href="modeling.html#cb666-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb666-3"><a href="modeling.html#cb666-3" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">train</span>(price <span class="sc">~</span> ., diamonds, <span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>,</span>
<span id="cb666-4"><a href="modeling.html#cb666-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">number =</span> <span class="dv">5</span>, <span class="at">verboseIter =</span> <span class="cn">TRUE</span>))</span></code></pre></div>
<pre><code>## + Fold1: intercept=TRUE 
## - Fold1: intercept=TRUE 
## + Fold2: intercept=TRUE 
## - Fold2: intercept=TRUE 
## + Fold3: intercept=TRUE 
## - Fold3: intercept=TRUE 
## + Fold4: intercept=TRUE 
## - Fold4: intercept=TRUE 
## + Fold5: intercept=TRUE 
## - Fold5: intercept=TRUE 
## Aggregating results
## Fitting final model on full training set</code></pre>
<div class="sourceCode" id="cb668"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb668-1"><a href="modeling.html#cb668-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print model to console</span></span>
<span id="cb668-2"><a href="modeling.html#cb668-2" aria-hidden="true" tabindex="-1"></a>model</span></code></pre></div>
<pre><code>## Linear Regression 
## 
## 53940 samples
##     9 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 43152, 43152, 43152, 43152, 43152 
## Resampling results:
## 
##   RMSE      Rsquared   MAE     
##   1137.965  0.9186084  741.3386
## 
## Tuning parameter &#39;intercept&#39; was held constant at a value of TRUE</code></pre>
<p>Note that <strong>caret</strong> handles the work of splitting test sets and calculating RMSE.</p>
<p>Another example from the DataCamp course.</p>
<div class="sourceCode" id="cb670"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb670-1"><a href="modeling.html#cb670-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb670-2"><a href="modeling.html#cb670-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb670-3"><a href="modeling.html#cb670-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit lm model using 5-fold CV: model</span></span>
<span id="cb670-4"><a href="modeling.html#cb670-4" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">train</span>(medv <span class="sc">~</span> ., Boston, <span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>,</span>
<span id="cb670-5"><a href="modeling.html#cb670-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">number =</span> <span class="dv">5</span>, <span class="at">verboseIter =</span> <span class="cn">TRUE</span>))</span></code></pre></div>
<pre><code>## + Fold1: intercept=TRUE 
## - Fold1: intercept=TRUE 
## + Fold2: intercept=TRUE 
## - Fold2: intercept=TRUE 
## + Fold3: intercept=TRUE 
## - Fold3: intercept=TRUE 
## + Fold4: intercept=TRUE 
## - Fold4: intercept=TRUE 
## + Fold5: intercept=TRUE 
## - Fold5: intercept=TRUE 
## Aggregating results
## Fitting final model on full training set</code></pre>
<div class="sourceCode" id="cb672"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb672-1"><a href="modeling.html#cb672-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print model to console</span></span>
<span id="cb672-2"><a href="modeling.html#cb672-2" aria-hidden="true" tabindex="-1"></a>model</span></code></pre></div>
<pre><code>## Linear Regression 
## 
## 506 samples
##  13 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 405, 405, 405, 403, 406 
## Resampling results:
## 
##   RMSE      Rsquared   MAE     
##   4.811293  0.7238097  3.375276
## 
## Tuning parameter &#39;intercept&#39; was held constant at a value of TRUE</code></pre>
<p>Cross validation can <em>itself</em> be repeated. The following is a 5-fold cross validation repeated 5 times.</p>
<div class="sourceCode" id="cb674"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb674-1"><a href="modeling.html#cb674-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit lm model using 5 x 5-fold CV: model</span></span>
<span id="cb674-2"><a href="modeling.html#cb674-2" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">train</span>(medv <span class="sc">~</span> ., Boston, <span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;repeatedcv&quot;</span>,</span>
<span id="cb674-3"><a href="modeling.html#cb674-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">number =</span> <span class="dv">5</span>, <span class="at">repeats =</span> <span class="dv">5</span>, <span class="at">verboseIter =</span> <span class="cn">TRUE</span>))</span></code></pre></div>
<pre><code>## + Fold1.Rep1: intercept=TRUE 
## - Fold1.Rep1: intercept=TRUE 
## + Fold2.Rep1: intercept=TRUE 
## - Fold2.Rep1: intercept=TRUE 
## + Fold3.Rep1: intercept=TRUE 
## - Fold3.Rep1: intercept=TRUE 
## + Fold4.Rep1: intercept=TRUE 
## - Fold4.Rep1: intercept=TRUE 
## + Fold5.Rep1: intercept=TRUE 
## - Fold5.Rep1: intercept=TRUE 
## + Fold1.Rep2: intercept=TRUE 
## - Fold1.Rep2: intercept=TRUE 
## + Fold2.Rep2: intercept=TRUE 
## - Fold2.Rep2: intercept=TRUE 
## + Fold3.Rep2: intercept=TRUE 
## - Fold3.Rep2: intercept=TRUE 
## + Fold4.Rep2: intercept=TRUE 
## - Fold4.Rep2: intercept=TRUE 
## + Fold5.Rep2: intercept=TRUE 
## - Fold5.Rep2: intercept=TRUE 
## + Fold1.Rep3: intercept=TRUE 
## - Fold1.Rep3: intercept=TRUE 
## + Fold2.Rep3: intercept=TRUE 
## - Fold2.Rep3: intercept=TRUE 
## + Fold3.Rep3: intercept=TRUE 
## - Fold3.Rep3: intercept=TRUE 
## + Fold4.Rep3: intercept=TRUE 
## - Fold4.Rep3: intercept=TRUE 
## + Fold5.Rep3: intercept=TRUE 
## - Fold5.Rep3: intercept=TRUE 
## + Fold1.Rep4: intercept=TRUE 
## - Fold1.Rep4: intercept=TRUE 
## + Fold2.Rep4: intercept=TRUE 
## - Fold2.Rep4: intercept=TRUE 
## + Fold3.Rep4: intercept=TRUE 
## - Fold3.Rep4: intercept=TRUE 
## + Fold4.Rep4: intercept=TRUE 
## - Fold4.Rep4: intercept=TRUE 
## + Fold5.Rep4: intercept=TRUE 
## - Fold5.Rep4: intercept=TRUE 
## + Fold1.Rep5: intercept=TRUE 
## - Fold1.Rep5: intercept=TRUE 
## + Fold2.Rep5: intercept=TRUE 
## - Fold2.Rep5: intercept=TRUE 
## + Fold3.Rep5: intercept=TRUE 
## - Fold3.Rep5: intercept=TRUE 
## + Fold4.Rep5: intercept=TRUE 
## - Fold4.Rep5: intercept=TRUE 
## + Fold5.Rep5: intercept=TRUE 
## - Fold5.Rep5: intercept=TRUE 
## Aggregating results
## Fitting final model on full training set</code></pre>
<div class="sourceCode" id="cb676"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb676-1"><a href="modeling.html#cb676-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print model to console</span></span>
<span id="cb676-2"><a href="modeling.html#cb676-2" aria-hidden="true" tabindex="-1"></a>model</span></code></pre></div>
<pre><code>## Linear Regression 
## 
## 506 samples
##  13 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold, repeated 5 times) 
## Summary of sample sizes: 405, 404, 404, 406, 405, 405, ... 
## Resampling results:
## 
##   RMSE    Rsquared  MAE     
##   4.8764  0.722424  3.421333
## 
## Tuning parameter &#39;intercept&#39; was held constant at a value of TRUE</code></pre>
<div class="sourceCode" id="cb678"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb678-1"><a href="modeling.html#cb678-1" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, Boston)</span>
<span id="cb678-2"><a href="modeling.html#cb678-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb678-3"><a href="modeling.html#cb678-3" aria-hidden="true" tabindex="-1"></a>error <span class="ot">&lt;-</span> p <span class="sc">-</span> Boston<span class="sc">$</span>medv</span>
<span id="cb678-4"><a href="modeling.html#cb678-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb678-5"><a href="modeling.html#cb678-5" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">mean</span>(error<span class="sc">^</span><span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] 4.679191</code></pre>
</div>
<div id="classification" class="section level2" number="17.7">
<h2><span class="header-section-number">17.7</span> Classification</h2>
<div id="an-rpart-classification-example." class="section level3" number="17.7.1">
<h3><span class="header-section-number">17.7.1</span> An <strong>rpart</strong> classification example.</h3>
<div class="sourceCode" id="cb680"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb680-1"><a href="modeling.html#cb680-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">rpart</span>(Species <span class="sc">~</span> ., <span class="at">data =</span> iris, <span class="at">method =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb680-2"><a href="modeling.html#cb680-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb680-3"><a href="modeling.html#cb680-3" aria-hidden="true" tabindex="-1"></a>predicted <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, iris, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb680-4"><a href="modeling.html#cb680-4" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(predicted)</span></code></pre></div>
<pre><code>##      1      2      3      4      5      6 
## setosa setosa setosa setosa setosa setosa 
## Levels: setosa versicolor virginica</code></pre>
<p>Study what’s going on in <strong>predict()</strong>:</p>
<div class="sourceCode" id="cb682"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb682-1"><a href="modeling.html#cb682-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ?predict.rpart</span></span></code></pre></div>
<p>So <strong>predict()</strong> uses the model to assign a predicted value to Species based on the rest of the iris dataset data.</p>
<p>The accuracy of this prediction can be tested by comparing this vector to the original Species.</p>
<div class="sourceCode" id="cb683"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb683-1"><a href="modeling.html#cb683-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(predicted <span class="sc">==</span> iris<span class="sc">$</span>Species)</span></code></pre></div>
<pre><code>## [1] 0.96</code></pre>
</div>
</div>
<div id="from-the-datacamp-course" class="section level2" number="17.8">
<h2><span class="header-section-number">17.8</span> From the DataCamp course</h2>
<div class="sourceCode" id="cb685"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb685-1"><a href="modeling.html#cb685-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlbench)</span>
<span id="cb685-2"><a href="modeling.html#cb685-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;Sonar&quot;</span>)</span>
<span id="cb685-3"><a href="modeling.html#cb685-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb685-4"><a href="modeling.html#cb685-4" aria-hidden="true" tabindex="-1"></a><span class="co"># First randomize the dataset.</span></span>
<span id="cb685-5"><a href="modeling.html#cb685-5" aria-hidden="true" tabindex="-1"></a>rows <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">nrow</span>(Sonar))</span>
<span id="cb685-6"><a href="modeling.html#cb685-6" aria-hidden="true" tabindex="-1"></a>Sonar <span class="ot">&lt;-</span> Sonar[rows, ]</span>
<span id="cb685-7"><a href="modeling.html#cb685-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb685-8"><a href="modeling.html#cb685-8" aria-hidden="true" tabindex="-1"></a><span class="co"># The split it into testing and training sets.</span></span>
<span id="cb685-9"><a href="modeling.html#cb685-9" aria-hidden="true" tabindex="-1"></a>split <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">nrow</span>(Sonar) <span class="sc">*</span> <span class="fl">0.6</span>)</span>
<span id="cb685-10"><a href="modeling.html#cb685-10" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> Sonar[<span class="dv">1</span><span class="sc">:</span>split, ]</span>
<span id="cb685-11"><a href="modeling.html#cb685-11" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> Sonar[(split <span class="sc">+</span> <span class="dv">1</span>)<span class="sc">:</span><span class="fu">nrow</span>(Sonar), ]</span>
<span id="cb685-12"><a href="modeling.html#cb685-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb685-13"><a href="modeling.html#cb685-13" aria-hidden="true" tabindex="-1"></a><span class="fu">nrow</span>(train)<span class="sc">/</span><span class="fu">nrow</span>(Sonar)</span></code></pre></div>
<pre><code>## [1] 0.6009615</code></pre>
<div class="sourceCode" id="cb687"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb687-1"><a href="modeling.html#cb687-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">glm</span>(Class <span class="sc">~</span> ., <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link =</span> <span class="st">&quot;logit&quot;</span>), train)</span></code></pre></div>
<pre><code>## Warning: glm.fit: algorithm did not converge</code></pre>
<pre><code>## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
<div class="sourceCode" id="cb690"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb690-1"><a href="modeling.html#cb690-1" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, test, <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb690-2"><a href="modeling.html#cb690-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(p)</span></code></pre></div>
<pre><code>##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## 0.000000 0.000000 0.002428 0.438835 1.000000 1.000000</code></pre>
<div class="sourceCode" id="cb692"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb692-1"><a href="modeling.html#cb692-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(p)</span></code></pre></div>
<p><img src="test-book_files/figure-html/mlbench-sonar-example-1.png" width="672" /></p>
<div class="sourceCode" id="cb693"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb693-1"><a href="modeling.html#cb693-1" aria-hidden="true" tabindex="-1"></a>p_class <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(<span class="fu">ifelse</span>(p <span class="sc">&gt;</span> <span class="fl">0.1</span>, <span class="st">&quot;M&quot;</span>, <span class="st">&quot;R&quot;</span>))</span>
<span id="cb693-2"><a href="modeling.html#cb693-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb693-3"><a href="modeling.html#cb693-3" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(p_class, test[[<span class="st">&quot;Class&quot;</span>]])</span></code></pre></div>
<pre><code>##        
## p_class  M  R
##       M 11 26
##       R 35 11</code></pre>
<div class="sourceCode" id="cb695"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb695-1"><a href="modeling.html#cb695-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(p_class, test[[<span class="st">&quot;Class&quot;</span>]])</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction  M  R
##          M 11 26
##          R 35 11
##                                           
##                Accuracy : 0.2651          
##                  95% CI : (0.1742, 0.3734)
##     No Information Rate : 0.5542          
##     P-Value [Acc &gt; NIR] : 1.0000          
##                                           
##                   Kappa : -0.4528         
##                                           
##  Mcnemar&#39;s Test P-Value : 0.3057          
##                                           
##             Sensitivity : 0.2391          
##             Specificity : 0.2973          
##          Pos Pred Value : 0.2973          
##          Neg Pred Value : 0.2391          
##              Prevalence : 0.5542          
##          Detection Rate : 0.1325          
##    Detection Prevalence : 0.4458          
##       Balanced Accuracy : 0.2682          
##                                           
##        &#39;Positive&#39; Class : M               
## </code></pre>
<p>According to Zach Mayer in DataCamp, manually evaluating classification threshholds is hard work and arbitrary: one would need to create dozens or hundreds of confusion matrices and then manually inspect them. Receiver operator curves add a new level of complexity and usefulness.</p>
<p>To illustrate, we take the predicted probability of each <code>Class</code> for each case of the <code>test</code> set, and compare it with its actual <code>Class</code>:</p>
<div class="sourceCode" id="cb697"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb697-1"><a href="modeling.html#cb697-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caTools)</span>
<span id="cb697-2"><a href="modeling.html#cb697-2" aria-hidden="true" tabindex="-1"></a><span class="fu">colAUC</span>(p, test[[<span class="st">&quot;Class&quot;</span>]], <span class="at">plotROC =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="test-book_files/figure-html/unnamed-chunk-161-1.png" width="672" /></p>
<pre><code>##              [,1]
## M vs. R 0.7532315</code></pre>
<p><code>trainControl()</code> in <strong>caret</strong> can use AUC (instead of accuracy), to tune the parameters of your models. The <code>twoClassSummary()</code> convenience function allows you to do this easily.</p>
<p>When using <code>twoClassSummary()</code>, be sure to always include the argument <code>classProbs = TRUE</code> or your model will throw an error! (You cannot calculate AUC with just class predictions. You need to have class probabilities as well.)</p>
<div class="sourceCode" id="cb699"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb699-1"><a href="modeling.html#cb699-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create trainControl object: myControl</span></span>
<span id="cb699-2"><a href="modeling.html#cb699-2" aria-hidden="true" tabindex="-1"></a>myControl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(</span>
<span id="cb699-3"><a href="modeling.html#cb699-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;cv&quot;</span>,</span>
<span id="cb699-4"><a href="modeling.html#cb699-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">number =</span> <span class="dv">10</span>,</span>
<span id="cb699-5"><a href="modeling.html#cb699-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">summaryFunction =</span> twoClassSummary,</span>
<span id="cb699-6"><a href="modeling.html#cb699-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">classProbs =</span> <span class="cn">TRUE</span>, <span class="co"># IMPORTANT!</span></span>
<span id="cb699-7"><a href="modeling.html#cb699-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">verboseIter =</span> <span class="cn">TRUE</span></span>
<span id="cb699-8"><a href="modeling.html#cb699-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb699-9"><a href="modeling.html#cb699-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb699-10"><a href="modeling.html#cb699-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Train glm with custom trainControl: model</span></span>
<span id="cb699-11"><a href="modeling.html#cb699-11" aria-hidden="true" tabindex="-1"></a>model<span class="ot">&lt;-</span><span class="fu">train</span>(Class<span class="sc">~</span>., <span class="at">data=</span>Sonar, <span class="at">method=</span><span class="st">&quot;glm&quot;</span>, <span class="at">trControl=</span>myControl)</span></code></pre></div>
<pre><code>## Warning in train.default(x, y, weights = w, ...): The metric &quot;Accuracy&quot; was not
## in the result set. ROC will be used instead.</code></pre>
<pre><code>## + Fold01: parameter=none</code></pre>
<pre><code>## Warning: glm.fit: algorithm did not converge</code></pre>
<pre><code>## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
<pre><code>## - Fold01: parameter=none 
## + Fold02: parameter=none</code></pre>
<pre><code>## Warning: glm.fit: algorithm did not converge

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
<pre><code>## - Fold02: parameter=none 
## + Fold03: parameter=none</code></pre>
<pre><code>## Warning: glm.fit: algorithm did not converge

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
<pre><code>## - Fold03: parameter=none 
## + Fold04: parameter=none</code></pre>
<pre><code>## Warning: glm.fit: algorithm did not converge

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
<pre><code>## - Fold04: parameter=none 
## + Fold05: parameter=none</code></pre>
<pre><code>## Warning: glm.fit: algorithm did not converge

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
<pre><code>## - Fold05: parameter=none 
## + Fold06: parameter=none</code></pre>
<pre><code>## Warning: glm.fit: algorithm did not converge

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
<pre><code>## - Fold06: parameter=none 
## + Fold07: parameter=none</code></pre>
<pre><code>## Warning: glm.fit: algorithm did not converge

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
<pre><code>## - Fold07: parameter=none 
## + Fold08: parameter=none</code></pre>
<pre><code>## Warning: glm.fit: algorithm did not converge

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
<pre><code>## - Fold08: parameter=none 
## + Fold09: parameter=none</code></pre>
<pre><code>## Warning: glm.fit: algorithm did not converge

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
<pre><code>## - Fold09: parameter=none 
## + Fold10: parameter=none</code></pre>
<pre><code>## Warning: glm.fit: algorithm did not converge

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
<pre><code>## - Fold10: parameter=none 
## Aggregating results
## Fitting final model on full training set</code></pre>
<pre><code>## Warning: glm.fit: algorithm did not converge

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
<div class="sourceCode" id="cb724"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb724-1"><a href="modeling.html#cb724-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print model to console</span></span>
<span id="cb724-2"><a href="modeling.html#cb724-2" aria-hidden="true" tabindex="-1"></a>model</span></code></pre></div>
<pre><code>## Generalized Linear Model 
## 
## 208 samples
##  60 predictor
##   2 classes: &#39;M&#39;, &#39;R&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 187, 187, 186, 188, 188, 187, ... 
## Resampling results:
## 
##   ROC        Sens       Spec
##   0.7221086  0.7378788  0.67</code></pre>
<p>So <code>twoClassSummary</code> to use AUC to tune the parameters for the model generates a much more accurate model than our random assignment for <code>p</code>.</p>
</div>
<div id="random-forest-with-caret" class="section level2" number="17.9">
<h2><span class="header-section-number">17.9</span> Random forest with <strong>caret</strong></h2>
<p>For this set, we’ll use the white wine quality data set from UC Irvine.</p>
<div class="sourceCode" id="cb726"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb726-1"><a href="modeling.html#cb726-1" aria-hidden="true" tabindex="-1"></a>wine <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv&quot;</span>,</span>
<span id="cb726-2"><a href="modeling.html#cb726-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">sep =</span> <span class="st">&quot;;&quot;</span>)</span>
<span id="cb726-3"><a href="modeling.html#cb726-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb726-4"><a href="modeling.html#cb726-4" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(wine)</span></code></pre></div>
<pre><code>## Rows: 4,898
## Columns: 12
## $ fixed.acidity        &lt;dbl&gt; 7.0, 6.3, 8.1, 7.2, 7.2, 8.1, 6.2, 7.0, 6.3, 8.1,…
## $ volatile.acidity     &lt;dbl&gt; 0.27, 0.30, 0.28, 0.23, 0.23, 0.28, 0.32, 0.27, 0…
## $ citric.acid          &lt;dbl&gt; 0.36, 0.34, 0.40, 0.32, 0.32, 0.40, 0.16, 0.36, 0…
## $ residual.sugar       &lt;dbl&gt; 20.70, 1.60, 6.90, 8.50, 8.50, 6.90, 7.00, 20.70,…
## $ chlorides            &lt;dbl&gt; 0.045, 0.049, 0.050, 0.058, 0.058, 0.050, 0.045, …
## $ free.sulfur.dioxide  &lt;dbl&gt; 45, 14, 30, 47, 47, 30, 30, 45, 14, 28, 11, 17, 1…
## $ total.sulfur.dioxide &lt;dbl&gt; 170, 132, 97, 186, 186, 97, 136, 170, 132, 129, 6…
## $ density              &lt;dbl&gt; 1.0010, 0.9940, 0.9951, 0.9956, 0.9956, 0.9951, 0…
## $ pH                   &lt;dbl&gt; 3.00, 3.30, 3.26, 3.19, 3.19, 3.26, 3.18, 3.00, 3…
## $ sulphates            &lt;dbl&gt; 0.45, 0.49, 0.44, 0.40, 0.40, 0.44, 0.47, 0.45, 0…
## $ alcohol              &lt;dbl&gt; 8.8, 9.5, 10.1, 9.9, 9.9, 10.1, 9.6, 8.8, 9.5, 11…
## $ quality              &lt;int&gt; 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 7, 5, 7, 6…</code></pre>
<div class="sourceCode" id="cb728"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb728-1"><a href="modeling.html#cb728-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Note that quality is an integer, not a factor. **caret**</span></span>
<span id="cb728-2"><a href="modeling.html#cb728-2" aria-hidden="true" tabindex="-1"></a><span class="co"># seems to take this in stride.</span></span>
<span id="cb728-3"><a href="modeling.html#cb728-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb728-4"><a href="modeling.html#cb728-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit random forest: model</span></span>
<span id="cb728-5"><a href="modeling.html#cb728-5" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">train</span>(quality <span class="sc">~</span> ., <span class="at">tuneLength =</span> <span class="dv">1</span>, <span class="at">data =</span> wine, <span class="at">method =</span> <span class="st">&quot;ranger&quot;</span>,</span>
<span id="cb728-6"><a href="modeling.html#cb728-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">5</span>, <span class="at">verboseIter =</span> <span class="cn">TRUE</span>))</span></code></pre></div>
<pre><code>## + Fold1: mtry=3, min.node.size=5, splitrule=variance 
## - Fold1: mtry=3, min.node.size=5, splitrule=variance 
## + Fold1: mtry=3, min.node.size=5, splitrule=extratrees 
## - Fold1: mtry=3, min.node.size=5, splitrule=extratrees 
## + Fold2: mtry=3, min.node.size=5, splitrule=variance 
## - Fold2: mtry=3, min.node.size=5, splitrule=variance 
## + Fold2: mtry=3, min.node.size=5, splitrule=extratrees 
## - Fold2: mtry=3, min.node.size=5, splitrule=extratrees 
## + Fold3: mtry=3, min.node.size=5, splitrule=variance 
## - Fold3: mtry=3, min.node.size=5, splitrule=variance 
## + Fold3: mtry=3, min.node.size=5, splitrule=extratrees 
## - Fold3: mtry=3, min.node.size=5, splitrule=extratrees 
## + Fold4: mtry=3, min.node.size=5, splitrule=variance 
## - Fold4: mtry=3, min.node.size=5, splitrule=variance 
## + Fold4: mtry=3, min.node.size=5, splitrule=extratrees 
## - Fold4: mtry=3, min.node.size=5, splitrule=extratrees 
## + Fold5: mtry=3, min.node.size=5, splitrule=variance 
## - Fold5: mtry=3, min.node.size=5, splitrule=variance 
## + Fold5: mtry=3, min.node.size=5, splitrule=extratrees 
## - Fold5: mtry=3, min.node.size=5, splitrule=extratrees 
## Aggregating results
## Selecting tuning parameters
## Fitting mtry = 3, splitrule = variance, min.node.size = 5 on full training set</code></pre>
<div class="sourceCode" id="cb730"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb730-1"><a href="modeling.html#cb730-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print model to console</span></span>
<span id="cb730-2"><a href="modeling.html#cb730-2" aria-hidden="true" tabindex="-1"></a>model</span></code></pre></div>
<pre><code>## Random Forest 
## 
## 4898 samples
##   11 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 3918, 3918, 3919, 3919, 3918 
## Resampling results across tuning parameters:
## 
##   splitrule   RMSE       Rsquared   MAE      
##   variance    0.6050967  0.5413882  0.4391071
##   extratrees  0.6153818  0.5364792  0.4578305
## 
## Tuning parameter &#39;mtry&#39; was held constant at a value of 3
## Tuning
##  parameter &#39;min.node.size&#39; was held constant at a value of 5
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were mtry = 3, splitrule = variance
##  and min.node.size = 5.</code></pre>
<div class="sourceCode" id="cb732"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb732-1"><a href="modeling.html#cb732-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model)</span></code></pre></div>
<p><img src="test-book_files/figure-html/wine-ranger-example-1.png" width="672" /></p>
<p>Let’s try this again with a longer <code>tuneLength</code>. This explores more models and potentially finds a better model.</p>
<div class="sourceCode" id="cb733"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb733-1"><a href="modeling.html#cb733-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">train</span>(quality <span class="sc">~</span> ., <span class="at">tuneLength =</span> <span class="dv">10</span>, <span class="at">data =</span> wine, <span class="at">method =</span> <span class="st">&quot;ranger&quot;</span>,</span>
<span id="cb733-2"><a href="modeling.html#cb733-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">5</span>, <span class="at">verboseIter =</span> <span class="cn">TRUE</span>))</span></code></pre></div>
<pre><code>## + Fold1: mtry= 2, min.node.size=5, splitrule=variance 
## - Fold1: mtry= 2, min.node.size=5, splitrule=variance 
## + Fold1: mtry= 3, min.node.size=5, splitrule=variance 
## - Fold1: mtry= 3, min.node.size=5, splitrule=variance 
## + Fold1: mtry= 4, min.node.size=5, splitrule=variance 
## - Fold1: mtry= 4, min.node.size=5, splitrule=variance 
## + Fold1: mtry= 5, min.node.size=5, splitrule=variance 
## - Fold1: mtry= 5, min.node.size=5, splitrule=variance 
## + Fold1: mtry= 6, min.node.size=5, splitrule=variance 
## - Fold1: mtry= 6, min.node.size=5, splitrule=variance 
## + Fold1: mtry= 7, min.node.size=5, splitrule=variance 
## - Fold1: mtry= 7, min.node.size=5, splitrule=variance 
## + Fold1: mtry= 8, min.node.size=5, splitrule=variance 
## - Fold1: mtry= 8, min.node.size=5, splitrule=variance 
## + Fold1: mtry= 9, min.node.size=5, splitrule=variance 
## - Fold1: mtry= 9, min.node.size=5, splitrule=variance 
## + Fold1: mtry=10, min.node.size=5, splitrule=variance 
## - Fold1: mtry=10, min.node.size=5, splitrule=variance 
## + Fold1: mtry=11, min.node.size=5, splitrule=variance 
## - Fold1: mtry=11, min.node.size=5, splitrule=variance 
## + Fold1: mtry= 2, min.node.size=5, splitrule=extratrees 
## - Fold1: mtry= 2, min.node.size=5, splitrule=extratrees 
## + Fold1: mtry= 3, min.node.size=5, splitrule=extratrees 
## - Fold1: mtry= 3, min.node.size=5, splitrule=extratrees 
## + Fold1: mtry= 4, min.node.size=5, splitrule=extratrees 
## - Fold1: mtry= 4, min.node.size=5, splitrule=extratrees 
## + Fold1: mtry= 5, min.node.size=5, splitrule=extratrees 
## - Fold1: mtry= 5, min.node.size=5, splitrule=extratrees 
## + Fold1: mtry= 6, min.node.size=5, splitrule=extratrees 
## - Fold1: mtry= 6, min.node.size=5, splitrule=extratrees 
## + Fold1: mtry= 7, min.node.size=5, splitrule=extratrees 
## - Fold1: mtry= 7, min.node.size=5, splitrule=extratrees 
## + Fold1: mtry= 8, min.node.size=5, splitrule=extratrees 
## - Fold1: mtry= 8, min.node.size=5, splitrule=extratrees 
## + Fold1: mtry= 9, min.node.size=5, splitrule=extratrees 
## - Fold1: mtry= 9, min.node.size=5, splitrule=extratrees 
## + Fold1: mtry=10, min.node.size=5, splitrule=extratrees 
## - Fold1: mtry=10, min.node.size=5, splitrule=extratrees 
## + Fold1: mtry=11, min.node.size=5, splitrule=extratrees 
## - Fold1: mtry=11, min.node.size=5, splitrule=extratrees 
## + Fold2: mtry= 2, min.node.size=5, splitrule=variance 
## - Fold2: mtry= 2, min.node.size=5, splitrule=variance 
## + Fold2: mtry= 3, min.node.size=5, splitrule=variance 
## - Fold2: mtry= 3, min.node.size=5, splitrule=variance 
## + Fold2: mtry= 4, min.node.size=5, splitrule=variance 
## - Fold2: mtry= 4, min.node.size=5, splitrule=variance 
## + Fold2: mtry= 5, min.node.size=5, splitrule=variance 
## - Fold2: mtry= 5, min.node.size=5, splitrule=variance 
## + Fold2: mtry= 6, min.node.size=5, splitrule=variance 
## - Fold2: mtry= 6, min.node.size=5, splitrule=variance 
## + Fold2: mtry= 7, min.node.size=5, splitrule=variance 
## - Fold2: mtry= 7, min.node.size=5, splitrule=variance 
## + Fold2: mtry= 8, min.node.size=5, splitrule=variance 
## - Fold2: mtry= 8, min.node.size=5, splitrule=variance 
## + Fold2: mtry= 9, min.node.size=5, splitrule=variance 
## - Fold2: mtry= 9, min.node.size=5, splitrule=variance 
## + Fold2: mtry=10, min.node.size=5, splitrule=variance 
## - Fold2: mtry=10, min.node.size=5, splitrule=variance 
## + Fold2: mtry=11, min.node.size=5, splitrule=variance 
## - Fold2: mtry=11, min.node.size=5, splitrule=variance 
## + Fold2: mtry= 2, min.node.size=5, splitrule=extratrees 
## - Fold2: mtry= 2, min.node.size=5, splitrule=extratrees 
## + Fold2: mtry= 3, min.node.size=5, splitrule=extratrees 
## - Fold2: mtry= 3, min.node.size=5, splitrule=extratrees 
## + Fold2: mtry= 4, min.node.size=5, splitrule=extratrees 
## - Fold2: mtry= 4, min.node.size=5, splitrule=extratrees 
## + Fold2: mtry= 5, min.node.size=5, splitrule=extratrees 
## - Fold2: mtry= 5, min.node.size=5, splitrule=extratrees 
## + Fold2: mtry= 6, min.node.size=5, splitrule=extratrees 
## - Fold2: mtry= 6, min.node.size=5, splitrule=extratrees 
## + Fold2: mtry= 7, min.node.size=5, splitrule=extratrees 
## - Fold2: mtry= 7, min.node.size=5, splitrule=extratrees 
## + Fold2: mtry= 8, min.node.size=5, splitrule=extratrees 
## - Fold2: mtry= 8, min.node.size=5, splitrule=extratrees 
## + Fold2: mtry= 9, min.node.size=5, splitrule=extratrees 
## - Fold2: mtry= 9, min.node.size=5, splitrule=extratrees 
## + Fold2: mtry=10, min.node.size=5, splitrule=extratrees 
## - Fold2: mtry=10, min.node.size=5, splitrule=extratrees 
## + Fold2: mtry=11, min.node.size=5, splitrule=extratrees 
## - Fold2: mtry=11, min.node.size=5, splitrule=extratrees 
## + Fold3: mtry= 2, min.node.size=5, splitrule=variance 
## - Fold3: mtry= 2, min.node.size=5, splitrule=variance 
## + Fold3: mtry= 3, min.node.size=5, splitrule=variance 
## - Fold3: mtry= 3, min.node.size=5, splitrule=variance 
## + Fold3: mtry= 4, min.node.size=5, splitrule=variance 
## - Fold3: mtry= 4, min.node.size=5, splitrule=variance 
## + Fold3: mtry= 5, min.node.size=5, splitrule=variance 
## - Fold3: mtry= 5, min.node.size=5, splitrule=variance 
## + Fold3: mtry= 6, min.node.size=5, splitrule=variance 
## - Fold3: mtry= 6, min.node.size=5, splitrule=variance 
## + Fold3: mtry= 7, min.node.size=5, splitrule=variance 
## - Fold3: mtry= 7, min.node.size=5, splitrule=variance 
## + Fold3: mtry= 8, min.node.size=5, splitrule=variance 
## - Fold3: mtry= 8, min.node.size=5, splitrule=variance 
## + Fold3: mtry= 9, min.node.size=5, splitrule=variance 
## - Fold3: mtry= 9, min.node.size=5, splitrule=variance 
## + Fold3: mtry=10, min.node.size=5, splitrule=variance 
## - Fold3: mtry=10, min.node.size=5, splitrule=variance 
## + Fold3: mtry=11, min.node.size=5, splitrule=variance 
## - Fold3: mtry=11, min.node.size=5, splitrule=variance 
## + Fold3: mtry= 2, min.node.size=5, splitrule=extratrees 
## - Fold3: mtry= 2, min.node.size=5, splitrule=extratrees 
## + Fold3: mtry= 3, min.node.size=5, splitrule=extratrees 
## - Fold3: mtry= 3, min.node.size=5, splitrule=extratrees 
## + Fold3: mtry= 4, min.node.size=5, splitrule=extratrees 
## - Fold3: mtry= 4, min.node.size=5, splitrule=extratrees 
## + Fold3: mtry= 5, min.node.size=5, splitrule=extratrees 
## - Fold3: mtry= 5, min.node.size=5, splitrule=extratrees 
## + Fold3: mtry= 6, min.node.size=5, splitrule=extratrees 
## - Fold3: mtry= 6, min.node.size=5, splitrule=extratrees 
## + Fold3: mtry= 7, min.node.size=5, splitrule=extratrees 
## - Fold3: mtry= 7, min.node.size=5, splitrule=extratrees 
## + Fold3: mtry= 8, min.node.size=5, splitrule=extratrees 
## - Fold3: mtry= 8, min.node.size=5, splitrule=extratrees 
## + Fold3: mtry= 9, min.node.size=5, splitrule=extratrees 
## - Fold3: mtry= 9, min.node.size=5, splitrule=extratrees 
## + Fold3: mtry=10, min.node.size=5, splitrule=extratrees 
## - Fold3: mtry=10, min.node.size=5, splitrule=extratrees 
## + Fold3: mtry=11, min.node.size=5, splitrule=extratrees 
## - Fold3: mtry=11, min.node.size=5, splitrule=extratrees 
## + Fold4: mtry= 2, min.node.size=5, splitrule=variance 
## - Fold4: mtry= 2, min.node.size=5, splitrule=variance 
## + Fold4: mtry= 3, min.node.size=5, splitrule=variance 
## - Fold4: mtry= 3, min.node.size=5, splitrule=variance 
## + Fold4: mtry= 4, min.node.size=5, splitrule=variance 
## - Fold4: mtry= 4, min.node.size=5, splitrule=variance 
## + Fold4: mtry= 5, min.node.size=5, splitrule=variance 
## - Fold4: mtry= 5, min.node.size=5, splitrule=variance 
## + Fold4: mtry= 6, min.node.size=5, splitrule=variance 
## - Fold4: mtry= 6, min.node.size=5, splitrule=variance 
## + Fold4: mtry= 7, min.node.size=5, splitrule=variance 
## - Fold4: mtry= 7, min.node.size=5, splitrule=variance 
## + Fold4: mtry= 8, min.node.size=5, splitrule=variance 
## - Fold4: mtry= 8, min.node.size=5, splitrule=variance 
## + Fold4: mtry= 9, min.node.size=5, splitrule=variance 
## - Fold4: mtry= 9, min.node.size=5, splitrule=variance 
## + Fold4: mtry=10, min.node.size=5, splitrule=variance 
## - Fold4: mtry=10, min.node.size=5, splitrule=variance 
## + Fold4: mtry=11, min.node.size=5, splitrule=variance 
## - Fold4: mtry=11, min.node.size=5, splitrule=variance 
## + Fold4: mtry= 2, min.node.size=5, splitrule=extratrees 
## - Fold4: mtry= 2, min.node.size=5, splitrule=extratrees 
## + Fold4: mtry= 3, min.node.size=5, splitrule=extratrees 
## - Fold4: mtry= 3, min.node.size=5, splitrule=extratrees 
## + Fold4: mtry= 4, min.node.size=5, splitrule=extratrees 
## - Fold4: mtry= 4, min.node.size=5, splitrule=extratrees 
## + Fold4: mtry= 5, min.node.size=5, splitrule=extratrees 
## - Fold4: mtry= 5, min.node.size=5, splitrule=extratrees 
## + Fold4: mtry= 6, min.node.size=5, splitrule=extratrees 
## - Fold4: mtry= 6, min.node.size=5, splitrule=extratrees 
## + Fold4: mtry= 7, min.node.size=5, splitrule=extratrees 
## - Fold4: mtry= 7, min.node.size=5, splitrule=extratrees 
## + Fold4: mtry= 8, min.node.size=5, splitrule=extratrees 
## - Fold4: mtry= 8, min.node.size=5, splitrule=extratrees 
## + Fold4: mtry= 9, min.node.size=5, splitrule=extratrees 
## - Fold4: mtry= 9, min.node.size=5, splitrule=extratrees 
## + Fold4: mtry=10, min.node.size=5, splitrule=extratrees 
## - Fold4: mtry=10, min.node.size=5, splitrule=extratrees 
## + Fold4: mtry=11, min.node.size=5, splitrule=extratrees 
## - Fold4: mtry=11, min.node.size=5, splitrule=extratrees 
## + Fold5: mtry= 2, min.node.size=5, splitrule=variance 
## - Fold5: mtry= 2, min.node.size=5, splitrule=variance 
## + Fold5: mtry= 3, min.node.size=5, splitrule=variance 
## - Fold5: mtry= 3, min.node.size=5, splitrule=variance 
## + Fold5: mtry= 4, min.node.size=5, splitrule=variance 
## - Fold5: mtry= 4, min.node.size=5, splitrule=variance 
## + Fold5: mtry= 5, min.node.size=5, splitrule=variance 
## - Fold5: mtry= 5, min.node.size=5, splitrule=variance 
## + Fold5: mtry= 6, min.node.size=5, splitrule=variance 
## - Fold5: mtry= 6, min.node.size=5, splitrule=variance 
## + Fold5: mtry= 7, min.node.size=5, splitrule=variance 
## - Fold5: mtry= 7, min.node.size=5, splitrule=variance 
## + Fold5: mtry= 8, min.node.size=5, splitrule=variance 
## - Fold5: mtry= 8, min.node.size=5, splitrule=variance 
## + Fold5: mtry= 9, min.node.size=5, splitrule=variance 
## - Fold5: mtry= 9, min.node.size=5, splitrule=variance 
## + Fold5: mtry=10, min.node.size=5, splitrule=variance 
## - Fold5: mtry=10, min.node.size=5, splitrule=variance 
## + Fold5: mtry=11, min.node.size=5, splitrule=variance 
## - Fold5: mtry=11, min.node.size=5, splitrule=variance 
## + Fold5: mtry= 2, min.node.size=5, splitrule=extratrees 
## - Fold5: mtry= 2, min.node.size=5, splitrule=extratrees 
## + Fold5: mtry= 3, min.node.size=5, splitrule=extratrees 
## - Fold5: mtry= 3, min.node.size=5, splitrule=extratrees 
## + Fold5: mtry= 4, min.node.size=5, splitrule=extratrees 
## - Fold5: mtry= 4, min.node.size=5, splitrule=extratrees 
## + Fold5: mtry= 5, min.node.size=5, splitrule=extratrees 
## - Fold5: mtry= 5, min.node.size=5, splitrule=extratrees 
## + Fold5: mtry= 6, min.node.size=5, splitrule=extratrees 
## - Fold5: mtry= 6, min.node.size=5, splitrule=extratrees 
## + Fold5: mtry= 7, min.node.size=5, splitrule=extratrees 
## - Fold5: mtry= 7, min.node.size=5, splitrule=extratrees 
## + Fold5: mtry= 8, min.node.size=5, splitrule=extratrees 
## - Fold5: mtry= 8, min.node.size=5, splitrule=extratrees 
## + Fold5: mtry= 9, min.node.size=5, splitrule=extratrees 
## - Fold5: mtry= 9, min.node.size=5, splitrule=extratrees 
## + Fold5: mtry=10, min.node.size=5, splitrule=extratrees 
## - Fold5: mtry=10, min.node.size=5, splitrule=extratrees 
## + Fold5: mtry=11, min.node.size=5, splitrule=extratrees 
## - Fold5: mtry=11, min.node.size=5, splitrule=extratrees 
## Aggregating results
## Selecting tuning parameters
## Fitting mtry = 4, splitrule = variance, min.node.size = 5 on full training set</code></pre>
<div class="sourceCode" id="cb735"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb735-1"><a href="modeling.html#cb735-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print model to console</span></span>
<span id="cb735-2"><a href="modeling.html#cb735-2" aria-hidden="true" tabindex="-1"></a>model</span></code></pre></div>
<pre><code>## Random Forest 
## 
## 4898 samples
##   11 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 3919, 3918, 3918, 3918, 3919 
## Resampling results across tuning parameters:
## 
##   mtry  splitrule   RMSE       Rsquared   MAE      
##    2    variance    0.6057267  0.5439626  0.4405916
##    2    extratrees  0.6236281  0.5298696  0.4653787
##    3    variance    0.6046583  0.5423307  0.4382451
##    3    extratrees  0.6156828  0.5361785  0.4564330
##    4    variance    0.6043205  0.5415035  0.4369536
##    4    extratrees  0.6121588  0.5385053  0.4515880
##    5    variance    0.6055318  0.5381417  0.4372017
##    5    extratrees  0.6105919  0.5382888  0.4489989
##    6    variance    0.6059000  0.5371010  0.4376776
##    6    extratrees  0.6100430  0.5376337  0.4473954
##    7    variance    0.6053503  0.5373499  0.4365124
##    7    extratrees  0.6103668  0.5356061  0.4465320
##    8    variance    0.6058807  0.5364227  0.4372000
##    8    extratrees  0.6088559  0.5371926  0.4442014
##    9    variance    0.6084825  0.5316505  0.4382170
##    9    extratrees  0.6090639  0.5360376  0.4442829
##   10    variance    0.6093909  0.5296893  0.4394500
##   10    extratrees  0.6095042  0.5344968  0.4435984
##   11    variance    0.6096074  0.5291148  0.4389384
##   11    extratrees  0.6088682  0.5352417  0.4435641
## 
## Tuning parameter &#39;min.node.size&#39; was held constant at a value of 5
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were mtry = 4, splitrule = variance
##  and min.node.size = 5.</code></pre>
<div class="sourceCode" id="cb737"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb737-1"><a href="modeling.html#cb737-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model)</span></code></pre></div>
<p><img src="test-book_files/figure-html/wine-tunelength-example-1.png" width="672" /></p>
</div>
<div id="random-forest-model-and-tunegrid" class="section level2" number="17.10">
<h2><span class="header-section-number">17.10</span> Random forest model and <code>tuneGrid()</code></h2>
<p>Custom tuning of grids can be used in <strong>caret</strong> by using <code>tuneGrid()</code>. While it is the most flexible method for fitting <strong>caret</strong> models and allows complete control over how the model is fit, it requires significant knowledge of the model and dramatically increases run time.</p>
<p>For my uses, most of the time I anticipate using <code>tuneLength</code> and the default settings in <strong>caret</strong> to build my random forest models.</p>
<div class="sourceCode" id="cb738"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb738-1"><a href="modeling.html#cb738-1" aria-hidden="true" tabindex="-1"></a>tuneGrid <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">.mtry =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">7</span>), <span class="at">.splitrule =</span> <span class="st">&quot;variance&quot;</span>,</span>
<span id="cb738-2"><a href="modeling.html#cb738-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">.min.node.size =</span> <span class="dv">5</span>)</span>
<span id="cb738-3"><a href="modeling.html#cb738-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb738-4"><a href="modeling.html#cb738-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit random forest: model</span></span>
<span id="cb738-5"><a href="modeling.html#cb738-5" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">train</span>(quality <span class="sc">~</span> ., <span class="at">tuneGrid =</span> tuneGrid, <span class="at">data =</span> wine,</span>
<span id="cb738-6"><a href="modeling.html#cb738-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">method =</span> <span class="st">&quot;ranger&quot;</span>, <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>,</span>
<span id="cb738-7"><a href="modeling.html#cb738-7" aria-hidden="true" tabindex="-1"></a>        <span class="at">number =</span> <span class="dv">5</span>, <span class="at">verboseIter =</span> <span class="cn">TRUE</span>))</span></code></pre></div>
<pre><code>## + Fold1: mtry=2, splitrule=variance, min.node.size=5 
## - Fold1: mtry=2, splitrule=variance, min.node.size=5 
## + Fold1: mtry=3, splitrule=variance, min.node.size=5 
## - Fold1: mtry=3, splitrule=variance, min.node.size=5 
## + Fold1: mtry=7, splitrule=variance, min.node.size=5 
## - Fold1: mtry=7, splitrule=variance, min.node.size=5 
## + Fold2: mtry=2, splitrule=variance, min.node.size=5 
## - Fold2: mtry=2, splitrule=variance, min.node.size=5 
## + Fold2: mtry=3, splitrule=variance, min.node.size=5 
## - Fold2: mtry=3, splitrule=variance, min.node.size=5 
## + Fold2: mtry=7, splitrule=variance, min.node.size=5 
## - Fold2: mtry=7, splitrule=variance, min.node.size=5 
## + Fold3: mtry=2, splitrule=variance, min.node.size=5 
## - Fold3: mtry=2, splitrule=variance, min.node.size=5 
## + Fold3: mtry=3, splitrule=variance, min.node.size=5 
## - Fold3: mtry=3, splitrule=variance, min.node.size=5 
## + Fold3: mtry=7, splitrule=variance, min.node.size=5 
## - Fold3: mtry=7, splitrule=variance, min.node.size=5 
## + Fold4: mtry=2, splitrule=variance, min.node.size=5 
## - Fold4: mtry=2, splitrule=variance, min.node.size=5 
## + Fold4: mtry=3, splitrule=variance, min.node.size=5 
## - Fold4: mtry=3, splitrule=variance, min.node.size=5 
## + Fold4: mtry=7, splitrule=variance, min.node.size=5 
## - Fold4: mtry=7, splitrule=variance, min.node.size=5 
## + Fold5: mtry=2, splitrule=variance, min.node.size=5 
## - Fold5: mtry=2, splitrule=variance, min.node.size=5 
## + Fold5: mtry=3, splitrule=variance, min.node.size=5 
## - Fold5: mtry=3, splitrule=variance, min.node.size=5 
## + Fold5: mtry=7, splitrule=variance, min.node.size=5 
## - Fold5: mtry=7, splitrule=variance, min.node.size=5 
## Aggregating results
## Selecting tuning parameters
## Fitting mtry = 3, splitrule = variance, min.node.size = 5 on full training set</code></pre>
<div class="sourceCode" id="cb740"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb740-1"><a href="modeling.html#cb740-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print model to console</span></span>
<span id="cb740-2"><a href="modeling.html#cb740-2" aria-hidden="true" tabindex="-1"></a>model</span></code></pre></div>
<pre><code>## Random Forest 
## 
## 4898 samples
##   11 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 3918, 3918, 3919, 3918, 3919 
## Resampling results across tuning parameters:
## 
##   mtry  RMSE       Rsquared   MAE      
##   2     0.6076591  0.5397497  0.4417339
##   3     0.6056877  0.5399161  0.4378556
##   7     0.6083201  0.5319077  0.4367244
## 
## Tuning parameter &#39;splitrule&#39; was held constant at a value of variance
## 
## Tuning parameter &#39;min.node.size&#39; was held constant at a value of 5
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were mtry = 3, splitrule = variance
##  and min.node.size = 5.</code></pre>
<div class="sourceCode" id="cb742"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb742-1"><a href="modeling.html#cb742-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot model</span></span>
<span id="cb742-2"><a href="modeling.html#cb742-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model)</span></code></pre></div>
<p><img src="test-book_files/figure-html/tunegrid-example-ranger-1.png" width="672" /></p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body">
<div id="ref-RN5383" class="csl-entry">
<div class="csl-left-margin">7. </div><div class="csl-right-inline">James G, Witten D, Hastie T, Tibshirani R. <em>An Introduction to Statistical Learning with Applications in r</em>. Second. Springer; 2021.</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="knncv.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="moremodeling.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/17modeling.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["test-book.pdf", "test-book.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
